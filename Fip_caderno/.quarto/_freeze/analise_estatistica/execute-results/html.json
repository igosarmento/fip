{
  "hash": "fe0a16a8bbb36bf3e82d12846c2b275e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"analise_estatistica\"\n---\n\n\n\n\n# **Análises estatísticas**\n\n## **Tipos de testes para análise estatística:**\n\nNesta aula, serão abordados os tipos de análise estatística em função da quantidade e da natureza das variáveis independentes (níveis dos fatores), bem como do número de tratamentos ou grupos experimentais a serem comparados.\n\n## Teste T\n\nO *teste* *t* é um dos testes estatísticos mais utilizados para comparar médias entre grupos. Ele é especialmente útil quando queremos verificar se duas amostras apresentam diferenças estatisticamente significativas. Como todo teste estatístico, o *teste t* também tem como produto a medida do valor de *p* (calculado a probabilidade da diferença encontrada (entre as médias) terem sido por acaso).\n\nNo RStudio, esse teste pode ser realizado de forma simples usando a função `t.test()`.\n\nTrabalhando um conjunto de dados e aplicando o “Teste t”.\n\n### Teste t para amostras independentes\n\nO teste t para amostras independentes avalia se há evidência estatística suficiente para afirmar que as médias dos dois grupos são diferentes. Esse teste assume que os dois grupos são independentes entre si, isto é, os valores de um grupo não influenciam os do outro.\n\n**Exemplo:** Experimento com o objetivo de avaliar o efeito do micronutriente magnésio (Mg), adicionado na solução do solo cultivado com plantas, no manejo de uma doença. O experimento foi conduzido em delineamento inteiramente casualizado com 10 repetições. Um dos tratamentos é o controle \"*control*\" (testemunha, sem a aplicação do micronutriente. O segundo é Magnésio \"*Mg2*\", onde houve aplicação do mineral. Em cada uma das repetições foi obtido um valor médio do comprimento (mm) de lesões.\n\nO conjunto de dados utilizado neste exemplo está disponível em uma planilha online no *Google Sheets*.Para acessar esses dados diretamente no R, foi utilizada a biblioteca `gsheet`, que permite importar planilhas do *Google Sheets* de forma prática.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Primeiramente, carregou-se a biblioteca com o comando:\nlibrary(gsheet)\n\n#Em seguida, os dados foram lidos a partir do link da planilha online usando a função gsheet2tbl, que converte a planilha em um data frame no R:\ndat_mg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n```\n:::\n\n\n\n\nCom os dados carregados, foi feita uma visualização gráfica utilizando a biblioteca `ggplot2`. O gráfico gerado é do tipo *jitter plot*, que ajuda a visualizar a dispersão dos dados ao longo dos diferentes tratamentos (trat) em relação à variável de interesse (comp):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ndat_mg |> \n  ggplot(aes(trat, comp))+\n  geom_jitter(width=0.1)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\nEsse tipo de gráfico é útil para observar possíveis padrões, sobreposição de valores e variações entre os grupos experimentais.\n\nAgora, vamos iniciar a análise dos dados e extrair estatísticas que resumem o conjunto, tanto em relação à tendência central quanto à dispersão.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\ndata2 <- dat_mg |>\n  group_by(trat) |>\n  summarise(\n    mean_com = mean(comp),\n    sd_comp = sd(comp),\n    var_comp = var(comp),\n    n = n(),\n    se_comp = sd_comp / sqrt(n - 1),\n    ci = se_comp * qt(0,025, df = 9))\ndata2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 7\n  trat    mean_com sd_comp var_comp     n se_comp    ci\n  <chr>      <dbl>   <dbl>    <dbl> <int>   <dbl> <dbl>\n1 Mg2         10.5    1.54     2.39    10   0.515  -Inf\n2 control     15.7    1.27     1.61    10   0.424  -Inf\n```\n\n\n:::\n:::\n\n\n\n\nAqui visualizaremos os dados em gráfico de barras vertical com erro padrão.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata2 |> \n  ggplot(aes(trat, mean_com)) +\n  geom_col(width = 0.5,\n           fill = \"#99E89D\") +\n  geom_errorbar(aes(\n    ymin = mean_com - se_comp,\n    ymax = mean_com + se_comp),\n    width = 0.1) +\n  ylim(0,20) +\nlabs(x = \"Tratamentos\", y = \"Tamanho médio das lesões (mm)\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\nIntervalo de confiança:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata2 |> \n  ggplot(aes(trat, mean_com)) +\n  geom_col(width = 0.5, fill = \"#99E89D\") +\n  geom_errorbar(aes(\n    ymin = mean_com - ci,\n    ymax = mean_com + ci),\n    width = 0.1) +\n  ylim(0,20) +\nlabs(x = \"Tratamentos\", y = \"Tamanho médio das lesões  (mm)\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\nApós importar e visualizar os dados sobre tratamentos com magnésio, procedeu-se com a transformação do formato dos dados e aplicação de um teste estatístico para comparação entre os grupos.\n\n#### Transformação dos dados (pivotagem)\n\nInicialmente, os dados foram reorganizados com a função `pivot_wider()` da biblioteca `tidyr`, com o objetivo de converter a estrutura do dataset do formato longo (onde os valores de tratamento estão em uma única coluna) para o formato largo (em que cada tratamento ocupa uma coluna distinta com seus respectivos valores):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)  # <- Adicione isso para usar pivot_wider()\ndat_mg2 <- dat_mg |>\n  pivot_wider (names_from = trat, values_from = comp) |> #Transformando o formato dos dados: O que era uma coluna \"longa\" vai virar várias colunas \"largas\".\n  ##   Pivot (passar de longo para largo)\n  \n  dplyr::select(-rep)\n```\n:::\n\n\n\n\nCom isso, a coluna `trat`, que antes indicava os diferentes grupos de tratamento (por exemplo, \"control\" e \"Mg2\"), é desmembrada em colunas separadas, facilitando a aplicação de testes estatísticos comparativos. A coluna `rep`, que representa as repetições experimentais, foi removida por não ser necessária nessa etapa da análise.\n\nUtilizou-se a função `t.test()` para comparar as médias dos dois tratamentos: `control` (sem magnésio) e `Mg2` (tratamento com magnésio):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nattach(dat_mg2)\n\nt_results <- t.test(control, Mg2)\nt_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  control and Mg2\nt = 8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 3.825607 6.490393\nsample estimates:\nmean of x mean of y \n   15.678    10.520 \n```\n\n\n:::\n:::\n\n\n\n\n#### Interpretação do valor de *p*\n\nO resultado do teste inclui o valor de *p* (*p-value*), que representa a probabilidade de observar uma diferença entre as médias tão grande quanto (ou maior que) a encontrada nos dados, assumindo que a hipótese nula seja verdadeira.\n\n-   **Hipótese nula (H₀):** as médias dos dois grupos são iguais.\n\n**Hipótese alternativa (H₁):** as médias dos grupos são diferentes\n\nSe o valor de *p* for muito pequeno (geralmente menor que 0,05), rejeita-se a hipótese nula. Isso significa que a diferença observada entre os grupos é estatisticamente significativa, e aceita-se a hipótese alternativa: os grupos são diferentes entre si.\n\nPortanto, o teste t aplicado permite concluir se a aplicação de magnésio (Mg2) gerou um efeito significativo em relação ao controle.\n\n#### Análise e Interpretação do Teste t com Apoio de Pacotes no R\n\nApós a realização do teste t para comparar dois tratamentos experimentais aplicados em plantas (por exemplo, controle e suplementação com magnésio), foram utilizadas ferramentas adicionais no R para interpretar, organizar e visualizar os resultados de forma mais clara e acessível.\n\nO pacote `report` foi utilizado para gerar uma interpretação automática e em linguagem natural dos resultados do teste t. Esse pacote é útil para descrever os principais resultados estatísticos em formato descritivo, ideal para relatórios e publicações.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(report) #Pacote para explicar os resultados das análises\nreport(t_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between control and Mg2\n(mean of x = 15.68, mean of y = 10.52) suggests that the effect is positive,\nstatistically significant, and large (difference = 5.16, 95% CI [3.83, 6.49],\nt(17.35) = 8.15, p < .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])\n```\n\n\n:::\n:::\n\n\n\n\nA função `report()` aplica uma análise interpretativa ao objeto do teste t (`t_results`), exibindo informações como estatísticas do teste, valor de *p*, médias dos grupos comparados e interpretação textual (por exemplo, se a diferença entre os grupos é significativa ou não).\n\nComo o objeto `t_results` foi gerado com os dados em formato longo, **não foi necessário fazer transformações adicionais** para usar a função `report()`.\n\n#### Realização do teste t com o pacote `rstatix`\n\nOutra forma de realizar o teste t, especialmente útil para análises com estrutura de dados em formato longo, é com o pacote `rstatix`. Ele fornece uma sintaxe clara e compatível com o `tidyverse`.\n\nAqui, `comp ~ trat` indica que estamos comparando a variável de resposta `comp` entre os níveis da variável `trat`. O resultado é armazenado no objeto `test`, que pode ser usado para visualização.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix)\ntest <- t_test(comp ~ trat, data = dat_mg)\ntest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  .y.   group1  group2    n1    n2 statistic    df           p\n* <chr> <chr>   <chr>  <int> <int>     <dbl> <dbl>       <dbl>\n1 comp  control Mg2       10    10      8.15  17.4 0.000000242\n```\n\n\n:::\n:::\n\n\n\n\n#### Visualização gráfica com valor de *p* usando `ggpubr`\n\nPara complementar a análise, foi construído um gráfico boxplot com o pacote `ggpubr`, que facilita a geração de gráficos estatísticos com suporte a *p-values*.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggpubr)\n\np <- ggboxplot(\n  dat_mg, x = \"trat\", y = \"comp\",\n  color = \"trat\", palette = \"jco\")\nprint(p)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nEm seguida, o valor de *p* obtido no teste t foi adicionado manualmente ao gráfico com `stat_pvalue_manual()`, indicando se há diferença estatística entre os grupos:\n\nO parâmetro `y.position = 18` define a altura em que o valor de *p* será exibido no gráfico. A função `ylim(0, 20)` ajusta os limites do eixo y para acomodar melhor os dados e o texto.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#add p-value manually\np + stat_pvalue_manual(test, label = \"p\",\n  y.position = 18)+\n    ylim(0,20)+\n  labs(x = \"Tratamento\",\n       y = \"Comprimento (mm)\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggsave(\"plot2.png\", bg = \"white\") #Por fim, o gráfico foi salvo em um arquivo de imagem.\n```\n:::\n\n\n\n\n#### Verificação de Suposições para o Teste t: Normalidade e Homogeneidade de Variâncias\n\nAo aplicar o *teste t* para comparação de médias entre dois grupos independentes, é fundamental verificar se os dados atendem às suposições básicas desse teste paramétrico. Essas suposições incluem:\n\n-   **Distribuição normal dos dados em cada grupo**\n\n-   **Homogeneidade das variâncias entre os grupos**\n\nO não atendimento dessas condições pode invalidar os resultados do teste ou exigir ajustes na sua aplicação.\n\n#### Teste de Normalidade: `shapiro.test()`\n\nA normalidade dos dados foi avaliada para cada grupo separadamente com o **teste de Shapiro-Wilk**, por meio da função `shapiro.test()`:\n\nEsse teste verifica se os dados seguem uma **distribuição normal**. A hipótese nula (H₀) é de que os dados são normalmente distribuídos.\n\n-   Se o **valor de p \\> 0,05**, não se rejeita H₀ → os dados são considerados normalmente distribuídos;\n\n-   Se o **valor de p \\< 0,05**, rejeita-se H₀ → os dados não seguem distribuição normal.\n\nAlém do teste, foram gerados histogramas para visualização da distribuição:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Testando a normalidade dos dados\nshapiro.test(Mg2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  control\nW = 0.93886, p-value = 0.5404\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(Mg2)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(control)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n:::\n\n\n\n\nOs histogramas ajudam a identificar visualmente desvios da normalidade, como assimetrias ou presença de outliers.\n\n**Análise visual da premissa de normalidade**: A análise visual da premissa de normalidade é realizada por qqplot (QQ-Plot), que permite verificar se uma amostra segue uma distribuição gaussiana. Podemos simplesmente fazer usando as funções qqnorm() e qqline() para cada umas das variáveis analisadas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm (Mg2)\nqqline(Mg2)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(control)\nqqline(control)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Teste de Homogeneidade de Variâncias: `var.test()`\n\nPara verificar se as variâncias dos dois grupos são semelhantes (homogêneas), utilizou-se o **teste de F** com a função `var.test()`:\n\nA hipótese nula (H₀) nesse teste é de que as variâncias dos dois grupos são iguais.\n\n-   Se o **valor de p \\> 0,05**, considera-se que as variâncias são homogêneas.\n\n-   Se o **valor de p \\< 0,05**, as variâncias são diferentes (heterocedásticas).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Testando a homogeneidade das variâncias\nvar.test(dat_mg2$Mg2,\n         dat_mg2$control) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  dat_mg2$Mg2 and dat_mg2$control\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n```\n\n\n:::\n:::\n\n\n\n\n#### Ajuste do Teste t com base nas variâncias\n\nSe o teste indicar variâncias homogêneas, pode-se aplicar o teste t com o argumento `var.equal = TRUE` (padrão).\\\nNo entanto, se for detectada heterogeneidade de variâncias, o teste t deve ser ajustado com:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_results <- t.test(control, Mg2, var.equal = FALSE)\n# O parâmetro var.equal = FALSE ativa a correção de Welch, que ajusta os graus de liberdade do teste, tornando-o mais robusto quando as variâncias são diferentes.\n```\n:::\n\n\n\n\n### Teste T para amostras dependentes\n\n**Exemplo:** Foi realizado um experimento com o objetivo de verificar o impacto do uso de uma escala na acurácia e precisão de estimativas visuais de severidade feitas por avaliadores. A hipótese testada foi de que o uso de uma escala diagramática auxilia na obtenção de estimativas mais acuradas em comparação com avaliações feitas sem esse recurso. Dez avaliadores foram selecionados aleatoriamente, e cada um realizou duas avaliações. Foram coletadas cinco variáveis relacionadas à concordância das estimativas. Como as medições foram repetidas para os mesmos avaliadores em momentos distintos, tratam-se de amostras dependentes.\n\n#### Comparando Dois Grupos (teste t pareado)\n\nAqui, os dados são importados diretamente de uma planilha online no Google Sheets com o pacote `gsheet`. A planilha contém escores de acurácia medidos antes e depois de uma intervenção (avaliados como `Unaided` e `Aided1`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#importação dos dados\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")\nhead(escala)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  <chr>      <chr>    <dbl>    <dbl>      <dbl>            <dbl>          <dbl>\n1 Unaided    A         0.81     0.83       0.98             1.19           0.11\n2 Unaided    B         0.72     0.73       0.99             0.92          -0.11\n3 Unaided    C         0.4      0.71       0.78             1.16           0.73\n4 Unaided    D         0.82     0.82       1                0.95          -0.01\n5 Unaided    E         0.75     0.75       0.99             1.1            0.07\n6 Unaided    F         0.45     0.75       0.92             0.8            0.34\n```\n\n\n:::\n:::\n\n\n\n\n### Teste t pareado\n\nEsse teste verifica se houve diferença significativa entre os dois momentos de avaliação (antes e depois da ajuda), utilizando o `t_test()` do pacote `rstatix`.\n\nA opção `paired = TRUE` indica que são as mesmas pessoas avaliadas duas vezes, e `var.equal = FALSE` corrige o teste caso as variâncias sejam diferentes (teste de Welch).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- t_test(acuracia ~ assessment,\n       data = escala,\n       paired = TRUE,\n       var.equal = FALSE)\ntest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  .y.      group1 group2     n1    n2 statistic    df       p\n* <chr>    <chr>  <chr>   <int> <int>     <dbl> <dbl>   <dbl>\n1 acuracia Aided1 Unaided    10    10      4.42     9 0.00167\n```\n\n\n:::\n:::\n\n\n\n\n**Visualização:** É gerado um boxplot para visualizar a distribuição das acurácias por tipo de avaliação (`Unaided` vs `Aided1`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala |> \n  ggplot(aes(assessment, acuracia))+\n         geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Testando suposições\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunaided <- escala |>\n  filter(assessment == \"Unaided\") |>\n  pull(acuracia)\n\naided <- escala |>\n  filter(assessment == \"Aided\") |>\n  pull(acuracia)\n\n\nif (length(unaided) >= 2 && length(aided) >= 2) {\n  var.test(unaided, aided) # Homogeneidade de variâncias\n} else {\n  message(\"Número de observações insuficiente em um dos grupos.\")\n}\n\nhist(unaided)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\nif (length(aided) > 1) {\n  hist(aided)\n} else {\n  message(\"Não há dados suficientes para gerar o histograma de 'aided'.\")\n}     # Visualização da distribuição\n\nshapiro.test(unaided) # Normalidade\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  unaided\nW = 0.7748, p-value = 0.007155\n```\n\n\n:::\n:::\n\n\n\n\nVerifica se os dados atendem às premissas do teste t (normalidade e variâncias iguais).\n\n-   Se **normalidade** falha → usar teste **não paramétrico**.\n\n-   Se **variâncias são diferentes**, continuar com `var.equal = FALSE`.\n\n### **Teste não paramétrico equivalente (Wilcoxon):**\n\nUm teste não paramétrico não faz nenhuma suposição sobre a distribuição da população ou tamanho da amostra. O `Wilcox.test` é o teste para dados não paramétricos equivalente ao *teste t* para dados paramétricos. o teste de `Wilcoxon` é usado para testar se as medianas das amostras são iguais nos casos em que a suposição de normalidade não é satisfeita ou quando não for possível checar essa suposição.\n\nUsar Wilcoxon se os dados não forem normais. O primeiro é o equivalente ao t pareado, o segundo ao t para amostras independentes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wilcox.test(unaided, aided)             # Wilcoxon pareado\n# wilcox.test(unaided, aided, paired = FALSE) # Mann-Whitney (independente)\n```\n:::\n\n\n\n\n# **Transformação de dados no R Studio**\n\nAntes de iniciar uma análise estatística no R, pode ser necessário transformar os dados, dependendo de suas características e das exigências do método analítico escolhido. Essas transformações são úteis para adequar os dados aos pressupostos da análise estatística, como a normalidade da distribuição e a homogeneidade das variâncias.\n\nAntes de realizar transformações, precisamos entender a natureza dos dados. Vamos trabalhar com o conjunto de dados mofo, presente na planilha dados-diversos.\n\n### Importando o conjunto de dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\n\nmofo <- read_excel(\"dados.xlsx\", \"mofo\")\n```\n:::\n\n\n\n\n#### Visualização dos dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo |>\n  ggplot(aes(treat, inc)) +\n  facet_wrap(~study) +\n  geom_point(color = \"#1A8C8C\") +\n  labs(\n    x = \"Tratamento\",\n    y = \"Incidência\"\n  )\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n\nHistograma para visualizar a incidência e outro para visualizar os dados de escleródio.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninc <- mofo |>\n  ggplot(aes(inc))+\n  geom_histogram(fill = \"#1A8C8C\")\n#Para o scleródio\nmofo |>\n    ggplot(aes(scl))+\n    geom_histogram(fill = \"#1A8C8C\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\nBoxplot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscl <- mofo |>\n  ggplot(aes(scl))+\n  geom_boxplot()\nlibrary(patchwork)\ninc + scl\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\nPara achar a média podemos usar as funções \\$, mean+conjunto ou summary.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo$scl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 2194 1663 1313 1177  753 1343 1519  516  643  400  643  921 1196 1331  756\n[16]  338  581  588  231  925  119  394  206  275  131  588 5013 3619 2325 2588\n[31] 3969 1556 3175 1763 2894  350  419  644 2850 6216 2888 2272 2868 2412 2372\n[46] 3424 1744 1456 1732 1080 1592 3268\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(mofo$scl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1639.096\n```\n\n\n:::\n:::\n\n\n\n\nOs dados podem ser transformados de diferentes formas, sendo as mais comuns log e raiz quadrada. \n\n## **Transformação logarítmica**\n\nA transformação logarítmica é uma técnica comum utilizada na análise de dados para lidar com variáveis que apresentam distribuição assimétrica ou variância heterogênea. Ela pode ajudar a estabilizar a variância, aproximar os dados de uma distribuição normal e melhorar a interpretação dos resultados estatísticos.\n\nNo RStudio, a transformação logarítmica pode ser aplicada facilmente com funções como `log()`, `log10()` (logaritmo na base 10) ou `log2()` (logaritmo na base 2), dependendo do contexto da análise. Podemos realizar essa transformação com o uso da função `mutate`. Através da função `mutate()` realizamos a criação/adição de uma nova variável (ou novas variaveis), que são funções de variáveis existentes, e também criamos/modificamos colunas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo2 <- mofo |>\n  mutate (scl2 = log(scl))\n  mofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 52 × 6\n   study treat   inc   scl   yld  scl2\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1     1    76  2194  2265  7.69\n 2     1     2    53  1663  2618  7.42\n 3     1     3    42  1313  2554  7.18\n 4     1     4    37  1177  2632  7.07\n 5     1     5    29   753  2820  6.62\n 6     1     6    42  1343  2799  7.20\n 7     1     7    55  1519  2503  7.33\n 8     1     8    40   516  2967  6.25\n 9     1     9    26   643  2965  6.47\n10     1    10    18   400  3088  5.99\n# ℹ 42 more rows\n```\n\n\n:::\n:::\n\n\n\n\n### Visualizar os dados tranformados\n\nHistograma\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo2 |>\n  ggplot(aes(scl2)) +\n  geom_histogram(bins = 10, fill = \"#1A8C8C\", color = \"black\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n\n\n## Transformação em raiz quadrada\n\nA transformação em raiz quadrada é uma técnica estatística utilizada para corrigir assimetrias nos dados e estabilizar a variância, especialmente quando os dados representam contagens ou variáveis discretas com distribuição assimétrica.\n\nEsse tipo de transformação é útil quando os dados apresentam variância crescente com a média, o que viola pressupostos importantes de muitos testes estatísticos, como a ANOVA e o teste t.\n\nNo RStudio, a transformação em raiz quadrada pode ser feita com a função `sqrt()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo2 <- mofo |>\n  mutate (scl2 = sqrt(scl))\n  mofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 52 × 6\n   study treat   inc   scl   yld  scl2\n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1     1    76  2194  2265  46.8\n 2     1     2    53  1663  2618  40.8\n 3     1     3    42  1313  2554  36.2\n 4     1     4    37  1177  2632  34.3\n 5     1     5    29   753  2820  27.4\n 6     1     6    42  1343  2799  36.6\n 7     1     7    55  1519  2503  39.0\n 8     1     8    40   516  2967  22.7\n 9     1     9    26   643  2965  25.4\n10     1    10    18   400  3088  20  \n# ℹ 42 more rows\n```\n\n\n:::\n:::\n\n\n\n\n### Visualizar os dados tranformados\n\nHistograma\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  mofo2 |>\n    ggplot(aes(scl2))+\n    geom_histogram(bins = 10, fill = \"#1A8C8C\", color = \"black\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n\n## **Transformação de dados Box-Cox**\n\nA transformação de Box-Cox é uma técnica estatística utilizada para estabilizar a variância e aproximar os dados de uma distribuição normal. Diferente de outras transformações fixas, como log ou raiz quadrada, a Box-Cox aplica uma família de transformações parametrizadas, permitindo encontrar automaticamente o melhor ajuste aos pressupostos dos modelos estatísticos.\n\nEla é especialmente útil quando não se sabe previamente qual transformação aplicar, pois estima um parâmetro lambda (λ) que define a forma ideal da transformação.\n\nA transformação de Box-Cox é definida pela seguinte equação: y(lambda) = (x\\^lambda - 1) / lambda\n\nNessa equação, “x” representa a variável original, “y(lambda)” representa a variável transformada para um determinado valor de lambda e “lambda” é o parâmetro de transformação que varia de -∞ a +∞. O valor de lambda determina o tipo de transformação aplicada: Se lambda = 0, a transformação de Box-Cox é equivalente ao logaritmo natural (ln). Se lambda = 1, a transformação de Box-Cox é equivalente à transformação linear (sem transformação). Se lambda \\< 0, é aplicada uma transformação inversa.\n\nA transformação Box-Cox pode ser aplicada usando a função `boxcox()` do pacote `MASS.`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\n```\n:::\n\n\n\n\n**Exemplo:** *InsectSprays*, do próprio R. A função `boxcox()` pode ser utilizada para calcular a transformação de Box-Cox e identificar o valor de lambda ótimo para uma determinada variável. Essa função retorna uma lista de resultados, incluindo o valor de lambda ótimo e gráficos de diagnóstico.\n\n### Importando dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninsects <- InsectSprays\n\nb <- boxcox(lm(insects$count+0.1 ~1))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda <- b$x[which.max(b$y)]\nlambda\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4242424\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninsects$count2 <- (insects$count ^ lambda - 1) / lambda\n\nhist(insects$count, \n     col = \"#1A8C8C\",        # cor do histograma\n     main = \"Histograma de Count Transformado\", \n     xlab = \"Contagem Transformada\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(insects$count2,\n     col = \"#1A8C8C\",\n     main = \"Histograma de Count2 Transformado\", \n     xlab = \"Contagem Transformada\"\n)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n\n# **ANOVA** (Análise de Variância)\n\nÉ um teste estatístico utilizado para comparar as médias de três ou mais grupos e verificar se há diferenças estatisticamente significativas entre elas. Ao invés de comparar pares de médias individualmente, como no teste t, a ANOVA avalia simultaneamente a variabilidade entre os grupos e dentro dos grupos.\n\nA ANOVA usa o teste F para testar a hipótese nula de que as médias populacionais são iguais contra a hipótese alternativa de que pelo menos uma média é diferente das demais.\n\n## **Anova com 1 fator (***One-way Anova*)\n\nÉ uma técnica estatística utilizada para comparar as médias de três ou mais grupos que diferem em relação a um único fator (ou variável independente). Esse fator pode representar, por exemplo, diferentes tratamentos, cultivares, doses de um produto ou condições experimentais.\n\nO objetivo é verificar se há diferença significativa entre as médias dos grupos. A hipótese nula assume que todas as médias são iguais, enquanto a hipótese alternativa indica que pelo menos uma delas é diferente.\n\n**Exemplo:** Experimento com um fator e em delineamento inteiramente casualizado (DIC) para comparar o crescimento micelial de diferentes espécies de um fungo fitopatogênico. A resposta a ser estudada é a TCM = taxa de crescimento micelial.\n\n### Importando o conjunto de dados:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nmicelial <- read_excel(\"dados.xlsx\", \"micelial\")\nhead(micelial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  especie   rep   tcm\n  <chr>   <dbl> <dbl>\n1 Fasi        1  1.5 \n2 Fasi        2  1.59\n3 Fasi        3  1.52\n4 Fasi        4  1.52\n5 Fasi        5  1.6 \n6 Fasi        6  1.7 \n```\n\n\n:::\n:::\n\n\n\n\n### Carregando pacotes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\n```\n:::\n\n\n\n\n### **Visualização dos dados**:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmicelial |>\n  ggplot(aes(x = especie, y = tcm)) +\n  geom_boxplot(utlier.color = NA, fill = \"#1A8C8C\", color = \"black\") +\n   geom_jitter(width = 0.1)+\n  labs(\n    x = \"Espécie Fúngica\",\n    y = \"Taxa de Crescimento Micelial\"\n  )\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n\n\n### **Modelo usando `aov()`**\n\nPara verificar os dados usando anova, um novo modelo para atribuir a função `aov()` contendo os argumentos tratamento em função da variável resposta deve ser criado (ex.: tcm \\~ espécie), o banco de dados referido deve ser enunciado após o argumento separado por vírgula seguido do nome data = nome do conjunto de dados (ex.: micelial). Depois disso, pede um quadro de resumo do novo modelo criado.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov1 <- aov(tcm ~ especie, data = micelial)\nsummary(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nespecie      4 1.4696  0.3674   19.63 2.03e-07 ***\nResiduals   25 0.4679  0.0187                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naov2 <- lm(tcm ~ especie, data = micelial) # Outra forma de fazer a ANOVA\naov2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nCoefficients:\n(Intercept)  especieFaus  especieFcor  especieFgra  especieFmer  \n      1.572       -0.335       -0.250       -0.660       -0.145  \n```\n\n\n:::\n:::\n\n\n\n\n#### **Testando as premissas**\n\n##### **Testes de Normalidade e Homocedasticidade**\n\n**Teste de Normalidade**\n\nA normalidade dos dados é uma condição importante para muitos testes estatísticos. Ela garante que os resultados das análises, como ANOVA e teste t, sejam confiáveis, pois esses métodos assumem que os dados vêm de uma população com distribuição normal.\n\n**Teste de Homocedasticidade**\n\nNa ANOVA, é necessário que os grupos comparados tenham variâncias semelhantes. Essa condição é chamada de homocedasticidade. Se as variâncias forem muito diferentes (heterocedasticidade), os resultados do teste F podem ser comprometidos.\n\nPara testar as premissas, é necessário instalar e carregar o pacote `performance` e o pacote `DHARMa`.\n\nO pacote `performance` permite checar as premissas `(check_)`, já o pacote `DHARMA` (*Distributed Hierarchical Accumulation of Residuals for Generalized Linear Models in R*) é para visualizar os dados pelo diagnóstico do resíduo. O pacote `DHARMa` permite faz uma comparação dos resíduos simulados, que são gerados pelo pacote, com os resíduos observados e ver graficamente quando a distribuição dos dados não é normal e/ou quando há variação heterocedástica.\n\nApós isso, deve-se fazer o teste de normalidade dos resíduos com a interação entre a anova e os resíduos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_heteroscedasticity(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.880).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.878).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nhist (aov1$residuals) #Ou hist(residuals(aov1))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Mostra a distribuição visual dos resíduos.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(aov1$residuals)\nqqline(aov1$residuals)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simulateResiduals(aov1))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(aov1$residuals) #Ou shapiro.test(residuals(aov1)) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  aov1$residuals\nW = 0.9821, p-value = 0.8782\n```\n\n\n:::\n:::\n\n\n\n\nO teste verifica a seguinte hipótese:\n\n-   **Hipótese nula (H₀)**: Os dados seguem distribuição normal;\n\n-   **Hipótese alternativa (H₁)**: Os dados não seguem distribuição normal.\n\nComparamos o p-valor com um nível de significância comum, geralmente **α = 0,05**:\n\n**p-valor = 0,8782 \\> 0,05** → Não rejeitamos a hipótese nula\n\nHomogeneidade de variâncias:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Bartlett – mais sensível a desvios da normalidade\nbartlett.test(tcm ~ especie, data = micelial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Teste de Levene – mais robusto à violação da normalidade\nlibrary(car)\nleveneTest(tcm ~ especie, data = micelial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  4  1.7563 0.1693\n      25               \n```\n\n\n:::\n:::\n\n\n\n\n##### Interpretação dos Resultados:\n\n-   **p-valor \\> 0,05** → Não há evidência de variâncias diferentes → Premissa atendida.\n\n-   **p-valor \\< 0,05** → As variâncias são significativamente diferentes → Premissa violada.\n\n#### Comparações múltiplas e médias ajustadas\n\n**Pacote “emmeans”**\n\n(“*estimated marginal means*”, ou médias marginais estimadas) é usado para realizar testes de comparação de médias entre grupos, ajustando para outros fatores importantes que podem influenciar as médias. O pacote é particularmente útil em modelos lineares generalizados (GLM).\n\n`emmeans(...)`: calcula as médias ajustadas (médias marginais) para cada grupo de `especie` com base no modelo.\n\nImportante para comparações entre grupos quando há mais de 2 níveis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nm <- emmeans(aov2, ~ especie)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL\n Fasi     1.572 0.0559 25    1.457     1.69\n Faus     1.237 0.0559 25    1.122     1.35\n Fcor     1.322 0.0559 25    1.207     1.44\n Fgra     0.912 0.0559 25    0.797     1.03\n Fmer     1.427 0.0559 25    1.312     1.54\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\n**Testes post-hoc (comparações entre grupos)**\n\n**Pacote “multcomp” -** `multcomp`: para fazer comparações múltiplas entre grupos.\n\nTestes simultâneos e intervalos de confiança para hipóteses lineares gerais em modelos paramétricos, incluindo efeitos lineares, lineares generalizados, lineares mistos e modelos de sobrevivência.\n\n**Pacote “multcompView” -** `multcompView`: para gerar **letras compactas**, indicando quais grupos são diferentes.\n\nConverte um vetor lógico ou um vetor de valores-*p* ou uma matriz de correlação, diferença ou distância em uma exibição identificando os pares para os quais as diferenças não foram significativamente diferentes.\n\n**Cld -** Extrai e exibe informações sobre todas as comparações pareadas de médias de mínimos quadrados.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(multcomp)\nlibrary(multcompView)\n\ncld(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(m) #Mostra os testes pareados (comparação entre pares de grupos).\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast    estimate    SE df t.ratio p.value\n Fasi - Faus    0.335 0.079 25   4.241  0.0023\n Fasi - Fcor    0.250 0.079 25   3.165  0.0302\n Fasi - Fgra    0.660 0.079 25   8.356  <.0001\n Fasi - Fmer    0.145 0.079 25   1.836  0.3765\n Faus - Fcor   -0.085 0.079 25  -1.076  0.8169\n Faus - Fgra    0.325 0.079 25   4.115  0.0031\n Faus - Fmer   -0.190 0.079 25  -2.405  0.1469\n Fcor - Fgra    0.410 0.079 25   5.191  0.0002\n Fcor - Fmer   -0.105 0.079 25  -1.329  0.6761\n Fgra - Fmer   -0.515 0.079 25  -6.520  <.0001\n\nP value adjustment: tukey method for comparing a family of 5 estimates \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npwpm(m) #Exibe uma matriz com as médias na diagonal e comparações entre os grupos fora dela.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        Fasi    Faus    Fcor    Fgra    Fmer\nFasi [1.572]  0.0023  0.0302  <.0001  0.3765\nFaus   0.335 [1.237]  0.8169  0.0031  0.1469\nFcor   0.250  -0.085 [1.322]  0.0002  0.6761\nFgra   0.660   0.325   0.410 [0.912]  <.0001\nFmer   0.145  -0.190  -0.105  -0.515 [1.427]\n\nRow and column labels: especie\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n```\n\n\n:::\n:::\n\n\n\n\n## ANOVA fatorial (two-way ANOVA)\n\nA ANOVA fatorial é utilizada quando há duas ou mais variáveis independentes (fatores), cada uma com dois ou mais níveis. Ela é apropriada para experimentos fatoriais completos, nos quais todas as combinações possíveis entre os níveis dos fatores são testadas. Além de avaliar os efeitos individuais de cada fator, essa análise também permite verificar se existe interação entre os fatores, ou seja, se o efeito de um fator depende dos níveis do outro.\n\n### Importando o conjunto de dados:\n\nBanco de dados utilizado: fungicida-vaso (conjunto de dados do dados diversos). Objeto nomeado como fung_vaso.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\n\nfung_vaso <- read_xlsx(\"dados.xlsx\", sheet = \"fungicida_vaso\")\n```\n:::\n\n\n\n\n**`factor(dose)`**: converte a variável `dose` em fator (categórica);\n\n**`severity * 100`**: transforma a variável de severidade em percentual;\n\n**`geom_jitter()`**: mostra os pontos com leve deslocamento horizontal, evitando sobreposição;\n\n**`facet_wrap(~ treat)`**: separa os gráficos por tratamento (`treat`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfung_vaso |> \n  ggplot(aes(factor(dose), severity*100))+ #transformando dose em um fator e ##transformar para percentual *100\n  geom_jitter(width = 0.1)+\n  facet_wrap(~ treat)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-54-1.png){width=672}\n:::\n:::\n\n\n\n\n### Modelo linear com interação\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_anti <- lm(severity ~ treat * dose, data = fung_vaso)\nanova(m_anti)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(>F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n#### Checagem das premissas e visualização com DHARMa:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(m_anti))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-56-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Médias ajustadas com `emmeans`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedia_anti <- emmeans(m_anti, ~ treat | dose)\nmedia_anti\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789\n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL\n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\n#### Comparações múltiplas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(media_anti)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  1    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   2   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  1    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n##### Agora inverte: médias de doses dentro de tratamentos\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedia_anti <- emmeans(m_anti, ~ dose | treat)\nmedia_anti\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.2921 0.0273 16  0.23420   0.3500\n  2.0 0.0501 0.0273 16 -0.00781   0.1080\n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.0210 0.0273 16 -0.03690   0.0789\n  2.0 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(media_anti)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n#### Coeficiente de variação\n\nEssa função do pacote `agricolae` calcula o coeficiente de variação (CV%) do modelo.\n\nAjuda a avaliar a precisão experimental. Valores abaixo de 20% geralmente são considerados bons (mas depende do contexto).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(agricolae)\ncv.model(m_anti)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 63.7165\n```\n\n\n:::\n:::\n\n\n\n\n#### E se não houver interação significativa?\n\nMostra os efeitos **individuais de dose e tratamento**, ignorando a interação.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n\np1 <- fung_vaso |> \n  ggplot(aes(factor(dose), severity*100)) + \n  geom_jitter(width = 0.1)\np2 <- fung_vaso |> \n  ggplot(aes(treat, severity*100)) + \n  geom_jitter(width = 0.1)\np1 + p2\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-61-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Visualização da interação\n\n-   Gera um gráfico de interação;\n\n-   Se as linhas forem paralelas, não há interação;\n\n-   Se forem cruzadas ou afastadas, pode indicar interação.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteraction.plot(fung_vaso$treat, fung_vaso$dose, fung_vaso$severity)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-62-1.png){width=672}\n:::\n:::\n\n\n\n\nTabela\n\n|          | 0.5     | 0.2    |\n|----------|---------|--------|\n| LI       | 29.2 Aa | 5.0 Ab |\n| TEBU     | 2.1 Ba  | 2.0 Aa |\n| cv = 63% |         |        |\n\n### Exemplo:\n\n#### Pacote `epifitter` e dados:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"epifitter\")\nlibrary(epifitter)\noidio <- PowderyMildew\n```\n:::\n\n\n\n\n#### Visualização dos dados filtrados\n\nFiltra apenas 3 tipos de irrigação.\n\n`sev*100`: transforma a severidade (que vai de 0 a 1) para percentual (0–100%).\n\n`facet_grid(moisture ~ irrigation_type)`: cria um painel com um gráfico para cada combinação de `moisture` (umidade) e `irrigation_type` (tipo de irrigação).\n\nO gráfico mostra como a doença evolui ao longo do tempo (`time`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noidio |> \n  filter(irrigation_type %in% c(\"MS\", \"MS above canopy\", \"Overhead\")) |> \n  ggplot(aes(time, sev*100)) + \n  geom_jitter(width = 0.1) +\n  facet_grid(moisture ~ irrigation_type)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-64-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Cálculo da AUDPC (Área Abaixo da Curva de Progresso da Doença)\n\n`group_by(...)` agrupa os dados por tratamento (irrigação, umidade e bloco);\n\n`AUDPC(...)` calcula a área abaixo da curva para cada grupo;\n\nA AUDPC resume a intensidade da doença ao longo do tempo.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(epifitter)\n\noidio3 <- oidio |>\n  group_by(irrigation_type, moisture, block) |>\n  summarise(AUDPC = AUDPC(time, sev), .groups = \"drop\")\n```\n:::\n\n\n\n\n#### Visualizando a AUDPC\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noidio3 |> \n  filter(irrigation_type %in% c(\"MS\", \"MS above canopy\", \"Overhead\")) |>\n  ggplot(aes(irrigation_type, AUDPC, color = moisture)) +\n  geom_point(width = 0.1) +\n  scale_y_continuous(limits = c(0, 20))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-66-1.png){width=672}\n:::\n:::\n\n\n\n\n#### ANOVA fatorial (efeito da irrigação e umidade na AUDPC)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noidio4 <- oidio3 |> \n  filter(irrigation_type %in% c(\"MS\", \"MS above canopy\", \"Overhead\"))\n\nanov_oidio <- lm(AUDPC ~ irrigation_type * moisture, data = oidio4)\nanova(anov_oidio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: AUDPC\n                         Df  Sum Sq Mean Sq F value    Pr(>F)    \nirrigation_type           2 134.341  67.170 451.721 5.073e-12 ***\nmoisture                  1   6.680   6.680  44.924 2.188e-05 ***\nirrigation_type:moisture  2   5.104   2.552  17.162 0.0003022 ***\nResiduals                12   1.784   0.149                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n#### Diagnóstico do modelo\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simulateResiduals(anov_oidio))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-68-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Médias ajustadas com `emmeans`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_oidio <- emmeans(anov_oidio, ~ irrigation_type | moisture)\nmedias_oidio\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmoisture = High moisture:\n irrigation_type emmean    SE df lower.CL upper.CL\n MS                8.52 0.223 12     8.04     9.01\n MS above canopy   3.99 0.223 12     3.51     4.48\n Overhead          3.68 0.223 12     3.20     4.17\n\nmoisture = Moderate moisture:\n irrigation_type emmean    SE df lower.CL upper.CL\n MS               11.18 0.223 12    10.70    11.67\n MS above canopy   4.86 0.223 12     4.37     5.34\n Overhead          3.81 0.223 12     3.33     4.30\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_oidio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmoisture = High moisture:\n irrigation_type emmean    SE df lower.CL upper.CL .group\n Overhead          3.68 0.223 12     3.20     4.17  1    \n MS above canopy   3.99 0.223 12     3.51     4.48  1    \n MS                8.52 0.223 12     8.04     9.01   2   \n\nmoisture = Moderate moisture:\n irrigation_type emmean    SE df lower.CL upper.CL .group\n Overhead          3.81 0.223 12     3.33     4.30  1    \n MS above canopy   4.86 0.223 12     4.37     5.34   2   \n MS               11.18 0.223 12    10.70    11.67    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\nAgora, inverte: mostra as médias de umidade dentro de cada tipo de irrigação.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_oidio2 <- emmeans(anov_oidio, ~ moisture | irrigation_type)\nmedias_oidio2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nirrigation_type = MS:\n moisture          emmean    SE df lower.CL upper.CL\n High moisture       8.52 0.223 12     8.04     9.01\n Moderate moisture  11.18 0.223 12    10.70    11.67\n\nirrigation_type = MS above canopy:\n moisture          emmean    SE df lower.CL upper.CL\n High moisture       3.99 0.223 12     3.51     4.48\n Moderate moisture   4.86 0.223 12     4.37     5.34\n\nirrigation_type = Overhead:\n moisture          emmean    SE df lower.CL upper.CL\n High moisture       3.68 0.223 12     3.20     4.17\n Moderate moisture   3.81 0.223 12     3.33     4.30\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\ncld(medias_oidio2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nirrigation_type = MS:\n moisture          emmean    SE df lower.CL upper.CL .group\n High moisture       8.52 0.223 12     8.04     9.01  1    \n Moderate moisture  11.18 0.223 12    10.70    11.67   2   \n\nirrigation_type = MS above canopy:\n moisture          emmean    SE df lower.CL upper.CL .group\n High moisture       3.99 0.223 12     3.51     4.48  1    \n Moderate moisture   4.86 0.223 12     4.37     5.34   2   \n\nirrigation_type = Overhead:\n moisture          emmean    SE df lower.CL upper.CL .group\n High moisture       3.68 0.223 12     3.20     4.17  1    \n Moderate moisture   3.81 0.223 12     3.33     4.30  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n#### Coeficiente de variação do modelo\n\nIndica a precisão do experimento - valores menores geralmente indicam maior confiabilidade\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncv.model(anov_oidio)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.418205\n```\n\n\n:::\n:::\n\n\n\n\nTabela\n\n|           | H. moisture | M. moisture |\n|-----------|-------------|-------------|\n| MS        | 8.52 Aa     | 11.18 Ab    |\n| MS Ac.    | 3.99 Ba     | 4.86 Bb     |\n| Overhead  | 3.68 Ba     | 3.81 Ca     |\n| CV = 6.41 |             |             |\n\n## Anova Fatorial - 3 Fatores\n\n### Exemplo:\n\nDados sobre a interação entre tipo de armazenamento e umidade.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho <- read_excel(\"dados.xlsx\", \"armazena\")\nmilho |>\n  filter(tempo ==8) |>\n  ggplot(aes(factor(tipo), peso_mil,\n             color = factor(umidade)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~ umidade)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-72-1.png){width=672}\n:::\n:::\n\n\n\n\nTestar a interação entre o tipo de armazenamento e o tempo 8\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho2 <- milho |>\n  filter(tempo ==8)\n\nm2 <- aov(peso_mil ~ factor(tipo)*factor(umidade),\n          data = milho2)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                             Df Sum Sq Mean Sq F value   Pr(>F)    \nfactor(tipo)                  1  11215   11215  2375.8 3.64e-15 ***\nfactor(umidade)               2  42814   21407  4534.8  < 2e-16 ***\nfactor(tipo):factor(umidade)  2   2329    1165   246.7 1.79e-10 ***\nResiduals                    12     57       5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nTestanto tipo de inoculação na incidencia de *Fusarium* sp. em milho\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho3 <- read_excel(\"dados.xlsx\", \"milho\")\n\nm4 <- aov(yield ~hybrid*method,\n          data = milho3)\nsummary(m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid         5 105876446 21175289   8.312 2.66e-05 ***\nmethod         1     42951    42951   0.017    0.897    \nhybrid:method  5  10619453  2123891   0.834    0.534    \nResiduals     36  91709593  2547489                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nChecagem das premissas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.928).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simulateResiduals(m4))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-76-1.png){width=672}\n:::\n:::\n\n\n\n\nMédias ajustadas com `emmeans`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_m4 <- emmeans(m4, ~ hybrid)\nmedias_m4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 564 36     9453    11742\n 30F53 YH   9309 564 36     8165    10454\n 30K64     11018 564 36     9874    12162\n 30S31H     8652 564 36     7507     9796\n 30S31YH    8056 564 36     6912     9201\n BG7049H   12402 564 36    11257    13546\n\nResults are averaged over the levels of: method \nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(medias_m4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 564 36     6912     9201  1    \n 30S31H     8652 564 36     7507     9796  12   \n 30F53 YH   9309 564 36     8165    10454  12   \n 30F53 HX  10598 564 36     9453    11742   23  \n 30K64     11018 564 36     9874    12162   23  \n BG7049H   12402 564 36    11257    13546    3  \n\nResults are averaged over the levels of: method \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\nCaso a interação não dê sifnificativa, tira a interação e deixa só o fator que teve significancia (isola o fator)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm5 <- aov(yield ~hybrid, data = milho3)\nsummary(m5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid       5 105876446 21175289   8.688 1.02e-05 ***\nResiduals   42 102371996  2437428                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm4 <- aov(yield ~hybrid,\n          data = milho3)\nsummary(m5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df    Sum Sq  Mean Sq F value   Pr(>F)    \nhybrid       5 105876446 21175289   8.688 1.02e-05 ***\nResiduals   42 102371996  2437428                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(m5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.763).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmedias_m5 <- emmeans(m5, ~hybrid)\nmedias_m5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n hybrid   emmean  SE df lower.CL upper.CL\n 30F53 HX  10598 552 42     9484    11712\n 30F53 YH   9309 552 42     8195    10423\n 30K64     11018 552 42     9904    12132\n 30S31H     8652 552 42     7538     9765\n 30S31YH    8056 552 42     6942     9170\n BG7049H   12402 552 42    11288    13516\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(medias_m5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n hybrid   emmean  SE df lower.CL upper.CL .group\n 30S31YH    8056 552 42     6942     9170  1    \n 30S31H     8652 552 42     7538     9765  12   \n 30F53 YH   9309 552 42     8195    10423  123  \n 30F53 HX  10598 552 42     9484    11712   234 \n 30K64     11018 552 42     9904    12132    34 \n BG7049H   12402 552 42    11288    13516     4 \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npwpm(medias_m5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         30F53 HX 30F53 YH   30K64  30S31H 30S31YH BG7049H\n30F53 HX  [10598]   0.5709  0.9942  0.1494  0.0254  0.2125\n30F53 YH     1288  [ 9309]  0.2643  0.9576  0.5999  0.0036\n30K64        -420    -1709 [11018]  0.0447  0.0059  0.4938\n30S31H       1946      658    2366 [ 8652]  0.9723  0.0003\n30S31YH      2541     1253    2962     595 [ 8056]  <.0001\nBG7049H     -1804    -3092   -1384   -3750   -4345 [12402]\n\nRow and column labels: hybrid\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n```\n\n\n:::\n:::\n\n\n\n\n## **ANOVA com bloco**\n\n### **Anova com bloco - Delineamento em Blocos Casualizado (DBC)**\n\nO (DBC) envolve os três princípios da experimentação: repetição, casualização e controle local. Neste caso, as condições locais não são homogêneas e podem ter efeito significativo sobre os tratamentos.\n\n#### Carregando pacotes e dados\n\nUsando o conjunto de dados fungicida_campo\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(Hmisc)\nfung_campo <- read_xlsx(\"dados.xlsx\", sheet = \"fungicida_campo\")\n```\n:::\n\n\n\n\n#### Gráfico de produção por tratamento\n\n`mutate(TRAT = factor(TRAT))`: transforma os tratamentos (TRAT) em fatores para garantir que o `ggplot` os trate como categorias.\n\n`geom_jitter`: mostra os dados de cada parcela/bloco, deslocados horizontalmente para evitar sobreposição.\n\n`stat_summary(fun.data = \"mean_cl_boot\")`: adiciona médias com intervalos de confiança via bootstrap.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfung_campo |> \n  mutate(TRAT = factor(TRAT)) |> \n  ggplot(aes(TRAT, PROD)) +\n  geom_jitter(width = 0.2) +\n  stat_summary(fun.data = \"mean_cl_boot\", colour = \"red\", width = 0.3)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-86-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Convertendo variáveis em fatores\n\nAqui, você transforma `TRAT` e `BLOCO` explicitamente em **fatores**, pois o R trata números como contínuos por padrão.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfung_campo$TRAT <- factor(fung_campo$TRAT)\nfung_campo$BLOCO <- factor(fung_campo$BLOCO)\n```\n:::\n\n\n\n\n#### **Modelo Anova com bloco**\n\nANOVA com efeito de blocos e tratamentos:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_campo <- lm(PROD ~ BLOCO + TRAT, data = fung_campo)\nanova(anova_campo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value Pr(>F)  \nBLOCO      3  105716   35239  0.2172 0.8833  \nTRAT       7 2994142  427735  2.6369 0.0402 *\nResiduals 21 3406384  162209                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n#### Checagem das premissas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\nlibrary(DHARMa)\ncheck_normality(anova_campo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.542).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(anova_campo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.216).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nplot(simulateResiduals(anova_campo))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-90-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Estimativa e comparação das médias dos tratamentos\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans_campo <- emmeans(anova_campo, ~ TRAT)\nmeans_campo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4722     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4838     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(multcomp)\ncld(means_campo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  1    \n 2      4935 201 21     4516     5354  12   \n 8      5078 201 21     4659     5497  12   \n 3      5110 201 21     4691     5529  12   \n 5      5122 201 21     4703     5541  12   \n 7      5128 201 21     4709     5546  12   \n 4      5140 201 21     4722     5559  12   \n 6      5256 201 21     4838     5675   2   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(means_campo)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-93-1.png){width=672}\n:::\n\n```{.r .cell-code}\npwpp(means_campo)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-93-2.png){width=672}\n:::\n\n```{.r .cell-code}\npwpm(means_campo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2431  0.0793  0.0639  0.0728  0.0272  0.0699 0.0985\n2  -715.7  [4935]  0.9983  0.9953  0.9974  0.9429  0.9968 0.9995\n3  -890.5  -174.8  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.1  -205.4   -30.6  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.7  -187.0   -12.2    18.4  [5122]  0.9997  1.0000 1.0000\n6 -1037.1  -321.4  -146.6  -116.0  -134.4  [5256]  0.9998 0.9981\n7  -908.4  -192.7   -17.9    12.7    -5.7   128.7  [5128] 1.0000\n8  -859.0  -143.3    31.5    62.1    43.7   178.0    49.4 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n```\n\n\n:::\n:::\n\n\n\n\nAnálise da Severidade da Ferrugem (`FER`):\n\n#### ANOVA com transformação logarítmica\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_fer <- lm(log(FER) ~ BLOCO + TRAT, data = fung_campo)\nanova(anova_fer)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: log(FER)\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n#### Diagnóstico do modelo\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simulateResiduals(anova_fer))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-95-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Médias com back-transformation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans_fer <- emmeans(anova_fer, ~ TRAT, type = \"response\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(means_fer)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n TRAT response    SE df lower.CL upper.CL .group\n 6        2.98 0.292 21     2.43     3.65  1    \n 4        3.08 0.301 21     2.51     3.78  1    \n 5        3.24 0.317 21     2.64     3.97  1    \n 7        3.37 0.330 21     2.75     4.13  1    \n 8        3.48 0.341 21     2.84     4.27  1    \n 3        3.81 0.373 21     3.11     4.67  12   \n 2        5.68 0.556 21     4.63     6.96   2   \n 1       20.02 1.960 21    16.33    24.54    3  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 8 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(means_fer)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-97-1.png){width=672}\n:::\n\n```{.r .cell-code}\npwpp(means_fer)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-97-2.png){width=672}\n:::\n\n```{.r .cell-code}\npwpm(means_fer)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        1       2       3       4       5       6       7       8\n1 [20.02]  <.0001  <.0001  <.0001  <.0001  <.0001  <.0001  <.0001\n2   3.525 [ 5.68]  0.1252  0.0048  0.0110  0.0028  0.0204  0.0343\n3   5.259   1.492 [ 3.81]  0.7832  0.9335  0.6440  0.9843  0.9976\n4   6.500   1.844   1.236 [ 3.08]  0.9999  1.0000  0.9976  0.9842\n5   6.178   1.753   1.175   0.951 [ 3.24]  0.9984  1.0000  0.9994\n6   6.721   1.906   1.278   1.034   1.088 [ 2.98]  0.9842  0.9431\n7   5.945   1.686   1.130   0.915   0.962   0.885 [ 3.37]  1.0000\n8   5.750   1.631   1.093   0.885   0.931   0.856   0.967 [ 3.48]\n\nRow and column labels: TRAT\nUpper triangle: P values   null = 1  adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (ratio)   earlier vs. later\n```\n\n\n:::\n:::\n\n\n\n\n## **Delineamento em parcela subdividida (*Split-plot*)**\n\n### Importando o conjunto de dados:\n\nExemplo:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho <- read_excel(\"dados.xlsx\", \"milho\")\n```\n:::\n\n\n\n\n#### Visualizando os dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho |> \n  \n  ggplot(aes(hybrid, index, color = method))+\n  geom_jitter(width = 0.1)+\n coord_flip()\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-99-1.png){width=672}\n:::\n:::\n\n\n\n\n#### **Ajustando o modelo**:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov_milho_bloco <- aov(index ~ factor(block) + hybrid*method + \nError(factor(block)/hybrid/method), data = milho)\n\nsummary(aov_milho_bloco)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nError: factor(block)\n              Df Sum Sq Mean Sq\nfactor(block)  3  592.2   197.4\n\nError: factor(block):hybrid\n          Df Sum Sq Mean Sq F value Pr(>F)  \nhybrid     5  974.2  194.84    3.14 0.0389 *\nResiduals 15  930.9   62.06                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: factor(block):hybrid:method\n              Df Sum Sq Mean Sq F value Pr(>F)  \nmethod         1  79.61   79.61   4.726 0.0433 *\nhybrid:method  5 265.28   53.06   3.150 0.0324 *\nResiduals     18 303.18   16.84                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n#### **Checagem das premissas**\n\nEm parcelas subdivididas não é possível checar as premissas pelo check\\_, então usa lme4, para checar pelo modelo misto.\n\n##### **Pacote “lme4”**\n\nAjusta modelos de efeitos mistos lineares e lineares generalizados. Os modelos e seus componentes são representados usando classes e métodos S4.\n\n##### **Função “lmer”**\n\nGera um componente aleatório que é específico a cada indivíduo, de modo que podemos ter, para cada um, um intercepto e uma inclinação distintas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Matrix)\nlibrary(lme4)\nmilho$block <- as.factor(milho$block)\nmix2 <- lmer(index ~ block + hybrid*method + \n(1|block/hybrid), data =  milho)\n\nlibrary(car)\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(>Chisq)   \nblock          0.3192  3   0.956380   \nhybrid        15.6987  5   0.007759 **\nmethod         4.7262  1   0.029706 * \nhybrid:method 15.7498  5   0.007596 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.621).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n```\n\n\n:::\n:::\n\n\n\n\n#### Necessário transformar os dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho$block <- as.factor(milho$block)\nmix2 <- lmer(sqrt(index) ~ block + hybrid*method + (1|block/hybrid), data = milho)\nlibrary(car)\nAnova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(>Chisq)   \nblock          0.0764  3   0.994506   \nhybrid        15.4171  5   0.008721 **\nmethod         3.9239  1   0.047605 * \nhybrid:method 13.3025  5   0.020703 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n##### Checagem\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.422).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.970).\n```\n\n\n:::\n:::\n\n\n\n\n#### **Comparação de médias**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans_mix2 <- emmeans(mix2, ~hybrid | method)\nmeans_mix2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL\n 30F53 HX   5.00 1.17 5356     2.69     7.30\n 30F53 YH   4.95 1.17 5356     2.65     7.25\n 30K64      4.50 1.17 5356     2.20     6.81\n 30S31H     6.10 1.17 5356     3.79     8.40\n 30S31YH    5.63 1.17 5356     3.33     7.93\n BG7049H    4.40 1.17 5356     2.10     6.71\n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL\n 30F53 HX   4.94 1.17 5356     2.64     7.25\n 30F53 YH   5.10 1.17 5356     2.80     7.41\n 30K64      4.61 1.17 5356     2.31     6.91\n 30S31H     5.13 1.17 5356     2.83     7.43\n 30S31YH    5.14 1.17 5356     2.84     7.44\n BG7049H    4.37 1.17 5356     2.07     6.67\n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(means_mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    4.40 1.17 5356     2.10     6.71  1    \n 30K64      4.50 1.17 5356     2.20     6.81  1    \n 30F53 YH   4.95 1.17 5356     2.65     7.25  12   \n 30F53 HX   5.00 1.17 5356     2.69     7.30  12   \n 30S31YH    5.63 1.17 5356     3.33     7.93  12   \n 30S31H     6.10 1.17 5356     3.79     8.40   2   \n\nmethod = silk:\n hybrid   emmean   SE   df lower.CL upper.CL .group\n BG7049H    4.37 1.17 5356     2.07     6.67  1    \n 30K64      4.61 1.17 5356     2.31     6.91  1    \n 30F53 HX   4.94 1.17 5356     2.64     7.25  1    \n 30F53 YH   5.10 1.17 5356     2.80     7.41  1    \n 30S31H     5.13 1.17 5356     2.83     7.43  1    \n 30S31YH    5.14 1.17 5356     2.84     7.44  1    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n# **Teste Não Paramétrico**\n\nOs testes não paramétricos são métodos estatísticos que não exigem que os dados sigam uma distribuição específica, como a normal. Por isso, são úteis quando as suposições dos testes paramétricos não são atendidas. Eles trabalham com dados em forma de postos (ordens) ou categorias e são ideais para amostras pequenas, dados assimétricos ou com *outliers*.\n\n**Exemplo:** conjunto *InsectSprays:* efeito de inseticida na mortalidade de insetos. Dados no pacote `datasets` do R.\n\n### Carregando o conjunto de dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninsects <- tibble::as_tibble(InsectSprays) |>\n  dplyr::select(spray, count)\ninsects\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 72 × 2\n   spray count\n   <fct> <dbl>\n 1 A        10\n 2 A         7\n 3 A        20\n 4 A        14\n 5 A        14\n 6 A        12\n 7 A        10\n 8 A        23\n 9 A        17\n10 A        20\n# ℹ 62 more rows\n```\n\n\n:::\n:::\n\n\n\n\n### Análise visual dos dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\ninsects |>\n  ggplot(aes(spray, count)) +\n  geom_boxplot(fill = \"lightblue\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-110-1.png){width=672}\n:::\n:::\n\n\n\n\n## Teste - Modelo ANOVA\n\nQuando se analisa um conjunto de dados e esses dados apresentam-se como não paramétricos, deve-se trabalhar esses dados de uma forma diferente. Mas antes, deve-se comprovar por meio da anova e da checagem das premissas, que os dados realmente não são normais e homogêneos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov2 <- aov(count ~ spray, data = insects)\nsummary(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n### Checagem das premissas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Non-normality of residuals detected (p = 0.022).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n```\n\n\n:::\n:::\n\n\n\n\nA partir da checagem das premissas, observa-se que os dados não são normais e homogeneos.\n\n## **Alternativas para dados não paramétricos**\n\nQuando se tem dados não paramétricos, tem-se 3 alternativas:\n\n1.  Transformar os dados (Exemplo: raiz quadrada, log, Box cox);\n\n2.  Usar testes não paramétricos (*Kruskal-Wallis*);\n\n3.  Ou usar modelos lineares generalizados.\n\n### **1. Transformar os dados para normalizar**\n\nExemplo: Usando a raiz quadrada para tentar normalizar e tornar os dados normais e homogenos.\n\nPode-se também tentar o log da variável resposta + 0.5.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov2 <- aov(sqrt(count) ~ spray, data = insects)\nsummary(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5  88.44  17.688    44.8 <2e-16 ***\nResiduals   66  26.06   0.395                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n#### Checagem das premissas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.681).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.854).\n```\n\n\n:::\n:::\n\n\n\n\n### **2. Uso de testes não paramétricos**\n\nSe com as transformações não normalizar e ainda forem heterogêneos, usa-se testes não paramétricos.\n\nUma das saídas para normalizar os dados é a utilização do teste de *Kruskal-Wallis*. O teste de Kruskal-Wallis utiliza os valores numéricos transformados em postos e agrupados num só conjunto de dados, é testado se as amostras vêm de uma mesma população, ou se pelo menos uma delas vêm de população distinta das demais. O teste de Kruskal-Wallis dispensa a pressuposição de normalidade e homocedasticidade. Tem 2 opções de teste Kruskal. Para usar essa opção, é necessário baixar e carregar o pacote agricolae.\n\n#### Teste de *Kruskal-Wallis*\n\nÉ utilizado em situações onde queremos comparar mais de dois grupos independentes, de tamanhos iguais ou não, com variável resposta quantitativa. É uma alternativa quando os pressupostos necesários para o teste F da Anova não são atendidos, pois este teste dispensa a pressuposição de normalidade e homocedasticidade.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(agricolae)\n\nkruskal.test(count ~ spray, data = insects)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskal(insects$count, insects$spray, \n        console = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nStudy: insects$count ~ insects$spray\nKruskal-Wallis test's\nTies or no Ties\n\nCritical Value: 54.69134\nDegrees of freedom: 5\nPvalue Chisq  : 1.510845e-10 \n\ninsects$spray,  means of the ranks\n\n  insects.count  r\nA      52.16667 12\nB      54.83333 12\nC      11.45833 12\nD      25.58333 12\nE      19.33333 12\nF      55.62500 12\n\nPost Hoc Analysis\n\nt-Student: 1.996564\nAlpha    : 0.05\nMinimum Significant Difference: 8.462804 \n\nTreatments with the same letter are not significantly different.\n\n  insects$count groups\nF      55.62500      a\nB      54.83333      a\nA      52.16667      a\nD      25.58333      b\nE      19.33333     bc\nC      11.45833      c\n```\n\n\n:::\n:::\n\n\n\n\nO pacote `emmeans` é muito útil na análise de Modelos Lineares Generalizados (GLM), pois permite obter as médias marginais estimadas dos fatores no modelo.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov2 <- aov(count ~ spray, data = insects)\nsummary(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)    \nspray        5   2669   533.8    34.7 <2e-16 ***\nResiduals   66   1015    15.4                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n##### Checagem das premissas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Non-normality of residuals detected (p = 0.022).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(aov2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n```\n\n\n:::\n:::\n\n\n\n\nFunção `emmeans`: tirar a média da variável inseticida. Para dar o valor original da média e não o valor transformado, usa-se a função `type = response`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\naov2_means <- emmeans(aov2, ~ spray,\n                         type = \"response\")\naov2_means\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray emmean   SE df lower.CL upper.CL\n A      14.50 1.13 66   12.240    16.76\n B      15.33 1.13 66   13.073    17.59\n C       2.08 1.13 66   -0.177     4.34\n D       4.92 1.13 66    2.656     7.18\n E       3.50 1.13 66    1.240     5.76\n F      16.67 1.13 66   14.406    18.93\n\nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\n\nA função `pwpm` gera uma tabela de comparação das médias e `cld` é uma função que serve para gerar os números que diferenciam os grupos de médias.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwpm(aov2_means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        A       B       C       D       E       F\nA [14.50]  0.9952  <.0001  <.0001  <.0001  0.7542\nB  -0.833 [15.33]  <.0001  <.0001  <.0001  0.9603\nC  12.417  13.250 [ 2.08]  0.4921  0.9489  <.0001\nD   9.583  10.417  -2.833 [ 4.92]  0.9489  <.0001\nE  11.000  11.833  -1.417   1.417 [ 3.50]  <.0001\nF  -2.167  -1.333 -14.583 -11.750 -13.167 [16.67]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean)   type = \"response\"\nLower triangle: Comparisons (estimate)   earlier vs. later\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(mvtnorm)\nlibrary(survival)\nlibrary(TH.data)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(aov2_means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n#### 3. **GLM – Modelos Lineares Generalizados**\n\nA função `glm` é utilizada para ajustar Modelos Lineares Generalizados no R. Esses modelos permitem trabalhar com diferentes distribuições de erro, como binomial, *Poisson* e outras, tornando possível a análise de variáveis resposta que não seguem uma distribuição normal. O modelo é definido por uma fórmula simbólica que relaciona a variável resposta aos preditores, e pela escolha de uma família de distribuição que representa o tipo de dado analisado. Para publicação de artigos, essa é a opção mais aconselhável.\n\nPara a geração de modelos, a função a ser utilizada é a `glm` e precisa indicar os argumentos f*amily = poisson(link = “identity”)*. Para visualizar, pode usar o pacote `Dharma` e gerar um plot.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\n\nglm1 <- glm(count ~spray,\n             data = insects,\n             family = poisson(link = \"identity\"))\nplot(simulateResiduals(glm1))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-125-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = count ~ spray, family = poisson(link = \"identity\"), \n    data = insects)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  14.5000     1.0992  13.191  < 2e-16 ***\nsprayB        0.8333     1.5767   0.529    0.597    \nsprayC      -12.4167     1.1756 -10.562  < 2e-16 ***\nsprayD       -9.5833     1.2720  -7.534 4.92e-14 ***\nsprayE      -11.0000     1.2247  -8.981  < 2e-16 ***\nsprayF        2.1667     1.6116   1.344    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm1_means <- emmeans(glm1, ~ spray)\ncld(glm1_means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n spray emmean    SE  df asymp.LCL asymp.UCL .group\n C       2.08 0.417 Inf      1.27      2.90  1    \n E       3.50 0.540 Inf      2.44      4.56  12   \n D       4.92 0.640 Inf      3.66      6.17   2   \n A      14.50 1.100 Inf     12.35     16.65    3  \n B      15.33 1.130 Inf     13.12     17.55    3  \n F      16.67 1.180 Inf     14.36     18.98    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\n# **Análise de Regressão**\n\nA análise de regressão é uma técnica estatística utilizada para examinar a relação entre variáveis por meio da construção de um modelo matemático. Quando os dados são quantitativos, ela costuma ser mais indicada que a análise de variância (ANOVA), pois permite descrever e prever a relação entre uma variável dependente (Y) e uma ou mais variáveis independentes (X).\n\nO objetivo é estimar os parâmetros de uma equação que represente essa relação funcional. Com isso, é possível identificar a direção e a intensidade do efeito das variáveis independentes sobre a variável resposta, além de realizar previsões para novos casos.\n\n# **Regressão linear simples**\n\nNa análise de regressão linear, parte-se do pressuposto de que existe uma relação linear entre a variável dependente e a variável independente, ou seja, essa relação pode ser representada por uma linha reta. A equação geral da regressão linear é:\\\n\n**y = β₀ + β₁x + ε**, onde:\n\n-   *y* representa a variável dependente (ou resposta);\n\n-   *x* é a variável independente (ou preditora);\n\n-   *β₀* é o intercepto da reta (valor de *y* quando *x = 0*);\n\n-   *β₁* é o coeficiente angular (inclinação da reta);\n\n-   *ε* é o termo de erro aleatório;\n\nNa regressão linear simples, o principal objetivo é testar se o coeficiente de inclinação (*β₁*) é significativamente diferente de zero. Esse teste indica se há evidência estatística de uma associação linear entre as variáveis. Um valor de *p* pequeno (geralmente \\< 0,05) sugere que a inclinação é significativamente diferente de zero, indicando uma relação linear entre *x* e *y*.\n\n### Carregando pacotes e importando o conjunto de dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Passo 1: Carregar pacotes e importar dados\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(lme4)\nlibrary(car) # para Anova()\nlibrary(readxl)\n\n# Importar dados - Google Sheets\n\n# estande <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=401662555#gid=401662555\") ou:\n\n\nestande <- read_excel(\"dados.xlsx\", \"estande\") # Planilha excel\n```\n:::\n\n\n\n\n### Visualizar distribuição geral com regressão\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráfico geral para visualizar a relação entre tratamento e número de plantas\nestande |>\n  ggplot(aes(trat, nplants)) +\n  geom_point(color = \"blue\") + # Pontos individuais\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") + # Linha de regressão\n  facet_wrap(~ exp) + # Um gráfico por experimento\n  theme_minimal() + # Tema limpo\n  labs(\n    x = \"% de inóculo na semente\",\n    y = \"Número de plantas\"\n  )\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-129-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Para ajustar para uma regressão linear usa-se o argumento method = “lm” dentro da função geom_smooth.\n```\n:::\n\n\n\n\n## **Modelo de melhor ajuste**\n\nDeve-se testar o modelo que melhor se ajusta aos dados. Pode-se testar fazer a análise de regressão para cada experimento (isola cada experimento) ou analisar em grupos (modelos mistos).\n\n#### Análise de regressão por experimento\n\n**Analisando cada experimento isoladamente:**\n\nÉ preciso criar um novo objeto de dados, chamado `exp1`, atribuindo a ele o conjunto `estande`. Em seguida, deve-se filtrar o experimento de interesse e gerar um novo objeto com esse subconjunto, o que possibilita a execução da análise de regressão.\n\n**Experimento 1:**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filtrar experimento 1 e calcular média por tratamento\nexp1 <- estande |>\n  filter(exp == 1) |>\n  group_by(trat) |>\n  summarise(nplants2 = mean(nplants, na.rm = TRUE))\n\n# Gráfico da média\nexp1 |>\n  ggplot(aes(trat, nplants2)) +\n  geom_point() +\n  ylim(20, 60)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-130-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Regressão linear com bloco (precisa existir a variável 'bloco')\nexp1_model <- estande |>\n  filter(exp == 1)\n\nm_exp1 <- lm(nplants ~ trat + bloco, data = exp1_model)\nsummary(m_exp1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat + bloco, data = exp1_model)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.0769  -6.7847  -0.7817   4.0522  22.6091 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  75.5833     5.7164  13.222 1.19e-11 ***\ntrat         -0.2419     0.1323  -1.829 0.081623 .  \nbloco        -9.2333     1.9485  -4.739 0.000111 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.67 on 21 degrees of freedom\nMultiple R-squared:  0.5513,\tAdjusted R-squared:  0.5086 \nF-statistic:  12.9 on 2 and 21 DF,  p-value: 0.0002216\n```\n\n\n:::\n:::\n\n\n\n\nFoi ajustado um modelo linear para avaliar o efeito do tratamento e do bloco sobre o número de plantas. O modelo apresentou um bom ajuste, explicando cerca de 55% da variação nos dados (R² = 0,55). O efeito do bloco foi altamente significativo (p \\< 0,001), indicando variações importantes entre os blocos experimentais. Já o efeito do tratamento foi marginalmente significativo (p = 0,082), sugerindo uma possível tendência de diferença entre tratamentos, embora com menor evidência estatística. O erro padrão residual foi de 10,67, e o modelo geral foi significativo pelo teste F (p \\< 0,001).\n\n**Experimento 2:**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <- estande |>\n  filter(exp == 2)\n\nm_exp2 <- lm(nplants ~ trat, data = exp2)\nsummary(m_exp2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n:::\n\n\n\n\nFoi ajustado um modelo linear para avaliar o efeito do tratamento (`trat`) sobre o número de plantas (`nplants`). O modelo apresentou um bom ajuste, explicando cerca de 46% da variação observada (R² = 0,46). O tratamento teve efeito estatisticamente significativo (p \\< 0,001), com uma estimativa de redução de 0,70 plantas por unidade do fator `trat`. O modelo como um todo foi altamente significativo (p \\< 0,001), indicando que `trat` é um fator importante na determinação do número de plantas nesta análise.\n\n**Experimento 3:**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp3 <- estande |>\n  filter(exp == 3)\n\nm_exp3 <- lm(nplants ~ trat, data = exp3)\nsummary(m_exp3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n\n\n:::\n:::\n\n\n\n\nFoi ajustado um modelo linear simples para investigar o efeito do tratamento sobre o número de plantas no experimento 3. O modelo apresentou um ajuste estatisticamente significativo (p \\< 0,001), explicando aproximadamente 61% da variação nos dados (R² = 0,61). O efeito do tratamento também foi altamente significativo (p \\< 0,001), com uma estimativa de redução média de 0,76 plantas para cada unidade de `trat`. O valor médio estimado de plantas no grupo de referência foi 95,75. O erro padrão residual foi de 10,53, indicando um bom ajuste aos dados.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(report)\nreport(m_exp3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWe fitted a linear model (estimated using OLS) to predict nplants with trat\n(formula: nplants ~ trat). The model explains a statistically significant and\nsubstantial proportion of variance (R2 = 0.61, F(1, 22) = 34.19, p < .001, adj.\nR2 = 0.59). The model's intercept, corresponding to trat = 0, is at 95.75 (95%\nCI [89.63, 101.87], t(22) = 32.43, p < .001). Within this model:\n\n  - The effect of trat is statistically significant and negative (beta = -0.76,\n95% CI [-1.03, -0.49], t(22) = -5.85, p < .001; Std. beta = -0.78, 95% CI\n[-1.06, -0.50])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n```\n\n\n:::\n:::\n\n\n\n\n#### Modelo misto - Exemplo\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Modelo misto com efeitos aleatórios de experimento e bloco\nm_misto <- lmer(nplants ~ trat + (1 | exp/bloco), data = estande)\n\n# Intervalos de confiança e sumário do modelo\nconfint(m_misto)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %     97.5 %\n.sig01       3.3332097 14.4218422\n.sig02       7.2377419 47.8269818\n.sigma       9.7314178 13.9359486\n(Intercept) 43.4631239 96.0274587\ntrat        -0.7328972 -0.4044812\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(m_misto)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (1 | exp/bloco)\n   Data: estande\n\nREML criterion at convergence: 575.8\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.21697 -0.63351  0.04292  0.67094  1.92907 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n bloco:exp (Intercept)  54.76    7.40   \n exp       (Intercept) 377.43   19.43   \n Residual              134.99   11.62   \nNumber of obs: 72, groups:  bloco:exp, 12; exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 69.74524   11.57191   6.027\ntrat        -0.56869    0.08314  -6.840\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.111\n```\n\n\n:::\n\n```{.r .cell-code}\n# ANOVA para verificar significância dos efeitos fixos\nAnova(m_misto) # com A maiúsculo\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(>Chisq)    \ntrat 46.788  1  7.909e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n#### Gráfico com linhas de regressão manuais\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gráfico com diferentes linhas de regressão para comparação\nestande |>\n  ggplot(aes(trat, nplants, color = factor(exp))) +\n  geom_point() +\n  geom_abline(intercept = 69.74, slope = -0.568, linewidth = 2) + # Linha principal\n  geom_abline(intercept = 43, slope = -0.73, linetype = \"dashed\") + # Linha comparativa\n  geom_abline(intercept = 96, slope = -0.40, linetype = \"dashed\")   # Outra linha comparativa\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-136-1.png){width=672}\n:::\n:::\n\n\n\n\n## **Modelo misto**\n\nEm um modelo misto, as observações são organizadas em grupos ou subgrupos, e cada um desses grupos pode apresentar efeitos aleatórios e/ou fixos distintos, conforme a estrutura dos dados. Por exemplo, quando os dados são coletados em diferentes localidades geográficas, é comum incluir um efeito aleatório para cada local, como ocorre no conjunto de dados estande.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmix <- lmer(nplants ~trat + (trat | exp),\n            data = estande)\nsummary(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nAnova(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: nplants\n      Chisq Df Pr(>Chisq)    \ntrat 11.985  1  0.0005362 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nQuando se usa o modelo misto, considera que todos os experimentos são agrupados, então considera que amostra é aleatória. Para fazer o modelo de regressão em grupo (misto) acrescenta-se na função aestetic o argumento group = exp.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande <- read_excel(\"dados.xlsx\", \"estande\")\nestande |>\n  ggplot(aes(trat, nplants, group = exp))+\n  geom_point()+\n  #facet_wrap(~ exp)+\n  geom_smooth(se =  F, method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-139-1.png){width=672}\n:::\n:::\n\n\n\n\nDe modo geral, os modelos mistos são mais eficazes do que aqueles que analisam cada experimento separadamente, pois conseguem considerar a variação tanto entre os experimentos quanto dentro deles. Além disso, esses modelos permitem analisar os dados de forma integrada, preservando informações importantes sobre a estrutura hierárquica dos dados.\n\n## **Modelo GLM**\n\nO modelo linear generalizado (GLM) é uma extensão do modelo linear tradicional que possibilita trabalhar com diferentes tipos de variáveis resposta, tanto categóricas quanto contínuas. Além disso, o GLM permite que a relação entre a variável resposta e as explicativas seja não linear, ou seja, não está restrito à suposição de uma relação linear entre elas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm(nplants ~ trat, data = exp3)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm1 <- stats::glm(nplants ~ trat, family = stats::gaussian(), data = exp3)\n\nglm2 <- stats::glm(nplants ~ trat, family = stats::poisson(link = \"log\"), data = exp3)\n\nAIC(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 185.0449\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 183.9324\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 183.9324\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nstats::glm(formula = nplants ~ trat, family = stats::gaussian(), \n    data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(glm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nstats::glm(formula = nplants ~ trat, family = stats::poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\nO modelo linear generalizado com distribuição gaussiana (`family = gaussian`) é indicado quando a variável resposta é contínua e segue uma distribuição normal, funcionando de forma equivalente ao modelo linear clássico (`lm`). Por outro lado, o modelo com distribuição de *Poisson* (`family = poisson`) é apropriado quando a variável resposta é um número inteiro não negativo e segue uma distribuição de *Poisson.*\n\nO critério AIC (*Akaike’s Information Criterion*) é utilizado para selecionar o melhor modelo entre várias opções, considerando tanto o ajuste aos dados quanto a complexidade do modelo. Modelos com valores menores de AIC são preferíveis, pois indicam um equilíbrio melhor entre precisão e simplicidade. No caso dos dados analisados, o modelo com família Poisson apresentou o menor AIC, indicando ser o mais adequado.\n\n# **Regressão não-linear**\n\nQuando a relação entre as variáveis independentes e a variável dependente não pode ser representada por uma linha reta, é necessário recorrer à regressão não linear. Esse tipo de análise é apropriado quando os dados apresentam padrões que não podem ser adequadamente modelados por uma função linear, permitindo capturar relações mais complexas entre as variáveis.\n\n### Carregar pacotes e importar dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pacote para importar tabela do Google Sheets\nlibrary(gsheet)\n\n# Importar dados\nfungi <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=465348652#gid=465348652\")\n```\n:::\n\n\n\n\n### Visualizar os dados para todos os fungos\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Agrupar por fungo e dose, calcular média de germinação\nfungi_summary <- fungi |>\n  group_by(code, dose) |>\n  summarise(germination = mean(germination, na.rm = TRUE), .groups = \"drop\")\n\n# Plotar a germinação por dose para cada fungo\nfungi_summary |>\n  ggplot(aes(x = dose, y = germination)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~ code) +\n  theme_minimal() +\n  labs(title = \"Germinação por dose para cada fungo\",\n       x = \"Dose\",\n       y = \"Germinação média\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-146-1.png){width=672}\n:::\n:::\n\n\n\n\n### Selecionar um fungo específico para ajustar modelos (exemplo: FGT43)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filtrar dados para o fungo FGT43\nFGT43 <- fungi_summary |>\n  filter(code == \"FGT43\")\n```\n:::\n\n\n\n\n### Ajustar modelos de regressão não linear usando o pacote `drc`\n\nO pacote `drc` é amplamente utilizado para o ajuste de modelos de regressão em estudos de dose-resposta. Ele oferece uma variedade de modelos, como log-logístico, log-probit, Weibull, entre outros, permitindo representar com precisão a relação entre a dose aplicada e a resposta observada. Além disso, o pacote disponibiliza funções para a estimativa de parâmetros importantes, como o EC50 (dose efetiva para 50% da resposta máxima).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(drc)\n\n# Ajustar modelo Weibull 2.3\nm_wb <- drm(germination ~ dose,\n            data = FGT43,\n            fct = W2.3())\n\n# Ajustar modelo log-logístico 3 parâmetros (LL.3)\nm_ll3 <- drm(germination ~ dose,\n             data = FGT43,\n             fct = LL.3())\n\n# Comparar AIC para escolher o melhor modelo\nAIC(m_wb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 32.34994\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(m_ll3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 26.7762\n```\n\n\n:::\n\n```{.r .cell-code}\n# Resumo do melhor modelo (exemplo: LL.3)\nsummary(m_ll3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  1.219692   0.175081  6.9664  0.006069 ** \nd:(Intercept) 48.486911   1.456007 33.3013 5.952e-05 ***\ne:(Intercept)  0.495895   0.060851  8.1494  0.003864 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.636105 (3 degrees of freedom)\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plotar ajuste do modelo LL.3\nplot(m_ll3, main = \"Ajuste do modelo LL.3 para FGT43\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-148-1.png){width=672}\n:::\n:::\n\n\n\n\n### Estimar a concentração efetiva EC50 a partir do modelo\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimar EC50 (dose para 50% do efeito)\nED(m_ll3, 50, interval = \"delta\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.495895   0.060851 0.302241 0.689550\n```\n\n\n:::\n:::\n\n\n\n\n### Estimar EC50 para todos os fungos de uma vez (pacote `ec50estimator`)\n\nA função do pacote `ec50estimator` permite calcular os valores de EC50 de forma prática e eficiente. Esses valores representam a dose necessária para atingir 50% da resposta máxima e são especialmente úteis para comparar a sensibilidade entre diferentes identificadores (ID). Com isso, é possível identificar variações na resposta à dose entre tratamentos, linhagens ou isolados, o que auxilia na avaliação da eficácia ou resistência em diferentes grupos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Instale o pacote se ainda não tiver: install.packages(\"ec50estimator\")\nlibrary(ec50estimator)\n\n# Estima EC50 para cada fungo (isolate_col = \"code\"), podendo estratificar por estado (strata_col)\ndf_ec50 <- estimate_EC50(germination ~ dose,\n                         data = fungi,\n                         isolate_col = \"code\",\n                         strata_col = \"state\",  # pode omitir se não tiver\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n```\n:::\n\n\n\n\n### Visualizar os resultados da estimativa EC50\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Gráfico de pontos ordenando pelo valor da estimativa (menor para maior EC50)\ndf_ec50 |>\n  ggplot(aes(x = reorder(ID, Estimate), y = Estimate)) +\n  geom_point() +\n  coord_flip() +\n  labs(x = \"Fungos (ordenados por EC50)\", y = \"EC50 estimado\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-151-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histograma da distribuição dos valores EC50\ndf_ec50 |>\n  ggplot(aes(x = Estimate)) +\n  geom_histogram(bins = 5, color = \"black\", fill = \"steelblue\") +\n  labs(title = \"Distribuição dos valores EC50 estimados\", x = \"EC50\", y = \"Frequência\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-152-1.png){width=672}\n:::\n:::\n\n\n\n\n### Exemplo 2:\n\nRegressão não-linar para determinação de EC50.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Carregando pacotes\nlibrary(ggplot2)\nlibrary(gsheet)\nlibrary(dplyr)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#importando o comjunto de dados\ndat <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/15pCj0zljvd-TGECe67OMt6sa21xO8BqUgv4d-kU8qi8/edit#gid=0\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen = 999)\n\ndat2 <- dat |> \n  dplyr::select(-Isolate, Population) |> \n  group_by(Code, Year, Dose) |> \n  summarise(GC_mean = mean(GC), .groups = \"drop\")\n```\n:::\n\n\n\n\nO comando `options(scipen = 999)` ajusta a opção `scipen`, que controla a exibição de números em notação científica. Ao definir esse valor como 999, o R passa a exibir números longos em formato decimal comum, evitando a notação exponencial.\n\nEm seguida, o bloco de código realiza as seguintes operações sobre o dataframe `dat`:\n\n-   Remove as colunas `Isolate` e `Population`, que não farão parte do novo conjunto de dados.\n\n-   Agrupa os dados pelas variáveis `Code`, `Year` e `Dose`.\n\n-   Calcula a média da variável `GC` para cada combinação desses grupos.\n\n-   Armazena o resultado em um novo dataframe chamado `dat2`, criando uma nova coluna chamada `GC_mean`, que contém a média de `GC` dentro de cada grupo.\n\nEssas operações são úteis para resumir os dados e preparar o conjunto para análises posteriores.\n\n**Exemplo:** gráfico só com um dos isolados - FGT152\n\nCriou-se um gráfico usando o dataframe FGT152, que é um subconjunto dos dados filtrados do `dat2`. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFGT152 <- dat2 |>\n  filter(Code == \"FGT152\")\n\nFGT152 |>\n  ggplot(aes(factor(Dose), GC_mean))+\n  geom_point()+\n  geom_line()+\n  facet_wrap(~ Code)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-156-1.png){width=672}\n:::\n:::\n\n\n\n\n#### **EC50 com pacote DRC**\n\n##### **Modelo log-logístico de 3 parâmetros**:\n\nEsse modelo é utilizado para descrever a relação entre a dose de um agente ou tratamento e a resposta biológica observada. Ele assume que a resposta varia de forma crescente ou decrescente com o aumento da dose, seguindo uma curva sigmoide (em forma de \"S\" ou \"S\" invertido). É especialmente útil em estudos de dose-resposta, onde se espera esse tipo de comportamento não linear.\n\nO comando `drc1 <- drm(GC_mean ~ Dose, data = FGT152, fct = LL.3())` ajusta um modelo de regressão de dose-resposta utilizando a função `drm()` do pacote **`drc`**. Nesse caso:\n\n-   `GC_mean ~ Dose`: define que a variável resposta é `GC_mean` e a variável preditora é `Dose`;\n\n-   `data = FGT152`: indica que os dados utilizados estão no dataframe `FGT152`;\n\n-   `fct = LL.3()`: especifica o uso do modelo log-logístico de três parâmetros (LL.3), adequado para curvas sigmoides.\n\nApós o ajuste, o comando `AIC(drc1)` calcula o *Akaike Information Criterion (AIC)* do modelo, uma medida que considera tanto o ajuste quanto a complexidade do modelo, quanto menor o AIC, melhor o modelo.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(drc)\n\ndrc1 <- drm(GC_mean ~ Dose, data = FGT152,\n            fct = LL.3())\nAIC(drc1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 33.60846\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(drc1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value     p-value    \nb:(Intercept)  0.401905   0.053427  7.5225    0.001672 ** \nd:(Intercept) 47.540342   1.459890 32.5643 0.000005302 ***\ne:(Intercept)  7.220130   2.340119  3.0854    0.036739 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.993805 (4 degrees of freedom)\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(drc1)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-159-1.png){width=672}\n:::\n:::\n\n\n\n\nO comando `ED(drc1, 50)` estima a dose efetiva necessária para alcançar 50% da resposta máxima (ED50). A função `ED()` retorna essa estimativa com base no modelo ajustado.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nED(drc1, 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   7.2201     2.3401\n```\n\n\n:::\n:::\n\n\n\n\n##### **Modelo W1.3**:\n\nApresentou o melhor ajuste aos dados com base no valor do AIC. Esse modelo oferece maior flexibilidade na modelagem da curva dose-resposta por incluir o parâmetro de assimetria (g). Esse parâmetro permite que a curva assuma formas assimétricas, ajustando-se melhor a situações em que a resposta não segue uma simetria perfeita em torno da dose efetiva, resultando em curvas sigmoides assimétricas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrc1 <- drm(GC_mean ~ Dose, data = FGT152,\n            fct = W1.3())\nAIC(drc1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 37.75192\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(drc1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n              Estimate Std. Error t-value    p-value    \nb:(Intercept)  0.28354    0.04760  5.9567   0.003987 ** \nd:(Intercept) 48.38112    2.09996 23.0390 0.00002103 ***\ne:(Intercept) 30.12379   12.58003  2.3946   0.074796 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.680509 (4 degrees of freedom)\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(drc1)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-163-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nED(drc1, 50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nEstimated effective doses\n\n       Estimate Std. Error\ne:1:50   8.2704     3.6719\n```\n\n\n:::\n:::\n\n\n\n\n##### **Pacote ec50estimator**\n\nA função `estimate_EC50()` é usada para estimar os valores de EC50 a partir dos dados disponíveis. Ela recebe diversos argumentos, cada um com um papel específico:\n\n-   `isolate_col = \"Code\"` define a coluna `\"Code\"` como identificador único para as diferentes amostras ou grupos;\n\n-   `interval = \"delta\"` especifica o tipo de intervalo de confiança a ser calculado para as estimativas de EC50;\n\n-   `fct = drc::LL.3()` indica que o modelo de ajuste utilizado é o log-logístico de três parâmetros.\n\nNo gráfico criado com `ggplot2`, dentro da função `aes()`, o argumento `(Estimate, reorder(ID, Estimate))` mapeia as variáveis para os eixos x e y. Aqui, `Estimate` representa os valores estimados de EC50, enquanto `ID` é reordenado com base nesses valores para controlar a ordem de exibição no gráfico.\n\nA função `geom_errorbar()` adiciona barras de erro ao gráfico, usando os valores `Lower` e `Upper`, que correspondem aos limites inferior e superior dos intervalos de confiança das estimativas de EC50. Por fim, o comando `xlim(0, 30)` define os limites do eixo x, restringindo a visualização das estimativas a valores entre 0 e 30.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ec50estimator)\n\ndf_ec50 <- estimate_EC50(GC_mean ~ Dose,\n                         data = dat2,\n                         isolate_col = \"Code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n\ndf_ec50 |>\n  ggplot(aes(Estimate, reorder(ID, Estimate)))+\n  geom_point()+\n  geom_errorbar(aes(xmin = Lower,\n                    xmax = Upper), width = 0.1)+\n  xlim(0,30)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-165-1.png){width=672}\n:::\n:::\n\n\n\n\n# **Análise de Correlação**\n\nA análise de correlação é utilizada para verificar a intensidade e a direção da relação linear entre duas variáveis contínuas. Seu principal objetivo é avaliar até que ponto as variáveis se associam — ou seja, se tendem a variar juntas de forma proporcional.\n\nEssa análise pode indicar:\n\n-   **Correlação positiva**: quando o aumento de uma variável está associado ao aumento da outra;\n\n-   **Correlação negativa**: quando o aumento de uma variável está associado à diminuição da outra;\n\n-   **Ausência de correlação**: quando não há uma relação linear evidente entre as variáveis.\n\nO coeficiente de correlação de Pearson é a medida mais comum e varia entre -1 e +1:\n\n-   Valores próximos de **+1** indicam forte correlação positiva;\n\n-   Valores próximos de **-1** indicam forte correlação negativa;\n\n-   Valores próximos de **0** indicam correlação fraca ou inexistente.\n\nÉ importante destacar que a correlação não implica causalidade, ou seja, uma variável pode estar associada à outra sem que necessariamente uma cause a outra.\n\n### Carregamento de pacotes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\n```\n:::\n\n\n\n\n### Importando o conjunto de dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande <- read_excel(\"dados.xlsx\", \"estande\")\n```\n:::\n\n\n\n\n### Visualização gráfica\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande |>\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  facet_wrap(~ exp)+\n  ylim(0,max(estande$nplants))+\n  geom_smooth(se =  F)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-168-1.png){width=672}\n:::\n:::\n\n\n\n\n## **Ajustando modelo linear simples e quadratico**\n\nPara ajustar modelos de regressão linear — seja simples ou quadrático — utiliza-se a função `lm()` no R. Essa função recebe como argumentos uma **fórmula** que define a relação entre a variável dependente e a(s) variável(is) independente(s), além do conjunto de dados a ser utilizado.\n\nPor exemplo, para um modelo linear simples, a fórmula seria `y ~ x`, onde `y` é a variável resposta e `x` é a variável explicativa. Para um modelo quadrático, a fórmula pode ser `y ~ x + I(x^2)`, incluindo o termo ao quadrado de `x`.\n\nO modelo ajustado é armazenado como um objeto do tipo `lm`, que pode ser examinado com a função `summary()`. Esse resumo fornece os coeficientes estimados, valores-p, estatísticas de ajuste (como o R²) e outros diagnósticos úteis.\n\n### Coeficiente de Determinação (R²)\n\nO **R²** representa a proporção da variação da variável resposta que é explicada pelo modelo ajustado. Seu valor varia entre 0 e 1:\n\n-   **R² = 0**: o modelo não explica nenhuma variação nos dados;\n\n-   **R² = 1**: o modelo explica toda a variação observada.\n\nQuanto maior o R², melhor o modelo se ajusta aos dados, indicando maior capacidade explicativa por parte das variáveis independentes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande2 <- estande |>\n  filter(exp ==2) |>\n  group_by(trat) |>\n  summarise(mean_nplants = mean(nplants))\n  \nestande2|>\n  ggplot(aes(trat, mean_nplants))+\n  geom_point()+\n  #geom_line()\n  geom_smooth(formula = y ~ poly(x, 2), method = \"lm\", color = \"black\")+\n  annotate(geom = \"text\", \n           x = 25, y = 70,\n           label = \"y = 66.3 - 1.777x + 0.0222x2\n           R2 = 0.0.88\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-169-1.png){width=672}\n:::\n:::\n\n\n\n\n## Modelo Quadrático\n\nDiferente do modelo linear, que descreve a relação entre duas variáveis por meio de uma linha reta, o modelo quadrático permite identificar padrões não lineares, com comportamento curvo.\n\nPara ajustar um modelo quadrático no R, utiliza-se a função `lm()`, incluindo o termo ao quadrado da variável independente na fórmula. Por exemplo, para modelar a relação entre uma variável dependente `y` e uma independente `x`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande2 <- estande2 |>\n  mutate(trat2 = trat^2)\n  m1 <- lm(mean_nplants ~ trat, data = estande2)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mean_nplants ~ trat, data = estande2)\n\nResiduals:\n     1      2      3      4      5      6 \n12.764 -2.134 -6.782 -3.327 -4.669  4.147 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     4.5505  13.402 0.000179 ***\ntrat         -0.7007     0.2012  -3.483 0.025294 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.117 on 4 degrees of freedom\nMultiple R-squared:  0.752,\tAdjusted R-squared:   0.69 \nF-statistic: 12.13 on 1 and 4 DF,  p-value: 0.02529\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(m1$residuals)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-171-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- lm(mean_nplants ~ trat + trat2,\n         data = estande2)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mean_nplants ~ trat + trat2, data = estande2)\n\nResiduals:\n      1       2       3       4       5       6 \n 7.4484 -4.4200 -6.4386  1.0739  3.0474 -0.7111 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.30156    4.70800  14.083 0.000776 ***\ntrat        -1.77720    0.62263  -2.854 0.064878 .  \ntrat2        0.02223    0.01242   1.790 0.171344    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.517 on 3 degrees of freedom\nMultiple R-squared:  0.8801,\tAdjusted R-squared:  0.8001 \nF-statistic: 11.01 on 2 and 3 DF,  p-value: 0.04152\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(m1, m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   df      AIC\nm1  3 45.72200\nm2  4 43.36151\n```\n\n\n:::\n:::\n\n\n\n\n## **Duas variáveis resposta**\n\n### Ajuste de Modelo Linear Simples e Quadrático\n\nPara ajustar modelos de regressão linear, seja simples ou quadrático, utiliza-se a função `lm()` no R. Essa função recebe como argumentos uma fórmula que define a relação entre a variável dependente e a(s) variável(is) independente(s), além do conjunto de dados a ser utilizado.\n\nPor exemplo, para um modelo linear simples, a fórmula seria `y ~ x`, onde `y` é a variável resposta e `x` é a variável explicativa. Para um modelo quadrático, a fórmula pode ser `y ~ x + I(x^2)`, incluindo o termo ao quadrado de `x`.\n\nO modelo ajustado é armazenado como um objeto do tipo `lm`, que pode ser examinado com a função `summary()`. Esse resumo fornece os coeficientes estimados, valores-p, estatísticas de ajuste (como o R²) e outros diagnósticos úteis.\n\n#### Importando o conjunto de dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo <- read_excel(\"dados.xlsx\", \"mofo\")\n```\n:::\n\n\n\n\n#### Visualizando os dados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo |>\n  ggplot(aes(inc, yld))+\n  geom_point()+\n  geom_smooth(se = F, method = \"lm\")+\n  facet_wrap(~ study)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-175-1.png){width=672}\n:::\n:::\n\n\n\n\nFiltrando o experimento 1 (study = 1):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- mofo |>\n  filter(study ==1)\nmofo1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1     1    76  2194  2265\n 2     1     2    53  1663  2618\n 3     1     3    42  1313  2554\n 4     1     4    37  1177  2632\n 5     1     5    29   753  2820\n 6     1     6    42  1343  2799\n 7     1     7    55  1519  2503\n 8     1     8    40   516  2967\n 9     1     9    26   643  2965\n10     1    10    18   400  3088\n11     1    11    27   643  3044\n12     1    12    28   921  2925\n13     1    13    36  1196  2867\n```\n\n\n:::\n:::\n\n\n\n\nA função `cor.test()` é utilizada para calcular o **coeficiente de correlação** entre duas variáveis numéricas. Além de fornecer o valor da correlação (como o coeficiente de Pearson), ela também realiza um **teste de hipótese** para verificar se essa correlação é **estatisticamente significativa**, ou seja, se é improvável que tenha ocorrido ao acaso.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(mofo1$inc, mofo1$yld)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -6.8451, df = 11, p-value = 0.00002782\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9699609 -0.6921361\nsample estimates:\n       cor \n-0.8999278 \n```\n\n\n:::\n:::\n\n\n\n\nFiltrando o experimento 2:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- mofo |>\n  filter(study ==2)\nmofo1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     2     1    76  1331  2257\n 2     2     2    44   756  2393\n 3     2     3    24   338  2401\n 4     2     4    33   581  2568\n 5     2     5    37   588  2320\n 6     2     6    34   231  2308\n 7     2     7    31   925  2389\n 8     2     8    16   119  2614\n 9     2     9    10   394  2681\n10     2    10     8   206  2694\n11     2    11    15   275  2674\n12     2    12     7   131  2666\n13     2    13    19   588  2454\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(mofo1$inc, mofo1$yld)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -4.6638, df = 11, p-value = 0.0006894\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9426562 -0.4790750\nsample estimates:\n       cor \n-0.8149448 \n```\n\n\n:::\n:::\n\n\n\n\nFiltrando o experimento 4:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- mofo |>\n  filter(study ==4)\nmofo1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     4     1    69  6216  1893\n 2     4     2    39  2888  2451\n 3     4     3    41  2272  2232\n 4     4     4    39  2868  2609\n 5     4     5    40  2412  2383\n 6     4     6    40  2372  2480\n 7     4     7    44  3424  2577\n 8     4     8    43  1744  2367\n 9     4     9    26  1456  2769\n10     4    10    29  1732  2907\n11     4    11    30  1080  2298\n12     4    12    34  1592  2976\n13     4    13    44  3268  2200\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(mofo1$inc, mofo1$yld)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -3.7242, df = 11, p-value = 0.003357\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9194503 -0.3327077\nsample estimates:\n       cor \n-0.7467931 \n```\n\n\n:::\n:::\n\n\n\n\nFiltrando o experimento 3:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- mofo |>\n  filter(study ==3)\nmofo1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n```\n\n\n:::\n:::\n\n\n\n\n### Matrizes de Correlação\n\nA matriz de correlação é uma tabela que exibe os coeficientes de correlação entre todos os pares de variáveis de um conjunto de dados. Cada célula da matriz indica a força e a direção da relação entre duas variáveis, geralmente usando o coeficiente de correlação de Pearson, embora outras medidas (como Spearman ou Kendall) também possam ser utilizadas, conforme o contexto da análise.\n\nGerando matriz de correlação para as variáveis selecionadas:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- mofo |>\n  filter(study ==3)\nmofo1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(mofo1$inc, mofo1$yld)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -10.9, df = 11, p-value = 0.0000003105\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\ncor(mofo1[, 3:5])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           inc        scl       yld\ninc  1.0000000  0.8441514 -0.956692\nscl  0.8441514  1.0000000 -0.836512\nyld -0.9566920 -0.8365120  1.000000\n```\n\n\n:::\n:::\n\n\n\n\n### Gráficos de Correlação\n\nPara visualizar matrizes de correlação, o pacote `corrplot` é uma ferramenta amplamente utilizada no R. Ele oferece diversas funções para explorar e representar visualmente as relações entre variáveis em um conjunto de dados, facilitando a identificação de padrões de correlação.\n\nPrincipais funções do pacote corrplot:\n\n-   `corr.test()`: realiza testes estatísticos para matrizes de correlação, calculando coeficientes de correlação, valores-p e intervalos de confiança, permitindo avaliar a significância das correlações.\n\n-   `corrplot()`: gera gráficos que exibem a matriz de correlação com diferentes estilos visuais. Permite personalizar o tipo de gráfico, as cores, adicionar os valores numéricos dos coeficientes, além de possibilitar agrupamentos hierárquicos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- mofo |>\n  filter(study ==3)\nmofo1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(mofo1$inc, mofo1$yld)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  mofo1$inc and mofo1$yld\nt = -10.9, df = 11, p-value = 0.0000003105\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9872663 -0.8579544\nsample estimates:\n      cor \n-0.956692 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npcor <- cor(mofo1[, 3:5])\n\nlibrary(corrplot)\ncorrplot(pcor, method = 'number', type = \"lower\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-188-1.png){width=672}\n:::\n:::\n\n\n\n\n### Modelo de Kendall\n\nO coeficiente de correlação de Kendall é uma medida não paramétrica que avalia a associação entre duas variáveis ordinais ou variáveis medidas em escala ordinal. Assim como o coeficiente de Pearson, o coeficiente de Kendall varia entre -1 e 1, indicando a direção e a força da relação.\n\nPor ser não paramétrico, o método de Kendall é mais robusto em situações onde os dados não seguem uma relação linear ou quando as variáveis não possuem distribuição normal, sendo uma alternativa adequada para analisar associações em dados ordinais ou com distribuições não normais.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo1 <- mofo |>\n  filter(study ==3)\nmofo1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 5\n   study treat   inc   scl   yld\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     3     1    65  5013  2839\n 2     3     2    33  3619  3375\n 3     3     3    40  2325  3264\n 4     3     4    35  2588  3301\n 5     3     5    48  3969  3220\n 6     3     6    31  1556  3321\n 7     3     7    39  3175  3229\n 8     3     8    25  1763  3517\n 9     3     9    26  2894  3595\n10     3    10    21   350  3702\n11     3    11    23   419  3652\n12     3    12    25   644  3608\n13     3    13    33  2850  3334\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(mofo1$inc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mofo1$inc\nW = 0.87111, p-value = 0.05412\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(mofo1$yld)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mofo1$yld\nW = 0.92193, p-value = 0.2663\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(mofo1$inc, mofo1$yld, method = \"spearman\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tSpearman's rank correlation rho\n\ndata:  mofo1$inc and mofo1$yld\nS = 715.97, p-value = 0.00000007166\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.9669458 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npcor <- cor(mofo1[, 3:5], method = \"spearman\")\n\nlibrary(corrplot)\ncorrplot(pcor, method = 'number', type = \"lower\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-193-1.png){width=672}\n:::\n:::\n\n\n\n\n# **Comparação de Frequência**\n\nA comparação de frequência é uma análise usada para verificar se há associação ou diferença significativa entre categorias de variáveis categóricas (qualitativas). É muito comum em experimentos, questionários e dados de contagem.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Carregando pacotes\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(rstatix)\n\n#Importando dados\nsurvey <- read_excel(\"dados.xlsx\",\"survey\")\n```\n:::\n\n\n\n\nA função `tabyl()` cria uma tabela de frequência tabular, mostrando a contagem de ocorrências de diferentes combinações de valores em variáveis categóricas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey |> \n  tabyl (year, species) |> \n  adorn_percentages()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n year      Fgra      Fspp\n 2009 0.8490566 0.1509434\n 2010 0.8657407 0.1342593\n 2011 0.7567568 0.2432432\n```\n\n\n:::\n:::\n\n\n\n\n## **Gráfico de barras - frequência**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey |> \n  filter(residue != \"NA\") |> \n  count(residue, species) |> \n  ggplot(aes(residue, n, fill = species)) +\n  geom_col() +\n  scale_fill_brewer(palette = \"Greens\") +\n  theme_minimal() +\n  labs(x = \"Resíduo\", y = \"Frequência\", fill = \"Espécie\")\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-195-1.png){width=672}\n:::\n:::\n\n\n\n\n## **Frequência de classe**\n\nA função `chisq.test()` é utilizada para realizar testes do qui-quadrado em duas principais situações:\n\n-   Testes de independência em tabelas de contingência — verifica se existe associação estatística entre duas variáveis categóricas;\n\n-   Testes de aderência (ou qualidade de ajuste) — avalia se a distribuição observada de uma variável categórica difere significativamente de uma distribuição esperada (teórica).\n\nEssa função retorna estatísticas como o valor do qui-quadrado, os graus de liberdade e o valor-p, que ajudam a determinar se as diferenças observadas são estatisticamente significativas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- table (survey$residue, survey$species)\nchisq.test(q)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 1.1997, df = 1, p-value = 0.2734\n```\n\n\n:::\n:::\n\n\n\n\n## **Para frequências mais baixas**\n\nA função `fisher.test()` realiza o teste exato de Fisher, que é utilizado para avaliar a independência entre linhas e colunas em uma tabela de contingência, especialmente quando os valores esperados são baixos (frequências menores que 5), condição na qual o teste do qui-quadrado pode não ser confiável.\n\nEsse teste verifica se há evidência de associação entre duas variáveis categóricas, assumindo que as margens da tabela (totais de linha e coluna) são fixas. Ele calcula exatamente a probabilidade de observar uma distribuição tão extrema quanto a observada, ou mais, sob a hipótese nula de independência.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfisher.test(q)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tFisher's Exact Test for Count Data\n\ndata:  q\np-value = 0.2118\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.357205 1.311411\nsample estimates:\nodds ratio \n 0.6819103 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nq <- table (survey$residue, survey$inc_class)\nchisq.test(q)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  q\nX-squared = 2.6165, df = 1, p-value = 0.1058\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey |> \n  filter(residue != \"NA\") |> \n  count(residue, inc_class) |> \n  ggplot(aes(residue, n, fill = inc_class)) +\n  geom_col() +\n  scale_fill_brewer(palette = \"Greens\") +\n  theme_minimal() +\n  labs(\n    x = \"Resíduo\",\n    y = \"Frequência\",\n    fill = \"Classe de Incidência\"\n  )\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-199-1.png){width=672}\n:::\n:::\n\n\n\n\n## **Cruzamento entre variáveis**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey |> count (year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n   year     n\n  <dbl> <int>\n1  2009   265\n2  2010   216\n3  2011   185\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#Frequência de ocorrência por ano\n\ntable (survey$year, survey$species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      \n       Fgra Fspp\n  2009  225   40\n  2010  187   29\n  2011  140   45\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncurve <- read_excel(\"dados.xlsx\",\"curve\")\n\ncurve2 <- curve |> \n  group_by(Irrigation, day) |> \n  summarise(mean_severity = mean (severity),\n            sd_severity = sd(severity))\n\ncurve2 |> ggplot(aes(day,mean_severity, color=Irrigation))+\n  geom_point()+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-202-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncurve2 |> ggplot(aes(day,mean_severity, color=Irrigation))+\n  geom_point()+\n  geom_errorbar(aes(ymin=mean_severity - sd_severity,\n                    ymax = mean_severity + sd_severity),\n                width = 0.1)+\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-203-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(epifitter)\n\ncurve3 <- curve |> \n  group_by(Irrigation, rep) |> \n  summarise(audpc = AUDPC(day, severity,\n                          y_proportion = F)) |> \n  pivot_wider(1, names_from = Irrigation,\n            values_from = audpc)\n\nt.test(curve3$Drip, curve$Furrow)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  curve3$Drip\nt = 51.206, df = 2, p-value = 0.0003812\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 12.26473 14.51493\nsample estimates:\nmean of x \n 13.38983 \n```\n\n\n:::\n:::\n\n\n\n\nExemplo:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\n\ntw <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1t5xftb0xSRPNFhM7h_MiPNtwt2UFUcm9/edit#gid=1594889893\")\ntw |> \n  group_by(cult,silicio,hai) |> \n  summarise (mean_lesion = mean (as.numeric(lesion_size)),\n             sd_lesion = sd(lesion_size)) |> \n  ggplot(aes(hai,mean_lesion, color = silicio))+\n  geom_line()+\n  geom_point()+\n  geom_errorbar(aes(ymin=mean_lesion - sd_lesion,\n                    ymax = mean_lesion + sd_lesion),\n                width = 0.1)+\n  facet_wrap(~cult)+\n   labs (y = \"Lesion size (mm)\", x = \"Hours after inoculation\")+\n  ggthemes::theme_few()+\nscale_color_manual(values = c(\"#1f78b4\", \"#6baed6\", \"#9ecae1\", \"#c6dbef\"))\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-205-1.png){width=672}\n:::\n:::\n\n\n\n\n# **Análise da área abaixo da curva de progresso da doença - AUDPC**\n\nA AUDPC (*Area Under the Disease Progress Curve*) é uma medida utilizada na fitopatologia para quantificar e comparar o progresso de doenças em plantas ao longo do tempo. É calculada a partir de observações repetidas da severidade ou tamanho das lesões ao longo do tempo. Para isso, constrói-se uma curva com o tempo no eixo x e a variável de interesse (como o tamanho da lesão) no eixo y. Em seguida, calcula-se a área sob essa curva. Valores elevados de AUDPC refletem maior intensidade ou impacto da doença, enquanto valores mais baixos indicam menor progressão ou severidade.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(agricolae)\nlibrary(dplyr)\n\ntw2 <- tw |>\n  group_by(exp,cult,silicio,rep) |> \n  summarise(audpc=audpc(lesion_size, hai)) |> \n  filter (audpc > 0)\n\n#Visualização com ggplot2\n#Aplicando a AUDPC e visualizando em boxplot\n\ntw2 |> \n  ggplot(aes(cult,audpc, color = silicio))+\n  geom_boxplot()+\n  facet_wrap(~ exp)\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-206-1.png){width=672}\n:::\n:::\n\n\n\n\n## **Teste ANOVA**\n\nOs resultados da análise de variância podem ajudar a identificar quais variáveis e interações têm efeito significativo na variável resposta audpc.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov1 <- aov(sqrt(audpc) ~exp*cult*silicio, data = tw2)\nsummary(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Df Sum Sq Mean Sq F value               Pr(>F)    \nexp               1    0.1     0.1   0.033              0.85737    \ncult              1  135.0   135.0  74.615       0.000000000267 ***\nsilicio           1  839.4   839.4 464.034 < 0.0000000000000002 ***\nexp:cult          1    0.0     0.0   0.000              0.99843    \nexp:silicio       1    0.0     0.0   0.002              0.96060    \ncult:silicio      1   19.3    19.3  10.671              0.00239 ** \nexp:cult:silicio  1    0.0     0.0   0.015              0.90324    \nResiduals        36   65.1     1.8                                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\ncheck_normality(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.893).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(aov1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.316).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nm1 <- emmeans (aov1, ~cult | silicio, type = \"response\")\n```\n:::\n\n\n\n\n### Exemplo\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tabela de frequência\ntab <- table(survey$residue, survey$species)\n\n# Teste qui-quadrado\nchisq.test(tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's Chi-squared test with Yates' continuity correction\n\ndata:  tab\nX-squared = 1.1997, df = 1, p-value = 0.2734\n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualização\nlibrary(ggplot2)\nsurvey |> \n  count(residue, species) |> \n  ggplot(aes(residue, n, fill = species)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(values = c(\"#2171b5\", \"#6baed6\", \"#9ecae1\", \"#c6dbef\")) +\n  labs(x = \"Resíduo\", y = \"Frequência\", fill = \"Espécie\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](analise_estatistica_files/figure-html/unnamed-chunk-211-1.png){width=672}\n:::\n:::\n\n\n\n\n# **Teste de Tukey e Scott Knott (Pacote `ExpDes.pt`)**\n\n**Pacote “ExpDes.pt”**\\\nO pacote `ExpDes.pt` é voltado para a análise de delineamentos experimentais, incluindo DIC, DBC e DQL. Ele permite realizar análises de variância e comparações de médias em diferentes tipos de experimentos, como:\n\n-   Esquemas fatoriais duplos e triplos (em DIC e DBC);\n\n-   Parcelas subdivididas (em DIC e DBC);\n\n-   Fatoriais com tratamento adicional (duplo ou triplo, em DIC e DBC).\n\nOferece ferramentas para:\n\n-   Comparação de múltiplas médias (em tratamentos qualitativos);\n\n-   Ajuste de modelos de regressão até o terceiro grau (para tratamentos quantitativos);\n\n-   Análise de resíduos para verificar pressupostos do modelo.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ExpDes.pt)\n```\n:::\n\n\n\n\n## **Teste de Tukey com pacote `ExpDes.pt` (Experimento em DIC)**\n\n### Instalar e carregar o pacote\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carregue o pacote\nlibrary(ExpDes.pt)\n```\n:::\n\n\n\n\n### **Criar os dados de exemplo**\n\nVamos supor que avaliamos a produtividade de 4 cultivares de milho, com 4 repetições cada:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fator: tratamentos (cultivares)\ntrat <- c(rep(\"A\", 4), rep(\"B\", 4), rep(\"C\", 4), rep(\"D\", 4))\n\n# Resposta: produtividade em kg/ha\nresp <- c(5000, 5200, 5100, 4950,\n          5300, 5400, 5350, 5250,\n          4800, 4700, 4900, 4750,\n          5100, 5000, 4950, 5050)\n```\n:::\n\n\n\n\n### Análise de variância com Tukey (DIC)\n\n`dic()`: realiza a análise para Delineamento Inteiramente Casualizado.\n\n`trat`: vetor com os tratamentos (fator qualitativo).\n\n`resp`: vetor com a variável resposta (produtividade).\n\n`quali = TRUE`: indica que os tratamentos são qualitativos.\n\n`mcomp = \"tukey\"`: escolhe o teste de comparação de médias de Tukey.\n\n`sigT = 0.05`: nível de significância (5%).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndic(trat, resp, quali = TRUE, mcomp = \"tukey\", sigT = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM     Fc       Pr>Fc\nTratamento  3 581250 193750 27.761 0.000011051\nResiduo    12  83750   6979                   \nTotal      15 665000                          \n------------------------------------------------------------------------\nCV = 1.65 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.6642314 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.7743792 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na \t B \t 5325 \n b \t A \t 5062.5 \n b \t D \t 5025 \n  c \t C \t 4787.5 \n------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n\n\n## **Teste de Tukey com pacote `ExpDes.pt` (dados transformados em raiz - sqrt)**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninsects <- InsectSprays\n\ninsects$count2 <- sqrt(insects$count)\n\ndic(insects$spray,\n    insects$count2,\n    mcomp = \"tukey\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ      QM     Fc                      Pr>Fc\nTratamento  5  88.438 17.6876 44.799 0.000000000000000000063345\nResiduo    66  26.058  0.3948                                  \nTotal      71 114.496                                          \n------------------------------------------------------------------------\nCV = 22.34 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.6813773 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.5855673 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na \t F \t 4.018617 \na \t B \t 3.876631 \na \t A \t 3.760678 \n b \t D \t 2.164354 \n bc \t E \t 1.809461 \n  c \t C \t 1.244857 \n------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n\n\n## **Teste de Scott Knott - pacote `ExpDes.pt`**\n\nO método de Scott-Knott é uma técnica eficiente para comparar tratamentos em experimentos, especialmente quando o objetivo é agrupar médias em conjuntos homogêneos. Esse método busca minimizar a variabilidade dentro dos grupos e, ao mesmo tempo, maximizar a diferença entre eles, evitando sobreposição. Para isso, as médias dos tratamentos são ordenadas, permitindo sua classificação. Em seguida, são avaliadas todas as possíveis divisões (partições) com o propósito de identificar a melhor separação entre os grupos.\n\n### **Experimento em DIC**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Agrupamento pelo teste de Scott Knott: O teste agrupa médias e serve para 1 fator apenas.\n\ndic(insects$spray,\n    insects$count2,\n    mcomp = \"sk\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL      SQ      QM     Fc                      Pr>Fc\nTratamento  5  88.438 17.6876 44.799 0.000000000000000000063345\nResiduo    66  26.058  0.3948                                  \nTotal      71 114.496                                          \n------------------------------------------------------------------------\nCV = 22.34 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos ( Shapiro-Wilk ) \nValor-p:  0.6813773 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.5855673 \nDe acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Scott-Knott\n------------------------------------------------------------------------\n  Grupos Tratamentos   Medias\n1      a           F 4.018617\n2      a           B 3.876631\n3      a           A 3.760678\n4      b           D 2.164354\n5      b           E 1.809461\n6      c           C 1.244857\n------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n\n\n\n### **Experimento em DBC**\n\n#### Criar dados de exemplo\n\nVamos supor que testamos 5 cultivares de feijão, com 4 blocos (repetições):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tratamentos (cultivares)\ntrat <- c(rep(\"A\",4), rep(\"B\",4), rep(\"C\",4), rep(\"D\",4), rep(\"E\",4))\n\n# Blocos (repetições)\nbloco <- rep(1:4, 5)\n\n# Produtividade em kg/ha (variável resposta)\nresp <- c(1800, 1850, 1750, 1820,  # A\n          2100, 2150, 2080, 2120,  # B\n          1700, 1680, 1720, 1690,  # C\n          1950, 1980, 1930, 1970,  # D\n          2200, 2250, 2220, 2180)  # E\n```\n:::\n\n\n\n\n#### **Análise de variância + Scott-Knott (DBC)**\n\n`dbc()`: função para analisar um experimento em Delineamento em Blocos Casualizados.\n\n`trat`: vetor com os tratamentos (cultivares).\n\n`bloco`: vetor com os blocos (repetições).\n\n`resp`: vetor com a variável resposta (ex: produtividade).\n\n`quali = TRUE`: indica que os tratamentos são qualitativos.\n\n`mcomp = \"sk\"`: aplica o **teste de Scott-Knott** para comparação de médias.\n\n`sigT = 0.05`: nível de significância de 5%.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbc(trat, bloco, resp, quali = TRUE, mcomp = \"sk\", sigT = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n           GL     SQ     QM      Fc   Pr>Fc\nTratamento  4 719620 179905 263.919 0.00000\nBloco       3   4820   1607   2.357 0.12313\nResiduo    12   8180    682                \nTotal      19 732620                       \n------------------------------------------------------------------------\nCV = 1.33 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos \nvalor-p:  0.55218 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nTeste de homogeneidade de variancia \nvalor-p:  0.2899448 \nDe acordo com o teste de oneillmathews a 5% de significancia, as variancias podem ser consideradas homogeneas.\n------------------------------------------------------------------------\n\nTeste de Scott-Knott\n------------------------------------------------------------------------\n  Grupos Tratamentos Medias\n1      a           E 2212.5\n2      b           B 2112.5\n3      c           D 1957.5\n4      d           A 1805.0\n5      e           C 1697.5\n------------------------------------------------------------------------\n```\n\n\n:::\n:::\n",
    "supporting": [
      "analise_estatistica_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}