---
title: "analise_estatistica"
---

# Análises estatísticas

#### Tipos de testes para análise estatística

Nesta aula, serão explorados diferentes tipos de análises estatísticas, considerando a quantidade e a natureza das variáveis independentes (ou níveis dos fatores), assim como o número de tratamentos ou grupos experimentais que serão comparados.

#### Teste t

O teste t é um dos métodos estatísticos mais comuns para comparar médias entre grupos. Ele é especialmente indicado quando se deseja avaliar se duas amostras apresentam diferenças estatisticamente significativas. Como em qualquer teste estatístico, o resultado inclui o valor de p, que indica a probabilidade de que a diferença observada entre as médias tenha ocorrido por acaso.

No RStudio, o teste t pode ser facilmente aplicado utilizando a função `t.test()`.

#### Aplicando o teste t em um conjunto de dados

O teste t para amostras independentes verifica se há evidências suficientes para afirmar que as médias de dois grupos são diferentes. Esse teste parte do pressuposto de que os grupos são independentes, ou seja, os dados de um grupo não interferem nos dados do outro.

#### Exemplo prático

Um experimento foi realizado para avaliar o efeito do micronutriente magnésio (Mg), adicionado na solução do solo, sobre o controle de uma doença em plantas. O experimento seguiu um delineamento inteiramente casualizado com 10 repetições. Dois tratamentos foram considerados: o controle ("control"), sem aplicação do micronutriente, e o tratamento com magnésio ("Mg2"), onde o mineral foi aplicado. Em cada repetição, foi medido o comprimento médio (em milímetros) das lesões nas plantas.

Os dados usados neste exemplo estão disponíveis em uma planilha online no Google Sheets. Para importar esses dados diretamente no R, foi utilizado o pacote `gsheet`, que facilita a leitura de planilhas hospedadas no Google Sheets.

```{r}
#Primeiramente, carregou-se a biblioteca com o comando:
library(gsheet)

#Em seguida, os dados foram lidos a partir do link da planilha online usando a função gsheet2tbl, que converte a planilha em um data frame no R:
dat_mg <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137")
```

Após importar os dados, realizou-se uma visualização gráfica utilizando o pacote **ggplot2**. O gráfico produzido foi um **jitter plot**, que auxilia na visualização da distribuição dos pontos de dados para cada tratamento (**trat**) em relação à variável analisada (**comp**). Esse tipo de gráfico é útil para evitar a sobreposição dos pontos e mostrar a dispersão real das observações.

```{r}
library(ggplot2)
dat_mg |> 
  ggplot(aes(trat, comp))+
  geom_jitter(width=0.1)
```

Esse gráfico é ideal para identificar padrões, verificar a presença de valores sobrepostos e analisar as variações entre os diferentes grupos experimentais.

A seguir, vamos começar a análise dos dados, extraindo medidas estatísticas que resumem o comportamento geral do conjunto, considerando tanto a tendência central quanto a dispersão dos valores.

```{r}
library(dplyr)
data2 <- dat_mg |>
  group_by(trat) |>
  summarise(
    mean_com = mean(comp),
    sd_comp = sd(comp),
    var_comp = var(comp),
    n = n(),
    se_comp = sd_comp / sqrt(n - 1),
    ci = se_comp * qt(0,025, df = 9))
data2

```

Nesta etapa, os dados serão representados em um gráfico de barras verticais que inclui barras de erro padrão, permitindo visualizar a média e a variabilidade dos grupos de forma clara.

```{r}
data2 |> 
  ggplot(aes(trat, mean_com)) +
  geom_col(width = 0.5,
           fill = "#99E89D") +
  geom_errorbar(aes(
    ymin = mean_com - se_comp,
    ymax = mean_com + se_comp),
    width = 0.1) +
  ylim(0,20) +
labs(x = "Tratamentos", y = "Tamanho médio das lesões (mm)")
```

Intervalo de confiança:

```{r}
data2 |> 
  ggplot(aes(trat, mean_com)) +
  geom_col(width = 0.5, fill = "#99E89D") +
  geom_errorbar(aes(
    ymin = mean_com - ci,
    ymax = mean_com + ci),
    width = 0.1) +
  ylim(0,20) +
labs(x = "Tratamentos", y = "Tamanho médio das lesões  (mm)")
```

Depois de importar e visualizar os dados referentes aos tratamentos com magnésio, foi realizada a transformação da estrutura dos dados e aplicada uma análise estatística para comparar os grupos.

Para isso, utilizou-se a função **pivot_wider()** do pacote **tidyr**, que reorganiza os dados do formato longo — no qual os tratamentos estão listados em uma única coluna — para o formato largo, onde cada tratamento passa a ser representado por uma coluna separada contendo seus respectivos valores.

```{r}
library(dplyr)
library(tidyr)  # <- Adicione isso para usar pivot_wider()
dat_mg2 <- dat_mg |>
  pivot_wider (names_from = trat, values_from = comp) |> #Transformando o formato dos dados: O que era uma coluna "longa" vai virar várias colunas "largas".
  ##   Pivot (passar de longo para largo)
  
  dplyr::select(-rep)
```

Dessa forma, a coluna **trat**, que anteriormente indicava os grupos de tratamento (como "control" e "Mg2"), foi dividida em colunas separadas para cada grupo, o que facilita a aplicação de testes estatísticos de comparação. A coluna **rep**, referente às repetições do experimento, foi descartada, pois não era necessária para essa etapa da análise.

Em seguida, aplicou-se a função **t.test()** para comparar as médias dos dois tratamentos: o grupo controle (sem aplicação de magnésio) e o grupo Mg2 (com aplicação do magnésio).

```{r}
attach(dat_mg2)

t_results <- t.test(control, Mg2)
t_results
```

#### Interpretação do valor de p

O resultado do teste apresenta o valor de p (p-value), que indica a probabilidade de encontrar uma diferença entre as médias igual ou maior do que a observada, considerando que a hipótese nula seja verdadeira.

A hipótese nula (H₀) postula que as médias dos dois grupos são iguais, enquanto a hipótese alternativa (H₁) sugere que as médias são diferentes.

Quando o valor de p é pequeno, geralmente inferior a 0,05, rejeitamos a hipótese nula. Isso significa que a diferença entre os grupos é estatisticamente significativa, apoiando a hipótese alternativa de que os grupos realmente diferem.

Assim, o teste t aplicado permite avaliar se a aplicação do magnésio (Mg2) produziu um efeito significativo em comparação ao controle.

#### Análise e interpretação do teste t com suporte de pacotes no R

Depois de realizar o teste t para comparar dois tratamentos aplicados em plantas — como o controle e a suplementação com magnésio — foram utilizadas ferramentas adicionais no R para facilitar a interpretação, organização e visualização dos resultados de forma mais intuitiva.

O pacote **report** foi empregado para gerar automaticamente uma descrição em linguagem natural dos resultados do teste t. Essa ferramenta é especialmente útil para criar resumos claros e acessíveis, ideais para relatórios e artigos científicos.

```{r}
library(report) #Pacote para explicar os resultados das análises
report(t_results)
```

A função **report()** realiza uma análise interpretativa do resultado do teste t armazenado no objeto `t_results`. Ela apresenta informações importantes, como as estatísticas do teste, o valor de p, as médias dos grupos comparados, além de uma descrição textual que indica se a diferença entre os grupos é estatisticamente significativa ou não.

Como o objeto `t_results` foi criado a partir dos dados no formato longo, não foi preciso realizar nenhuma transformação adicional para utilizar a função **report()** de forma direta.

#### Realização do teste t utilizando o pacote rstatix

Uma alternativa eficiente para executar o teste t, especialmente quando se trabalha com dados no formato longo, é usar o pacote **rstatix**. Esse pacote oferece uma sintaxe simples e integrada ao tidyverse, facilitando a análise.

No comando utilizado, `comp ~ trat` indica que a variável resposta **comp** será comparada entre os diferentes níveis da variável **trat**. O resultado do teste é armazenado no objeto `test`, que pode ser posteriormente utilizado para geração de gráficos ou relatórios.

```{r}
library(rstatix)
test <- t_test(comp ~ trat, data = dat_mg)
test
```

#### Visualização gráfica com valor de *p* usando `ggpubr`

Para enriquecer a análise, foi criado um boxplot utilizando o pacote **ggpubr**, que simplifica a criação de gráficos estatísticos e permite adicionar diretamente os valores de p, facilitando a interpretação visual dos resultados.

```{r}
library(ggpubr)

p <- ggboxplot(
  dat_mg, x = "trat", y = "comp",
  color = "trat", palette = "jco")
print(p)
```

Em seguida, o valor de p resultante do teste t foi inserido manualmente no gráfico utilizando a função **stat_pvalue_manual()**, que destaca se existe diferença estatisticamente significativa entre os grupos. O argumento `y.position = 18` determina a altura onde o valor de p será exibido, enquanto a função **ylim(0, 20)** ajusta os limites do eixo y para garantir que tanto os dados quanto os textos fiquem bem acomodados na visualização.

```{r}
#add p-value manually
p + stat_pvalue_manual(test, label = "p",
  y.position = 18)+
    ylim(0,20)+
  labs(x = "Tratamento",
       y = "Comprimento (mm)")

ggsave("plot2.png", bg = "white") #Por fim, o gráfico foi salvo em um arquivo de imagem.

```

#### Verificação das suposições para o teste t: normalidade e homogeneidade de variâncias

Antes de aplicar o teste t para comparar médias entre dois grupos independentes, é essencial confirmar se os dados cumprem as premissas fundamentais desse teste paramétrico. Entre essas premissas estão a normalidade da distribuição dos dados em cada grupo e a igualdade das variâncias entre eles. Caso essas condições não sejam atendidas, os resultados do teste podem ser comprometidos, sendo necessário considerar métodos alternativos ou ajustes.

Para verificar a normalidade dos dados em cada grupo, utilizou-se o teste de Shapiro-Wilk por meio da função `shapiro.test()`. Esse teste tem como hipótese nula (H₀) que os dados seguem uma distribuição normal. Assim, se o valor de p for maior que 0,05, não há evidências para rejeitar a normalidade, ou seja, os dados podem ser considerados normalmente distribuídos. Por outro lado, um valor de p menor que 0,05 indica que os dados não seguem uma distribuição normal.

Além do teste estatístico, histogramas foram elaborados para fornecer uma visualização gráfica da distribuição dos dados em cada grupo.

```{r}
#Testando a normalidade dos dados
shapiro.test(Mg2)
shapiro.test(control)

hist(Mg2)
hist(control)
```

Os histogramas são úteis para identificar visualmente possíveis desvios da normalidade, como assimetrias ou a presença de valores extremos (outliers).

Para uma avaliação visual mais detalhada da normalidade, utiliza-se o **QQ-Plot** (gráfico quantil-quantil), que permite comparar a distribuição da amostra com a distribuição normal teórica. No R, isso pode ser feito facilmente com as funções `qqnorm()` e `qqline()`, aplicadas a cada variável analisada, para observar se os pontos se alinham à linha reta, indicando conformidade com a distribuição normal.

```{r}
qqnorm (Mg2)
qqline(Mg2)
```

```{r}
qqnorm(control)
qqline(control)
```

#### Teste de homogeneidade das variâncias: var.test()

Para avaliar se as variâncias dos dois grupos são equivalentes, foi aplicado o teste de Fisher, disponível na função `var.test()`. A hipótese nula (H₀) deste teste assume que as variâncias dos grupos são iguais.

Quando o valor de p é maior que 0,05, conclui-se que as variâncias são homogêneas. Por outro lado, se o valor de p for inferior a 0,05, indica-se que as variâncias diferem significativamente, caracterizando heterocedasticidade.

```{r}
#Testando a homogeneidade das variâncias
var.test(dat_mg2$Mg2,
         dat_mg2$control) 
```

#### Ajuste do teste t conforme a homogeneidade das variâncias

Quando o teste aponta para variâncias homogêneas, o teste t pode ser realizado usando o argumento padrão `var.equal = TRUE`. Porém, se for identificada heterocedasticidade — ou seja, variâncias diferentes entre os grupos — é necessário ajustar o teste t para considerar essa condição, alterando o parâmetro para refletir essa diferença.

```{r}
t_results <- t.test(control, Mg2, var.equal = FALSE)
# O parâmetro var.equal = FALSE ativa a correção de Welch, que ajusta os graus de liberdade do teste, tornando-o mais robusto quando as variâncias são diferentes.
```

### Teste t para amostras dependentes

Um experimento foi conduzido para avaliar o efeito do uso de uma escala diagramática na precisão e acurácia das estimativas visuais de severidade feitas por avaliadores. A hipótese levantada foi que a utilização dessa escala melhora a exatidão das avaliações em comparação com avaliações realizadas sem o auxílio da escala. Dez avaliadores foram selecionados aleatoriamente, e cada um realizou duas avaliações em momentos diferentes. Foram coletadas cinco variáveis relacionadas à concordância das estimativas. Como as medições são repetidas para os mesmos indivíduos, trata-se de amostras dependentes.

#### Comparação entre dois grupos (teste t pareado)

Os dados utilizados foram importados diretamente de uma planilha online do Google Sheets, por meio do pacote **gsheet**. Essa planilha contém escores de acurácia obtidos antes e depois da intervenção, denominados “Unaided” (sem auxílio) e “Aided1” (com auxílio).

```{r}
#importação dos dados
escala <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173")
head(escala)

```

### Teste t pareado

O teste t pareado é utilizado para determinar se existe uma diferença significativa entre dois momentos de avaliação realizados pelas mesmas pessoas (antes e depois da intervenção). No R, esse teste pode ser aplicado com a função `t_test()` do pacote **rstatix**.

O argumento `paired = TRUE` especifica que as amostras são dependentes, ou seja, as medições são feitas nos mesmos indivíduos em duas ocasiões diferentes. Já o parâmetro `var.equal = FALSE` ajusta o teste para considerar possíveis diferenças nas variâncias, utilizando o método de Welch.

```{r}
test <- t_test(acuracia ~ assessment,
       data = escala,
       paired = TRUE,
       var.equal = FALSE)
test
```

Para facilitar a interpretação dos resultados, é criado um boxplot que mostra a distribuição dos escores de acurácia para cada tipo de avaliação, comparando as condições “Unaided” e “Aided1”.

```{r}
escala |> 
  ggplot(aes(assessment, acuracia))+
         geom_boxplot()
```

#### Testando suposições

```{r}
unaided <- escala |>
  filter(assessment == "Unaided") |>
  pull(acuracia)

aided <- escala |>
  filter(assessment == "Aided") |>
  pull(acuracia)


if (length(unaided) >= 2 && length(aided) >= 2) {
  var.test(unaided, aided) # Homogeneidade de variâncias
} else {
  message("Número de observações insuficiente em um dos grupos.")
}

hist(unaided)

if (length(aided) > 1) {
  hist(aided)
} else {
  message("Não há dados suficientes para gerar o histograma de 'aided'.")
}     # Visualização da distribuição

shapiro.test(unaided) # Normalidade
```

Verifica se os dados atendem às premissas do teste t (normalidade e variâncias iguais).

-   Se **normalidade** falha → usar teste **não paramétrico**.

-   Se **variâncias são diferentes**, continuar com `var.equal = FALSE`.

### **Teste não paramétrico equivalente (Wilcoxon):**

Um teste não paramétrico não faz nenhuma suposição sobre a distribuição da população ou tamanho da amostra. O `Wilcox.test` é o teste para dados não paramétricos equivalente ao *teste t* para dados paramétricos. o teste de `Wilcoxon` é usado para testar se as medianas das amostras são iguais nos casos em que a suposição de normalidade não é satisfeita ou quando não for possível checar essa suposição.

Usar Wilcoxon se os dados não forem normais. O primeiro é o equivalente ao t pareado, o segundo ao t para amostras independentes.

```{r}
# wilcox.test(unaided, aided)             # Wilcoxon pareado
# wilcox.test(unaided, aided, paired = FALSE) # Mann-Whitney (independente)
```

# **Transformação de dados no R Studio**

Antes de iniciar uma análise estatística no R, pode ser necessário transformar os dados, dependendo de suas características e das exigências do método analítico escolhido. Essas transformações são úteis para adequar os dados aos pressupostos da análise estatística, como a normalidade da distribuição e a homogeneidade das variâncias.

Antes de realizar transformações, precisamos entender a natureza dos dados. Vamos trabalhar com o conjunto de dados mofo, presente na planilha dados-diversos.

### Importando o conjunto de dados

```{r}
library(tidyverse)
library(readxl)

mofo <- read_excel("dados.xlsx", "mofo")
```

#### Visualização dos dados

```{r}
mofo |>
  ggplot(aes(treat, inc)) +
  facet_wrap(~study) +
  geom_point(color = "#1A8C8C") +
  labs(
    x = "Tratamento",
    y = "Incidência"
  )
```

Histograma para visualizar a incidência e outro para visualizar os dados de escleródio.

```{r}
inc <- mofo |>
  ggplot(aes(inc))+
  geom_histogram(fill = "#1A8C8C")
#Para o scleródio
mofo |>
    ggplot(aes(scl))+
    geom_histogram(fill = "#1A8C8C")
```

Boxplot:

```{r}
scl <- mofo |>
  ggplot(aes(scl))+
  geom_boxplot()
library(patchwork)
inc + scl
```

Para achar a média podemos usar as funções \$, mean+conjunto ou summary.

```{r}
mofo$scl

mean(mofo$scl)
```

Os dados podem ser transformados de diferentes formas, sendo as mais comuns log e raiz quadrada. 

## **Transformação logarítmica**

A transformação logarítmica é uma técnica comum utilizada na análise de dados para lidar com variáveis que apresentam distribuição assimétrica ou variância heterogênea. Ela pode ajudar a estabilizar a variância, aproximar os dados de uma distribuição normal e melhorar a interpretação dos resultados estatísticos.

No RStudio, a transformação logarítmica pode ser aplicada facilmente com funções como `log()`, `log10()` (logaritmo na base 10) ou `log2()` (logaritmo na base 2), dependendo do contexto da análise. Podemos realizar essa transformação com o uso da função `mutate`. Através da função `mutate()` realizamos a criação/adição de uma nova variável (ou novas variaveis), que são funções de variáveis existentes, e também criamos/modificamos colunas.

```{r}
mofo2 <- mofo |>
  mutate (scl2 = log(scl))
  mofo2
```

### Visualizar os dados tranformados

Histograma

```{r}
mofo2 |>
  ggplot(aes(scl2)) +
  geom_histogram(bins = 10, fill = "#1A8C8C", color = "black")

```

## Transformação em raiz quadrada

A transformação em raiz quadrada é uma técnica estatística utilizada para corrigir assimetrias nos dados e estabilizar a variância, especialmente quando os dados representam contagens ou variáveis discretas com distribuição assimétrica.

Esse tipo de transformação é útil quando os dados apresentam variância crescente com a média, o que viola pressupostos importantes de muitos testes estatísticos, como a ANOVA e o teste t.

No RStudio, a transformação em raiz quadrada pode ser feita com a função `sqrt()`:

```{r}
mofo2 <- mofo |>
  mutate (scl2 = sqrt(scl))
  mofo2
```

### Visualizar os dados tranformados

Histograma

```{r}
  mofo2 |>
    ggplot(aes(scl2))+
    geom_histogram(bins = 10, fill = "#1A8C8C", color = "black")
```

## **Transformação de dados Box-Cox**

A transformação de Box-Cox é uma técnica estatística utilizada para estabilizar a variância e aproximar os dados de uma distribuição normal. Diferente de outras transformações fixas, como log ou raiz quadrada, a Box-Cox aplica uma família de transformações parametrizadas, permitindo encontrar automaticamente o melhor ajuste aos pressupostos dos modelos estatísticos.

Ela é especialmente útil quando não se sabe previamente qual transformação aplicar, pois estima um parâmetro lambda (λ) que define a forma ideal da transformação.

A transformação de Box-Cox é definida pela seguinte equação: y(lambda) = (x\^lambda - 1) / lambda

Nessa equação, “x” representa a variável original, “y(lambda)” representa a variável transformada para um determinado valor de lambda e “lambda” é o parâmetro de transformação que varia de -∞ a +∞. O valor de lambda determina o tipo de transformação aplicada: Se lambda = 0, a transformação de Box-Cox é equivalente ao logaritmo natural (ln). Se lambda = 1, a transformação de Box-Cox é equivalente à transformação linear (sem transformação). Se lambda \< 0, é aplicada uma transformação inversa.

A transformação Box-Cox pode ser aplicada usando a função `boxcox()` do pacote `MASS.`

```{r}
library(MASS)
```

**Exemplo:** *InsectSprays*, do próprio R. A função `boxcox()` pode ser utilizada para calcular a transformação de Box-Cox e identificar o valor de lambda ótimo para uma determinada variável. Essa função retorna uma lista de resultados, incluindo o valor de lambda ótimo e gráficos de diagnóstico.

### Importando dados

```{r}
insects <- InsectSprays

b <- boxcox(lm(insects$count+0.1 ~1))
```

```{r}
lambda <- b$x[which.max(b$y)]
lambda
```

```{r}
insects$count2 <- (insects$count ^ lambda - 1) / lambda

hist(insects$count, 
     col = "#1A8C8C",        # cor do histograma
     main = "Histograma de Count Transformado", 
     xlab = "Contagem Transformada")
```

```{r}
hist(insects$count2,
     col = "#1A8C8C",
     main = "Histograma de Count2 Transformado", 
     xlab = "Contagem Transformada"
)
```

# **ANOVA** (Análise de Variância)

É um teste estatístico utilizado para comparar as médias de três ou mais grupos e verificar se há diferenças estatisticamente significativas entre elas. Ao invés de comparar pares de médias individualmente, como no teste t, a ANOVA avalia simultaneamente a variabilidade entre os grupos e dentro dos grupos.

A ANOVA usa o teste F para testar a hipótese nula de que as médias populacionais são iguais contra a hipótese alternativa de que pelo menos uma média é diferente das demais.

## **Anova com 1 fator (***One-way Anova*)

É uma técnica estatística utilizada para comparar as médias de três ou mais grupos que diferem em relação a um único fator (ou variável independente). Esse fator pode representar, por exemplo, diferentes tratamentos, cultivares, doses de um produto ou condições experimentais.

O objetivo é verificar se há diferença significativa entre as médias dos grupos. A hipótese nula assume que todas as médias são iguais, enquanto a hipótese alternativa indica que pelo menos uma delas é diferente.

**Exemplo:** Experimento com um fator e em delineamento inteiramente casualizado (DIC) para comparar o crescimento micelial de diferentes espécies de um fungo fitopatogênico. A resposta a ser estudada é a TCM = taxa de crescimento micelial.

### Importando o conjunto de dados:

```{r}
library(readxl)
micelial <- read_excel("dados.xlsx", "micelial")
head(micelial)
```

### Carregando pacotes:

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
```

### **Visualização dos dados**:

```{r}
micelial |>
  ggplot(aes(x = especie, y = tcm)) +
  geom_boxplot(utlier.color = NA, fill = "#1A8C8C", color = "black") +
   geom_jitter(width = 0.1)+
  labs(
    x = "Espécie Fúngica",
    y = "Taxa de Crescimento Micelial"
  )
```

### **Modelo usando `aov()`**

Para verificar os dados usando anova, um novo modelo para atribuir a função `aov()` contendo os argumentos tratamento em função da variável resposta deve ser criado (ex.: tcm \~ espécie), o banco de dados referido deve ser enunciado após o argumento separado por vírgula seguido do nome data = nome do conjunto de dados (ex.: micelial). Depois disso, pede um quadro de resumo do novo modelo criado.

```{r}
aov1 <- aov(tcm ~ especie, data = micelial)
summary(aov1)
```

```{r}
aov2 <- lm(tcm ~ especie, data = micelial) # Outra forma de fazer a ANOVA
aov2
```

#### **Testando as premissas**

##### **Testes de Normalidade e Homocedasticidade**

**Teste de Normalidade**

A normalidade dos dados é uma condição importante para muitos testes estatísticos. Ela garante que os resultados das análises, como ANOVA e teste t, sejam confiáveis, pois esses métodos assumem que os dados vêm de uma população com distribuição normal.

**Teste de Homocedasticidade**

Na ANOVA, é necessário que os grupos comparados tenham variâncias semelhantes. Essa condição é chamada de homocedasticidade. Se as variâncias forem muito diferentes (heterocedasticidade), os resultados do teste F podem ser comprometidos.

Para testar as premissas, é necessário instalar e carregar o pacote `performance` e o pacote `DHARMa`.

O pacote `performance` permite checar as premissas `(check_)`, já o pacote `DHARMA` (*Distributed Hierarchical Accumulation of Residuals for Generalized Linear Models in R*) é para visualizar os dados pelo diagnóstico do resíduo. O pacote `DHARMa` permite faz uma comparação dos resíduos simulados, que são gerados pelo pacote, com os resíduos observados e ver graficamente quando a distribuição dos dados não é normal e/ou quando há variação heterocedástica.

Após isso, deve-se fazer o teste de normalidade dos resíduos com a interação entre a anova e os resíduos.

```{r}
library(performance)
check_heteroscedasticity(aov1)
```

```{r}
check_normality(aov1)
```

```{r}
library(DHARMa)
hist (aov1$residuals) #Ou hist(residuals(aov1))

# Mostra a distribuição visual dos resíduos.
```

```{r}
qqnorm(aov1$residuals)
qqline(aov1$residuals)
```

```{r}
plot(simulateResiduals(aov1))
```

```{r}
shapiro.test(aov1$residuals) #Ou shapiro.test(residuals(aov1)) 
```

O teste verifica a seguinte hipótese:

-   **Hipótese nula (H₀)**: Os dados seguem distribuição normal;

-   **Hipótese alternativa (H₁)**: Os dados não seguem distribuição normal.

Comparamos o p-valor com um nível de significância comum, geralmente **α = 0,05**:

**p-valor = 0,8782 \> 0,05** → Não rejeitamos a hipótese nula

Homogeneidade de variâncias:

```{r}
# Teste de Bartlett – mais sensível a desvios da normalidade
bartlett.test(tcm ~ especie, data = micelial)
```

```{r}
# Teste de Levene – mais robusto à violação da normalidade
library(car)
leveneTest(tcm ~ especie, data = micelial)
```

##### Interpretação dos Resultados:

-   **p-valor \> 0,05** → Não há evidência de variâncias diferentes → Premissa atendida.

-   **p-valor \< 0,05** → As variâncias são significativamente diferentes → Premissa violada.

#### Comparações múltiplas e médias ajustadas

**Pacote “emmeans”**

(“*estimated marginal means*”, ou médias marginais estimadas) é usado para realizar testes de comparação de médias entre grupos, ajustando para outros fatores importantes que podem influenciar as médias. O pacote é particularmente útil em modelos lineares generalizados (GLM).

`emmeans(...)`: calcula as médias ajustadas (médias marginais) para cada grupo de `especie` com base no modelo.

Importante para comparações entre grupos quando há mais de 2 níveis.

```{r}
library(emmeans)
m <- emmeans(aov2, ~ especie)
m
```

**Testes post-hoc (comparações entre grupos)**

**Pacote “multcomp” -** `multcomp`: para fazer comparações múltiplas entre grupos.

Testes simultâneos e intervalos de confiança para hipóteses lineares gerais em modelos paramétricos, incluindo efeitos lineares, lineares generalizados, lineares mistos e modelos de sobrevivência.

**Pacote “multcompView” -** `multcompView`: para gerar **letras compactas**, indicando quais grupos são diferentes.

Converte um vetor lógico ou um vetor de valores-*p* ou uma matriz de correlação, diferença ou distância em uma exibição identificando os pares para os quais as diferenças não foram significativamente diferentes.

**Cld -** Extrai e exibe informações sobre todas as comparações pareadas de médias de mínimos quadrados.

```{r}
library(multcomp)
library(multcompView)

cld(m)
```

```{r}
pairs(m) #Mostra os testes pareados (comparação entre pares de grupos).
```

```{r}
pwpm(m) #Exibe uma matriz com as médias na diagonal e comparações entre os grupos fora dela.
```

## ANOVA fatorial (two-way ANOVA)

A ANOVA fatorial é utilizada quando há duas ou mais variáveis independentes (fatores), cada uma com dois ou mais níveis. Ela é apropriada para experimentos fatoriais completos, nos quais todas as combinações possíveis entre os níveis dos fatores são testadas. Além de avaliar os efeitos individuais de cada fator, essa análise também permite verificar se existe interação entre os fatores, ou seja, se o efeito de um fator depende dos níveis do outro.

### Importando o conjunto de dados:

Banco de dados utilizado: fungicida-vaso (conjunto de dados do dados diversos). Objeto nomeado como fung_vaso.

```{r}
library(tidyverse)
library(readxl)

fung_vaso <- read_xlsx("dados.xlsx", sheet = "fungicida_vaso")
```

**`factor(dose)`**: converte a variável `dose` em fator (categórica);

**`severity * 100`**: transforma a variável de severidade em percentual;

**`geom_jitter()`**: mostra os pontos com leve deslocamento horizontal, evitando sobreposição;

**`facet_wrap(~ treat)`**: separa os gráficos por tratamento (`treat`).

```{r}
fung_vaso |> 
  ggplot(aes(factor(dose), severity*100))+ #transformando dose em um fator e ##transformar para percentual *100
  geom_jitter(width = 0.1)+
  facet_wrap(~ treat)
```

### Modelo linear com interação

```{r}
m_anti <- lm(severity ~ treat * dose, data = fung_vaso)
anova(m_anti)
```

#### Checagem das premissas e visualização com DHARMa:

```{r}
library(DHARMa)
plot(simulateResiduals(m_anti))
```

#### Médias ajustadas com `emmeans`

```{r}
media_anti <- emmeans(m_anti, ~ treat | dose)
media_anti
```

#### Comparações múltiplas

```{r}
cld(media_anti)
```

##### Agora inverte: médias de doses dentro de tratamentos

```{r}
media_anti <- emmeans(m_anti, ~ dose | treat)
media_anti
cld(media_anti)
```

#### Coeficiente de variação

Essa função do pacote `agricolae` calcula o coeficiente de variação (CV%) do modelo.

Ajuda a avaliar a precisão experimental. Valores abaixo de 20% geralmente são considerados bons (mas depende do contexto).

```{r}
library(agricolae)
cv.model(m_anti)
```

#### E se não houver interação significativa?

Mostra os efeitos **individuais de dose e tratamento**, ignorando a interação.

```{r}
library(patchwork)

p1 <- fung_vaso |> 
  ggplot(aes(factor(dose), severity*100)) + 
  geom_jitter(width = 0.1)
p2 <- fung_vaso |> 
  ggplot(aes(treat, severity*100)) + 
  geom_jitter(width = 0.1)
p1 + p2
```

#### Visualização da interação

-   Gera um gráfico de interação;

-   Se as linhas forem paralelas, não há interação;

-   Se forem cruzadas ou afastadas, pode indicar interação.

```{r}
interaction.plot(fung_vaso$treat, fung_vaso$dose, fung_vaso$severity)
```

Tabela

|          | 0.5     | 0.2    |
|----------|---------|--------|
| LI       | 29.2 Aa | 5.0 Ab |
| TEBU     | 2.1 Ba  | 2.0 Aa |
| cv = 63% |         |        |

### Exemplo:

#### Pacote `epifitter` e dados:

```{r}
#install.packages("epifitter")
library(epifitter)
oidio <- PowderyMildew
```

#### Visualização dos dados filtrados

Filtra apenas 3 tipos de irrigação.

`sev*100`: transforma a severidade (que vai de 0 a 1) para percentual (0–100%).

`facet_grid(moisture ~ irrigation_type)`: cria um painel com um gráfico para cada combinação de `moisture` (umidade) e `irrigation_type` (tipo de irrigação).

O gráfico mostra como a doença evolui ao longo do tempo (`time`).

```{r}
oidio |> 
  filter(irrigation_type %in% c("MS", "MS above canopy", "Overhead")) |> 
  ggplot(aes(time, sev*100)) + 
  geom_jitter(width = 0.1) +
  facet_grid(moisture ~ irrigation_type)
```

#### Cálculo da AUDPC (Área Abaixo da Curva de Progresso da Doença)

`group_by(...)` agrupa os dados por tratamento (irrigação, umidade e bloco);

`AUDPC(...)` calcula a área abaixo da curva para cada grupo;

A AUDPC resume a intensidade da doença ao longo do tempo.

```{r}
library(dplyr)
library(epifitter)

oidio3 <- oidio |>
  group_by(irrigation_type, moisture, block) |>
  summarise(AUDPC = AUDPC(time, sev), .groups = "drop")
```

#### Visualizando a AUDPC

```{r}
oidio3 |> 
  filter(irrigation_type %in% c("MS", "MS above canopy", "Overhead")) |>
  ggplot(aes(irrigation_type, AUDPC, color = moisture)) +
  geom_point(width = 0.1) +
  scale_y_continuous(limits = c(0, 20))
```

#### ANOVA fatorial (efeito da irrigação e umidade na AUDPC)

```{r}
oidio4 <- oidio3 |> 
  filter(irrigation_type %in% c("MS", "MS above canopy", "Overhead"))

anov_oidio <- lm(AUDPC ~ irrigation_type * moisture, data = oidio4)
anova(anov_oidio)
```

#### Diagnóstico do modelo

```{r}
plot(simulateResiduals(anov_oidio))
```

#### Médias ajustadas com `emmeans`

```{r}
medias_oidio <- emmeans(anov_oidio, ~ irrigation_type | moisture)
medias_oidio
cld(medias_oidio)
```

Agora, inverte: mostra as médias de umidade dentro de cada tipo de irrigação.

```{r}
medias_oidio2 <- emmeans(anov_oidio, ~ moisture | irrigation_type)
medias_oidio2
cld(medias_oidio2)
```

#### Coeficiente de variação do modelo

Indica a precisão do experimento - valores menores geralmente indicam maior confiabilidade

```{r}
cv.model(anov_oidio)
```

Tabela

|           | H. moisture | M. moisture |
|-----------|-------------|-------------|
| MS        | 8.52 Aa     | 11.18 Ab    |
| MS Ac.    | 3.99 Ba     | 4.86 Bb     |
| Overhead  | 3.68 Ba     | 3.81 Ca     |
| CV = 6.41 |             |             |

## Anova Fatorial - 3 Fatores

### Exemplo:

Dados sobre a interação entre tipo de armazenamento e umidade.

```{r}
milho <- read_excel("dados.xlsx", "armazena")
milho |>
  filter(tempo ==8) |>
  ggplot(aes(factor(tipo), peso_mil,
             color = factor(umidade)))+
  geom_jitter(width = 0.1)+
  facet_wrap(~ umidade)
```

Testar a interação entre o tipo de armazenamento e o tempo 8

```{r}
milho2 <- milho |>
  filter(tempo ==8)

m2 <- aov(peso_mil ~ factor(tipo)*factor(umidade),
          data = milho2)
summary(m2)
```

Testanto tipo de inoculação na incidencia de *Fusarium* sp. em milho

```{r}
milho3 <- read_excel("dados.xlsx", "milho")

m4 <- aov(yield ~hybrid*method,
          data = milho3)
summary(m4)
```

Checagem das premissas

```{r}
check_heteroscedasticity(m4)
```

```{r}
plot(simulateResiduals(m4))
```

Médias ajustadas com `emmeans`

```{r}
medias_m4 <- emmeans(m4, ~ hybrid)
medias_m4
```

```{r}
cld(medias_m4)
```

Caso a interação não dê sifnificativa, tira a interação e deixa só o fator que teve significancia (isola o fator)

```{r}
m5 <- aov(yield ~hybrid, data = milho3)
summary(m5)
```

```{r}
m4 <- aov(yield ~hybrid,
          data = milho3)
summary(m5)
```

```{r}
check_heteroscedasticity(m5)
```

```{r}
medias_m5 <- emmeans(m5, ~hybrid)
medias_m5
```

```{r}
cld(medias_m5)
```

```{r}
pwpm(medias_m5)
```

## **ANOVA com bloco**

### **Anova com bloco - Delineamento em Blocos Casualizado (DBC)**

O (DBC) envolve os três princípios da experimentação: repetição, casualização e controle local. Neste caso, as condições locais não são homogêneas e podem ter efeito significativo sobre os tratamentos.

#### Carregando pacotes e dados

Usando o conjunto de dados fungicida_campo

```{r}
library(readxl)
library(Hmisc)
fung_campo <- read_xlsx("dados.xlsx", sheet = "fungicida_campo")
```

#### Gráfico de produção por tratamento

`mutate(TRAT = factor(TRAT))`: transforma os tratamentos (TRAT) em fatores para garantir que o `ggplot` os trate como categorias.

`geom_jitter`: mostra os dados de cada parcela/bloco, deslocados horizontalmente para evitar sobreposição.

`stat_summary(fun.data = "mean_cl_boot")`: adiciona médias com intervalos de confiança via bootstrap.

```{r}
fung_campo |> 
  mutate(TRAT = factor(TRAT)) |> 
  ggplot(aes(TRAT, PROD)) +
  geom_jitter(width = 0.2) +
  stat_summary(fun.data = "mean_cl_boot", colour = "red", width = 0.3)


```

#### Convertendo variáveis em fatores

Aqui, você transforma `TRAT` e `BLOCO` explicitamente em **fatores**, pois o R trata números como contínuos por padrão.

```{r}
fung_campo$TRAT <- factor(fung_campo$TRAT)
fung_campo$BLOCO <- factor(fung_campo$BLOCO)
```

#### **Modelo Anova com bloco**

ANOVA com efeito de blocos e tratamentos:

```{r}
anova_campo <- lm(PROD ~ BLOCO + TRAT, data = fung_campo)
anova(anova_campo)

```

#### Checagem das premissas

```{r}
library(performance)
library(DHARMa)
check_normality(anova_campo)
check_heteroscedasticity(anova_campo)
```

```{r}
library(DHARMa)
plot(simulateResiduals(anova_campo))
```

#### Estimativa e comparação das médias dos tratamentos

```{r}
means_campo <- emmeans(anova_campo, ~ TRAT)
means_campo
```

```{r}
library(multcomp)
cld(means_campo)
```

```{r}
plot(means_campo)
pwpp(means_campo)
pwpm(means_campo)
```

Análise da Severidade da Ferrugem (`FER`):

#### ANOVA com transformação logarítmica

```{r}
anova_fer <- lm(log(FER) ~ BLOCO + TRAT, data = fung_campo)
anova(anova_fer)
```

#### Diagnóstico do modelo

```{r}
plot(simulateResiduals(anova_fer))
```

#### Médias com back-transformation

```{r}
means_fer <- emmeans(anova_fer, ~ TRAT, type = "response")
```

```{r}
cld(means_fer)
plot(means_fer)
pwpp(means_fer)
pwpm(means_fer)
```

## **Delineamento em parcela subdividida (*Split-plot*)**

### Importando o conjunto de dados:

Exemplo:

```{r}
milho <- read_excel("dados.xlsx", "milho")
```

#### Visualizando os dados

```{r}
milho |> 
  
  ggplot(aes(hybrid, index, color = method))+
  geom_jitter(width = 0.1)+
 coord_flip()
```

#### **Ajustando o modelo**:

```{r}
aov_milho_bloco <- aov(index ~ factor(block) + hybrid*method + 
Error(factor(block)/hybrid/method), data = milho)

summary(aov_milho_bloco)
```

#### **Checagem das premissas**

Em parcelas subdivididas não é possível checar as premissas pelo check\_, então usa lme4, para checar pelo modelo misto.

##### **Pacote “lme4”**

Ajusta modelos de efeitos mistos lineares e lineares generalizados. Os modelos e seus componentes são representados usando classes e métodos S4.

##### **Função “lmer”**

Gera um componente aleatório que é específico a cada indivíduo, de modo que podemos ter, para cada um, um intercepto e uma inclinação distintas.

```{r}
library(Matrix)
library(lme4)
milho$block <- as.factor(milho$block)
mix2 <- lmer(index ~ block + hybrid*method + 
(1|block/hybrid), data =  milho)

library(car)
Anova(mix2)
```

```{r}
check_normality(mix2)
```

```{r}
check_heteroscedasticity(mix2)
```

#### Necessário transformar os dados

```{r}
milho$block <- as.factor(milho$block)
mix2 <- lmer(sqrt(index) ~ block + hybrid*method + (1|block/hybrid), data = milho)
library(car)
Anova(mix2)
```

##### Checagem

```{r}
check_normality(mix2)
```

```{r}
check_heteroscedasticity(mix2)
```

#### **Comparação de médias**

```{r}
means_mix2 <- emmeans(mix2, ~hybrid | method)
means_mix2
```

```{r}
cld(means_mix2)
```

# **Teste Não Paramétrico**

Os testes não paramétricos são métodos estatísticos que não exigem que os dados sigam uma distribuição específica, como a normal. Por isso, são úteis quando as suposições dos testes paramétricos não são atendidas. Eles trabalham com dados em forma de postos (ordens) ou categorias e são ideais para amostras pequenas, dados assimétricos ou com *outliers*.

**Exemplo:** conjunto *InsectSprays:* efeito de inseticida na mortalidade de insetos. Dados no pacote `datasets` do R.

### Carregando o conjunto de dados

```{r}
insects <- tibble::as_tibble(InsectSprays) |>
  dplyr::select(spray, count)
insects
```

### Análise visual dos dados

```{r}
library(ggplot2)

insects |>
  ggplot(aes(spray, count)) +
  geom_boxplot(fill = "lightblue")
```

## Teste - Modelo ANOVA

Quando se analisa um conjunto de dados e esses dados apresentam-se como não paramétricos, deve-se trabalhar esses dados de uma forma diferente. Mas antes, deve-se comprovar por meio da anova e da checagem das premissas, que os dados realmente não são normais e homogêneos.

```{r}
aov2 <- aov(count ~ spray, data = insects)
summary(aov2)
```

### Checagem das premissas

```{r}
library(performance)
check_normality(aov2)
```

```{r}
check_heteroscedasticity(aov2)
```

A partir da checagem das premissas, observa-se que os dados não são normais e homogeneos.

## **Alternativas para dados não paramétricos**

Quando se tem dados não paramétricos, tem-se 3 alternativas:

1.  Transformar os dados (Exemplo: raiz quadrada, log, Box cox);

2.  Usar testes não paramétricos (*Kruskal-Wallis*);

3.  Ou usar modelos lineares generalizados.

### **1. Transformar os dados para normalizar**

Exemplo: Usando a raiz quadrada para tentar normalizar e tornar os dados normais e homogenos.

Pode-se também tentar o log da variável resposta + 0.5.

```{r}
aov2 <- aov(sqrt(count) ~ spray, data = insects)
summary(aov2)
```

#### Checagem das premissas

```{r}
check_normality(aov2)
```

```{r}
check_heteroscedasticity(aov2)
```

### **2. Uso de testes não paramétricos**

Se com as transformações não normalizar e ainda forem heterogêneos, usa-se testes não paramétricos.

Uma das saídas para normalizar os dados é a utilização do teste de *Kruskal-Wallis*. O teste de Kruskal-Wallis utiliza os valores numéricos transformados em postos e agrupados num só conjunto de dados, é testado se as amostras vêm de uma mesma população, ou se pelo menos uma delas vêm de população distinta das demais. O teste de Kruskal-Wallis dispensa a pressuposição de normalidade e homocedasticidade. Tem 2 opções de teste Kruskal. Para usar essa opção, é necessário baixar e carregar o pacote agricolae.

#### Teste de *Kruskal-Wallis*

É utilizado em situações onde queremos comparar mais de dois grupos independentes, de tamanhos iguais ou não, com variável resposta quantitativa. É uma alternativa quando os pressupostos necesários para o teste F da Anova não são atendidos, pois este teste dispensa a pressuposição de normalidade e homocedasticidade.

```{r}
library(agricolae)

kruskal.test(count ~ spray, data = insects)
```

```{r}
kruskal(insects$count, insects$spray, 
        console = TRUE)
```

O pacote `emmeans` é muito útil na análise de Modelos Lineares Generalizados (GLM), pois permite obter as médias marginais estimadas dos fatores no modelo.

```{r}
aov2 <- aov(count ~ spray, data = insects)
summary(aov2)
```

##### Checagem das premissas

```{r}
check_normality(aov2)
```

```{r}
check_heteroscedasticity(aov2)
```

Função `emmeans`: tirar a média da variável inseticida. Para dar o valor original da média e não o valor transformado, usa-se a função `type = response`.

```{r}
library(emmeans)
aov2_means <- emmeans(aov2, ~ spray,
                         type = "response")
aov2_means
```

A função `pwpm` gera uma tabela de comparação das médias e `cld` é uma função que serve para gerar os números que diferenciam os grupos de médias.

```{r}
pwpm(aov2_means)
```

```{r}

library(MASS)
library(mvtnorm)
library(survival)
library(TH.data)
library(multcomp)
library(multcompView)
cld(aov2_means)
```

#### 3. **GLM – Modelos Lineares Generalizados**

A função `glm` é utilizada para ajustar Modelos Lineares Generalizados no R. Esses modelos permitem trabalhar com diferentes distribuições de erro, como binomial, *Poisson* e outras, tornando possível a análise de variáveis resposta que não seguem uma distribuição normal. O modelo é definido por uma fórmula simbólica que relaciona a variável resposta aos preditores, e pela escolha de uma família de distribuição que representa o tipo de dado analisado. Para publicação de artigos, essa é a opção mais aconselhável.

Para a geração de modelos, a função a ser utilizada é a `glm` e precisa indicar os argumentos f*amily = poisson(link = “identity”)*. Para visualizar, pode usar o pacote `Dharma` e gerar um plot.

```{r}
library(DHARMa)

glm1 <- glm(count ~spray,
             data = insects,
             family = poisson(link = "identity"))
plot(simulateResiduals(glm1))
```

```{r}
summary(glm1)
```

```{r}
glm1_means <- emmeans(glm1, ~ spray)
cld(glm1_means)
```

# **Análise de Regressão**

A análise de regressão é uma técnica estatística utilizada para examinar a relação entre variáveis por meio da construção de um modelo matemático. Quando os dados são quantitativos, ela costuma ser mais indicada que a análise de variância (ANOVA), pois permite descrever e prever a relação entre uma variável dependente (Y) e uma ou mais variáveis independentes (X).

O objetivo é estimar os parâmetros de uma equação que represente essa relação funcional. Com isso, é possível identificar a direção e a intensidade do efeito das variáveis independentes sobre a variável resposta, além de realizar previsões para novos casos.

# **Regressão linear simples**

Na análise de regressão linear, parte-se do pressuposto de que existe uma relação linear entre a variável dependente e a variável independente, ou seja, essa relação pode ser representada por uma linha reta. A equação geral da regressão linear é:\

**y = β₀ + β₁x + ε**, onde:

-   *y* representa a variável dependente (ou resposta);

-   *x* é a variável independente (ou preditora);

-   *β₀* é o intercepto da reta (valor de *y* quando *x = 0*);

-   *β₁* é o coeficiente angular (inclinação da reta);

-   *ε* é o termo de erro aleatório;

Na regressão linear simples, o principal objetivo é testar se o coeficiente de inclinação (*β₁*) é significativamente diferente de zero. Esse teste indica se há evidência estatística de uma associação linear entre as variáveis. Um valor de *p* pequeno (geralmente \< 0,05) sugere que a inclinação é significativamente diferente de zero, indicando uma relação linear entre *x* e *y*.

### Carregando pacotes e importando o conjunto de dados

```{r}
# Passo 1: Carregar pacotes e importar dados
library(gsheet)
library(ggplot2)
library(dplyr)
library(lme4)
library(car) # para Anova()
library(readxl)

# Importar dados - Google Sheets

# estande <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=401662555#gid=401662555") ou:


estande <- read_excel("dados.xlsx", "estande") # Planilha excel
```

### Visualizar distribuição geral com regressão

```{r}
# Gráfico geral para visualizar a relação entre tratamento e número de plantas
estande |>
  ggplot(aes(trat, nplants)) +
  geom_point(color = "blue") + # Pontos individuais
  geom_smooth(method = "lm", se = FALSE, color = "black") + # Linha de regressão
  facet_wrap(~ exp) + # Um gráfico por experimento
  theme_minimal() + # Tema limpo
  labs(
    x = "% de inóculo na semente",
    y = "Número de plantas"
  )
# Para ajustar para uma regressão linear usa-se o argumento method = “lm” dentro da função geom_smooth.
```

## **Modelo de melhor ajuste**

Deve-se testar o modelo que melhor se ajusta aos dados. Pode-se testar fazer a análise de regressão para cada experimento (isola cada experimento) ou analisar em grupos (modelos mistos).

#### Análise de regressão por experimento

**Analisando cada experimento isoladamente:**

É preciso criar um novo objeto de dados, chamado `exp1`, atribuindo a ele o conjunto `estande`. Em seguida, deve-se filtrar o experimento de interesse e gerar um novo objeto com esse subconjunto, o que possibilita a execução da análise de regressão.

**Experimento 1:**

```{r}
# Filtrar experimento 1 e calcular média por tratamento
exp1 <- estande |>
  filter(exp == 1) |>
  group_by(trat) |>
  summarise(nplants2 = mean(nplants, na.rm = TRUE))

# Gráfico da média
exp1 |>
  ggplot(aes(trat, nplants2)) +
  geom_point() +
  ylim(20, 60)
```

```{r}
# Regressão linear com bloco (precisa existir a variável 'bloco')
exp1_model <- estande |>
  filter(exp == 1)

m_exp1 <- lm(nplants ~ trat + bloco, data = exp1_model)
summary(m_exp1)
```

Foi ajustado um modelo linear para avaliar o efeito do tratamento e do bloco sobre o número de plantas. O modelo apresentou um bom ajuste, explicando cerca de 55% da variação nos dados (R² = 0,55). O efeito do bloco foi altamente significativo (p \< 0,001), indicando variações importantes entre os blocos experimentais. Já o efeito do tratamento foi marginalmente significativo (p = 0,082), sugerindo uma possível tendência de diferença entre tratamentos, embora com menor evidência estatística. O erro padrão residual foi de 10,67, e o modelo geral foi significativo pelo teste F (p \< 0,001).

**Experimento 2:**

```{r}
exp2 <- estande |>
  filter(exp == 2)

m_exp2 <- lm(nplants ~ trat, data = exp2)
summary(m_exp2)
```

Foi ajustado um modelo linear para avaliar o efeito do tratamento (`trat`) sobre o número de plantas (`nplants`). O modelo apresentou um bom ajuste, explicando cerca de 46% da variação observada (R² = 0,46). O tratamento teve efeito estatisticamente significativo (p \< 0,001), com uma estimativa de redução de 0,70 plantas por unidade do fator `trat`. O modelo como um todo foi altamente significativo (p \< 0,001), indicando que `trat` é um fator importante na determinação do número de plantas nesta análise.

**Experimento 3:**

```{r}
exp3 <- estande |>
  filter(exp == 3)

m_exp3 <- lm(nplants ~ trat, data = exp3)
summary(m_exp3)
```

Foi ajustado um modelo linear simples para investigar o efeito do tratamento sobre o número de plantas no experimento 3. O modelo apresentou um ajuste estatisticamente significativo (p \< 0,001), explicando aproximadamente 61% da variação nos dados (R² = 0,61). O efeito do tratamento também foi altamente significativo (p \< 0,001), com uma estimativa de redução média de 0,76 plantas para cada unidade de `trat`. O valor médio estimado de plantas no grupo de referência foi 95,75. O erro padrão residual foi de 10,53, indicando um bom ajuste aos dados.

```{r}
library(report)
report(m_exp3)
```

#### Modelo misto - Exemplo

```{r}
# Modelo misto com efeitos aleatórios de experimento e bloco
m_misto <- lmer(nplants ~ trat + (1 | exp/bloco), data = estande)

# Intervalos de confiança e sumário do modelo
confint(m_misto)
summary(m_misto)

# ANOVA para verificar significância dos efeitos fixos
Anova(m_misto) # com A maiúsculo
```

#### Gráfico com linhas de regressão manuais

```{r}
# Gráfico com diferentes linhas de regressão para comparação
estande |>
  ggplot(aes(trat, nplants, color = factor(exp))) +
  geom_point() +
  geom_abline(intercept = 69.74, slope = -0.568, linewidth = 2) + # Linha principal
  geom_abline(intercept = 43, slope = -0.73, linetype = "dashed") + # Linha comparativa
  geom_abline(intercept = 96, slope = -0.40, linetype = "dashed")   # Outra linha comparativa
```

## **Modelo misto**

Em um modelo misto, as observações são organizadas em grupos ou subgrupos, e cada um desses grupos pode apresentar efeitos aleatórios e/ou fixos distintos, conforme a estrutura dos dados. Por exemplo, quando os dados são coletados em diferentes localidades geográficas, é comum incluir um efeito aleatório para cada local, como ocorre no conjunto de dados estande.

```{r}
library(lme4)
mix <- lmer(nplants ~trat + (trat | exp),
            data = estande)
summary(mix)
```

```{r}
library(car)
Anova(mix)
```

Quando se usa o modelo misto, considera que todos os experimentos são agrupados, então considera que amostra é aleatória. Para fazer o modelo de regressão em grupo (misto) acrescenta-se na função aestetic o argumento group = exp.

```{r}
estande <- read_excel("dados.xlsx", "estande")
estande |>
  ggplot(aes(trat, nplants, group = exp))+
  geom_point()+
  #facet_wrap(~ exp)+
  geom_smooth(se =  F, method = "lm")
```

De modo geral, os modelos mistos são mais eficazes do que aqueles que analisam cada experimento separadamente, pois conseguem considerar a variação tanto entre os experimentos quanto dentro deles. Além disso, esses modelos permitem analisar os dados de forma integrada, preservando informações importantes sobre a estrutura hierárquica dos dados.

## **Modelo GLM**

O modelo linear generalizado (GLM) é uma extensão do modelo linear tradicional que possibilita trabalhar com diferentes tipos de variáveis resposta, tanto categóricas quanto contínuas. Além disso, o GLM permite que a relação entre a variável resposta e as explicativas seja não linear, ou seja, não está restrito à suposição de uma relação linear entre elas.

```{r}
lm1 <- lm(nplants ~ trat, data = exp3)
summary(lm1)
```

```{r}
glm1 <- stats::glm(nplants ~ trat, family = stats::gaussian(), data = exp3)

glm2 <- stats::glm(nplants ~ trat, family = stats::poisson(link = "log"), data = exp3)

AIC(glm1)
AIC(glm2)
```

```{r}
AIC(glm2)
```

```{r}
summary(glm1)
```

```{r}
summary(glm2)
```

O modelo linear generalizado com distribuição gaussiana (`family = gaussian`) é indicado quando a variável resposta é contínua e segue uma distribuição normal, funcionando de forma equivalente ao modelo linear clássico (`lm`). Por outro lado, o modelo com distribuição de *Poisson* (`family = poisson`) é apropriado quando a variável resposta é um número inteiro não negativo e segue uma distribuição de *Poisson.*

O critério AIC (*Akaike’s Information Criterion*) é utilizado para selecionar o melhor modelo entre várias opções, considerando tanto o ajuste aos dados quanto a complexidade do modelo. Modelos com valores menores de AIC são preferíveis, pois indicam um equilíbrio melhor entre precisão e simplicidade. No caso dos dados analisados, o modelo com família Poisson apresentou o menor AIC, indicando ser o mais adequado.

# **Regressão não-linear**

Quando a relação entre as variáveis independentes e a variável dependente não pode ser representada por uma linha reta, é necessário recorrer à regressão não linear. Esse tipo de análise é apropriado quando os dados apresentam padrões que não podem ser adequadamente modelados por uma função linear, permitindo capturar relações mais complexas entre as variáveis.

### Carregar pacotes e importar dados

```{r}
# Pacote para importar tabela do Google Sheets
library(gsheet)

# Importar dados
fungi <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=465348652#gid=465348652")
```

### Visualizar os dados para todos os fungos

```{r}
library(dplyr)
library(ggplot2)

# Agrupar por fungo e dose, calcular média de germinação
fungi_summary <- fungi |>
  group_by(code, dose) |>
  summarise(germination = mean(germination, na.rm = TRUE), .groups = "drop")

# Plotar a germinação por dose para cada fungo
fungi_summary |>
  ggplot(aes(x = dose, y = germination)) +
  geom_point() +
  geom_line() +
  facet_wrap(~ code) +
  theme_minimal() +
  labs(title = "Germinação por dose para cada fungo",
       x = "Dose",
       y = "Germinação média")
```

### Selecionar um fungo específico para ajustar modelos (exemplo: FGT43)

```{r}
# Filtrar dados para o fungo FGT43
FGT43 <- fungi_summary |>
  filter(code == "FGT43")
```

### Ajustar modelos de regressão não linear usando o pacote `drc`

O pacote `drc` é amplamente utilizado para o ajuste de modelos de regressão em estudos de dose-resposta. Ele oferece uma variedade de modelos, como log-logístico, log-probit, Weibull, entre outros, permitindo representar com precisão a relação entre a dose aplicada e a resposta observada. Além disso, o pacote disponibiliza funções para a estimativa de parâmetros importantes, como o EC50 (dose efetiva para 50% da resposta máxima).

```{r}
library(drc)

# Ajustar modelo Weibull 2.3
m_wb <- drm(germination ~ dose,
            data = FGT43,
            fct = W2.3())

# Ajustar modelo log-logístico 3 parâmetros (LL.3)
m_ll3 <- drm(germination ~ dose,
             data = FGT43,
             fct = LL.3())

# Comparar AIC para escolher o melhor modelo
AIC(m_wb)
AIC(m_ll3)

# Resumo do melhor modelo (exemplo: LL.3)
summary(m_ll3)

# Plotar ajuste do modelo LL.3
plot(m_ll3, main = "Ajuste do modelo LL.3 para FGT43")
```

### Estimar a concentração efetiva EC50 a partir do modelo

```{r}
# Estimar EC50 (dose para 50% do efeito)
ED(m_ll3, 50, interval = "delta")
```

### Estimar EC50 para todos os fungos de uma vez (pacote `ec50estimator`)

A função do pacote `ec50estimator` permite calcular os valores de EC50 de forma prática e eficiente. Esses valores representam a dose necessária para atingir 50% da resposta máxima e são especialmente úteis para comparar a sensibilidade entre diferentes identificadores (ID). Com isso, é possível identificar variações na resposta à dose entre tratamentos, linhagens ou isolados, o que auxilia na avaliação da eficácia ou resistência em diferentes grupos.

```{r}
# Instale o pacote se ainda não tiver: install.packages("ec50estimator")
library(ec50estimator)

# Estima EC50 para cada fungo (isolate_col = "code"), podendo estratificar por estado (strata_col)
df_ec50 <- estimate_EC50(germination ~ dose,
                         data = fungi,
                         isolate_col = "code",
                         strata_col = "state",  # pode omitir se não tiver
                         interval = "delta",
                         fct = drc::LL.3())
```

### Visualizar os resultados da estimativa EC50

```{r}
library(ggplot2)

# Gráfico de pontos ordenando pelo valor da estimativa (menor para maior EC50)
df_ec50 |>
  ggplot(aes(x = reorder(ID, Estimate), y = Estimate)) +
  geom_point() +
  coord_flip() +
  labs(x = "Fungos (ordenados por EC50)", y = "EC50 estimado") +
  theme_minimal()
```

```{r}

# Histograma da distribuição dos valores EC50
df_ec50 |>
  ggplot(aes(x = Estimate)) +
  geom_histogram(bins = 5, color = "black", fill = "steelblue") +
  labs(title = "Distribuição dos valores EC50 estimados", x = "EC50", y = "Frequência") +
  theme_minimal()
```

### Exemplo 2:

Regressão não-linar para determinação de EC50.

```{r}
#Carregando pacotes
library(ggplot2)
library(gsheet)
library(dplyr)
```

```{r}
#importando o comjunto de dados
dat <- gsheet2tbl("https://docs.google.com/spreadsheets/d/15pCj0zljvd-TGECe67OMt6sa21xO8BqUgv4d-kU8qi8/edit#gid=0")
```

```{r}
options(scipen = 999)

dat2 <- dat |> 
  dplyr::select(-Isolate, Population) |> 
  group_by(Code, Year, Dose) |> 
  summarise(GC_mean = mean(GC), .groups = "drop")
```

O comando `options(scipen = 999)` ajusta a opção `scipen`, que controla a exibição de números em notação científica. Ao definir esse valor como 999, o R passa a exibir números longos em formato decimal comum, evitando a notação exponencial.

Em seguida, o bloco de código realiza as seguintes operações sobre o dataframe `dat`:

-   Remove as colunas `Isolate` e `Population`, que não farão parte do novo conjunto de dados.

-   Agrupa os dados pelas variáveis `Code`, `Year` e `Dose`.

-   Calcula a média da variável `GC` para cada combinação desses grupos.

-   Armazena o resultado em um novo dataframe chamado `dat2`, criando uma nova coluna chamada `GC_mean`, que contém a média de `GC` dentro de cada grupo.

Essas operações são úteis para resumir os dados e preparar o conjunto para análises posteriores.

**Exemplo:** gráfico só com um dos isolados - FGT152

Criou-se um gráfico usando o dataframe FGT152, que é um subconjunto dos dados filtrados do `dat2`. 

```{r}
FGT152 <- dat2 |>
  filter(Code == "FGT152")

FGT152 |>
  ggplot(aes(factor(Dose), GC_mean))+
  geom_point()+
  geom_line()+
  facet_wrap(~ Code)
```

#### **EC50 com pacote DRC**

##### **Modelo log-logístico de 3 parâmetros**:

Esse modelo é utilizado para descrever a relação entre a dose de um agente ou tratamento e a resposta biológica observada. Ele assume que a resposta varia de forma crescente ou decrescente com o aumento da dose, seguindo uma curva sigmoide (em forma de "S" ou "S" invertido). É especialmente útil em estudos de dose-resposta, onde se espera esse tipo de comportamento não linear.

O comando `drc1 <- drm(GC_mean ~ Dose, data = FGT152, fct = LL.3())` ajusta um modelo de regressão de dose-resposta utilizando a função `drm()` do pacote **`drc`**. Nesse caso:

-   `GC_mean ~ Dose`: define que a variável resposta é `GC_mean` e a variável preditora é `Dose`;

-   `data = FGT152`: indica que os dados utilizados estão no dataframe `FGT152`;

-   `fct = LL.3()`: especifica o uso do modelo log-logístico de três parâmetros (LL.3), adequado para curvas sigmoides.

Após o ajuste, o comando `AIC(drc1)` calcula o *Akaike Information Criterion (AIC)* do modelo, uma medida que considera tanto o ajuste quanto a complexidade do modelo, quanto menor o AIC, melhor o modelo.

```{r}
library(drc)

drc1 <- drm(GC_mean ~ Dose, data = FGT152,
            fct = LL.3())
AIC(drc1)
```

```{r}
summary(drc1)
```

```{r}
plot(drc1)
```

O comando `ED(drc1, 50)` estima a dose efetiva necessária para alcançar 50% da resposta máxima (ED50). A função `ED()` retorna essa estimativa com base no modelo ajustado.

```{r}
ED(drc1, 50)
```

##### **Modelo W1.3**:

Apresentou o melhor ajuste aos dados com base no valor do AIC. Esse modelo oferece maior flexibilidade na modelagem da curva dose-resposta por incluir o parâmetro de assimetria (g). Esse parâmetro permite que a curva assuma formas assimétricas, ajustando-se melhor a situações em que a resposta não segue uma simetria perfeita em torno da dose efetiva, resultando em curvas sigmoides assimétricas.

```{r}
drc1 <- drm(GC_mean ~ Dose, data = FGT152,
            fct = W1.3())
AIC(drc1)
```

```{r}
summary(drc1)
```

```{r}
plot(drc1)
```

```{r}
ED(drc1, 50)
```

##### **Pacote ec50estimator**

A função `estimate_EC50()` é usada para estimar os valores de EC50 a partir dos dados disponíveis. Ela recebe diversos argumentos, cada um com um papel específico:

-   `isolate_col = "Code"` define a coluna `"Code"` como identificador único para as diferentes amostras ou grupos;

-   `interval = "delta"` especifica o tipo de intervalo de confiança a ser calculado para as estimativas de EC50;

-   `fct = drc::LL.3()` indica que o modelo de ajuste utilizado é o log-logístico de três parâmetros.

No gráfico criado com `ggplot2`, dentro da função `aes()`, o argumento `(Estimate, reorder(ID, Estimate))` mapeia as variáveis para os eixos x e y. Aqui, `Estimate` representa os valores estimados de EC50, enquanto `ID` é reordenado com base nesses valores para controlar a ordem de exibição no gráfico.

A função `geom_errorbar()` adiciona barras de erro ao gráfico, usando os valores `Lower` e `Upper`, que correspondem aos limites inferior e superior dos intervalos de confiança das estimativas de EC50. Por fim, o comando `xlim(0, 30)` define os limites do eixo x, restringindo a visualização das estimativas a valores entre 0 e 30.

```{r}
library(ec50estimator)

df_ec50 <- estimate_EC50(GC_mean ~ Dose,
                         data = dat2,
                         isolate_col = "Code",
                         interval = "delta",
                         fct = drc::LL.3())

df_ec50 |>
  ggplot(aes(Estimate, reorder(ID, Estimate)))+
  geom_point()+
  geom_errorbar(aes(xmin = Lower,
                    xmax = Upper), width = 0.1)+
  xlim(0,30)
```

# **Análise de Correlação**

A análise de correlação é utilizada para verificar a intensidade e a direção da relação linear entre duas variáveis contínuas. Seu principal objetivo é avaliar até que ponto as variáveis se associam — ou seja, se tendem a variar juntas de forma proporcional.

Essa análise pode indicar:

-   **Correlação positiva**: quando o aumento de uma variável está associado ao aumento da outra;

-   **Correlação negativa**: quando o aumento de uma variável está associado à diminuição da outra;

-   **Ausência de correlação**: quando não há uma relação linear evidente entre as variáveis.

O coeficiente de correlação de Pearson é a medida mais comum e varia entre -1 e +1:

-   Valores próximos de **+1** indicam forte correlação positiva;

-   Valores próximos de **-1** indicam forte correlação negativa;

-   Valores próximos de **0** indicam correlação fraca ou inexistente.

É importante destacar que a correlação não implica causalidade, ou seja, uma variável pode estar associada à outra sem que necessariamente uma cause a outra.

### Carregamento de pacotes

```{r}
library(tidyverse)
library(readxl)
library(ggplot2)
```

### Importando o conjunto de dados

```{r}
estande <- read_excel("dados.xlsx", "estande")
```

### Visualização gráfica

```{r}
estande |>
  ggplot(aes(trat, nplants))+
  geom_point()+
  facet_wrap(~ exp)+
  ylim(0,max(estande$nplants))+
  geom_smooth(se =  F)
```

## **Ajustando modelo linear simples e quadratico**

Para ajustar modelos de regressão linear — seja simples ou quadrático — utiliza-se a função `lm()` no R. Essa função recebe como argumentos uma **fórmula** que define a relação entre a variável dependente e a(s) variável(is) independente(s), além do conjunto de dados a ser utilizado.

Por exemplo, para um modelo linear simples, a fórmula seria `y ~ x`, onde `y` é a variável resposta e `x` é a variável explicativa. Para um modelo quadrático, a fórmula pode ser `y ~ x + I(x^2)`, incluindo o termo ao quadrado de `x`.

O modelo ajustado é armazenado como um objeto do tipo `lm`, que pode ser examinado com a função `summary()`. Esse resumo fornece os coeficientes estimados, valores-p, estatísticas de ajuste (como o R²) e outros diagnósticos úteis.

### Coeficiente de Determinação (R²)

O **R²** representa a proporção da variação da variável resposta que é explicada pelo modelo ajustado. Seu valor varia entre 0 e 1:

-   **R² = 0**: o modelo não explica nenhuma variação nos dados;

-   **R² = 1**: o modelo explica toda a variação observada.

Quanto maior o R², melhor o modelo se ajusta aos dados, indicando maior capacidade explicativa por parte das variáveis independentes.

```{r}
estande2 <- estande |>
  filter(exp ==2) |>
  group_by(trat) |>
  summarise(mean_nplants = mean(nplants))
  
estande2|>
  ggplot(aes(trat, mean_nplants))+
  geom_point()+
  #geom_line()
  geom_smooth(formula = y ~ poly(x, 2), method = "lm", color = "black")+
  annotate(geom = "text", 
           x = 25, y = 70,
           label = "y = 66.3 - 1.777x + 0.0222x2
           R2 = 0.0.88")
```

## Modelo Quadrático

Diferente do modelo linear, que descreve a relação entre duas variáveis por meio de uma linha reta, o modelo quadrático permite identificar padrões não lineares, com comportamento curvo.

Para ajustar um modelo quadrático no R, utiliza-se a função `lm()`, incluindo o termo ao quadrado da variável independente na fórmula. Por exemplo, para modelar a relação entre uma variável dependente `y` e uma independente `x`.

```{r}
estande2 <- estande2 |>
  mutate(trat2 = trat^2)
  m1 <- lm(mean_nplants ~ trat, data = estande2)
summary(m1)
```

```{r}
hist(m1$residuals)
```

```{r}
m2 <- lm(mean_nplants ~ trat + trat2,
         data = estande2)
summary(m2)
```

```{r}
AIC(m1, m2)
```

## **Duas variáveis resposta**

### Ajuste de Modelo Linear Simples e Quadrático

Para ajustar modelos de regressão linear, seja simples ou quadrático, utiliza-se a função `lm()` no R. Essa função recebe como argumentos uma fórmula que define a relação entre a variável dependente e a(s) variável(is) independente(s), além do conjunto de dados a ser utilizado.

Por exemplo, para um modelo linear simples, a fórmula seria `y ~ x`, onde `y` é a variável resposta e `x` é a variável explicativa. Para um modelo quadrático, a fórmula pode ser `y ~ x + I(x^2)`, incluindo o termo ao quadrado de `x`.

O modelo ajustado é armazenado como um objeto do tipo `lm`, que pode ser examinado com a função `summary()`. Esse resumo fornece os coeficientes estimados, valores-p, estatísticas de ajuste (como o R²) e outros diagnósticos úteis.

#### Importando o conjunto de dados

```{r}
mofo <- read_excel("dados.xlsx", "mofo")
```

#### Visualizando os dados

```{r}
mofo |>
  ggplot(aes(inc, yld))+
  geom_point()+
  geom_smooth(se = F, method = "lm")+
  facet_wrap(~ study)
```

Filtrando o experimento 1 (study = 1):

```{r}
mofo1 <- mofo |>
  filter(study ==1)
mofo1
```

A função `cor.test()` é utilizada para calcular o **coeficiente de correlação** entre duas variáveis numéricas. Além de fornecer o valor da correlação (como o coeficiente de Pearson), ela também realiza um **teste de hipótese** para verificar se essa correlação é **estatisticamente significativa**, ou seja, se é improvável que tenha ocorrido ao acaso.

```{r}
cor.test(mofo1$inc, mofo1$yld)
```

Filtrando o experimento 2:

```{r}
mofo1 <- mofo |>
  filter(study ==2)
mofo1
```

```{r}
cor.test(mofo1$inc, mofo1$yld)
```

Filtrando o experimento 4:

```{r}
mofo1 <- mofo |>
  filter(study ==4)
mofo1
```

```{r}
cor.test(mofo1$inc, mofo1$yld)
```

Filtrando o experimento 3:

```{r}
mofo1 <- mofo |>
  filter(study ==3)
mofo1
```

### Matrizes de Correlação

A matriz de correlação é uma tabela que exibe os coeficientes de correlação entre todos os pares de variáveis de um conjunto de dados. Cada célula da matriz indica a força e a direção da relação entre duas variáveis, geralmente usando o coeficiente de correlação de Pearson, embora outras medidas (como Spearman ou Kendall) também possam ser utilizadas, conforme o contexto da análise.

Gerando matriz de correlação para as variáveis selecionadas:

```{r}
mofo1 <- mofo |>
  filter(study ==3)
mofo1
```

```{r}
cor.test(mofo1$inc, mofo1$yld)
```

```{r}
library(dplyr)

cor(mofo1[, 3:5])
```

### Gráficos de Correlação

Para visualizar matrizes de correlação, o pacote `corrplot` é uma ferramenta amplamente utilizada no R. Ele oferece diversas funções para explorar e representar visualmente as relações entre variáveis em um conjunto de dados, facilitando a identificação de padrões de correlação.

Principais funções do pacote corrplot:

-   `corr.test()`: realiza testes estatísticos para matrizes de correlação, calculando coeficientes de correlação, valores-p e intervalos de confiança, permitindo avaliar a significância das correlações.

-   `corrplot()`: gera gráficos que exibem a matriz de correlação com diferentes estilos visuais. Permite personalizar o tipo de gráfico, as cores, adicionar os valores numéricos dos coeficientes, além de possibilitar agrupamentos hierárquicos.

```{r}
mofo1 <- mofo |>
  filter(study ==3)
mofo1
```

```{r}
cor.test(mofo1$inc, mofo1$yld)
```

```{r}
pcor <- cor(mofo1[, 3:5])

library(corrplot)
corrplot(pcor, method = 'number', type = "lower")
```

### Modelo de Kendall

O coeficiente de correlação de Kendall é uma medida não paramétrica que avalia a associação entre duas variáveis ordinais ou variáveis medidas em escala ordinal. Assim como o coeficiente de Pearson, o coeficiente de Kendall varia entre -1 e 1, indicando a direção e a força da relação.

Por ser não paramétrico, o método de Kendall é mais robusto em situações onde os dados não seguem uma relação linear ou quando as variáveis não possuem distribuição normal, sendo uma alternativa adequada para analisar associações em dados ordinais ou com distribuições não normais.

```{r}
mofo1 <- mofo |>
  filter(study ==3)
mofo1
```

```{r}
shapiro.test(mofo1$inc)
```

```{r}
shapiro.test(mofo1$yld)
```

```{r}
cor.test(mofo1$inc, mofo1$yld, method = "spearman")
```

```{r}
pcor <- cor(mofo1[, 3:5], method = "spearman")

library(corrplot)
corrplot(pcor, method = 'number', type = "lower")
```

# **Comparação de Frequência**

A comparação de frequência é uma análise usada para verificar se há associação ou diferença significativa entre categorias de variáveis categóricas (qualitativas). É muito comum em experimentos, questionários e dados de contagem.

```{r warning(FALSE)}
#Carregando pacotes
library(tidyverse)
library(readxl)
library(janitor)
library(ggplot2)
library(dplyr)
library(rstatix)

#Importando dados
survey <- read_excel("dados.xlsx","survey")
```

A função `tabyl()` cria uma tabela de frequência tabular, mostrando a contagem de ocorrências de diferentes combinações de valores em variáveis categóricas.

```{r}
survey |> 
  tabyl (year, species) |> 
  adorn_percentages()
```

## **Gráfico de barras - frequência**

```{r}
survey |> 
  filter(residue != "NA") |> 
  count(residue, species) |> 
  ggplot(aes(residue, n, fill = species)) +
  geom_col() +
  scale_fill_brewer(palette = "Greens") +
  theme_minimal() +
  labs(x = "Resíduo", y = "Frequência", fill = "Espécie")
```

## **Frequência de classe**

A função `chisq.test()` é utilizada para realizar testes do qui-quadrado em duas principais situações:

-   Testes de independência em tabelas de contingência — verifica se existe associação estatística entre duas variáveis categóricas;

-   Testes de aderência (ou qualidade de ajuste) — avalia se a distribuição observada de uma variável categórica difere significativamente de uma distribuição esperada (teórica).

Essa função retorna estatísticas como o valor do qui-quadrado, os graus de liberdade e o valor-p, que ajudam a determinar se as diferenças observadas são estatisticamente significativas.

```{r}
q <- table (survey$residue, survey$species)
chisq.test(q)
```

## **Para frequências mais baixas**

A função `fisher.test()` realiza o teste exato de Fisher, que é utilizado para avaliar a independência entre linhas e colunas em uma tabela de contingência, especialmente quando os valores esperados são baixos (frequências menores que 5), condição na qual o teste do qui-quadrado pode não ser confiável.

Esse teste verifica se há evidência de associação entre duas variáveis categóricas, assumindo que as margens da tabela (totais de linha e coluna) são fixas. Ele calcula exatamente a probabilidade de observar uma distribuição tão extrema quanto a observada, ou mais, sob a hipótese nula de independência.

```{r}
fisher.test(q)
```

```{r}
q <- table (survey$residue, survey$inc_class)
chisq.test(q)
```

```{r}
survey |> 
  filter(residue != "NA") |> 
  count(residue, inc_class) |> 
  ggplot(aes(residue, n, fill = inc_class)) +
  geom_col() +
  scale_fill_brewer(palette = "Greens") +
  theme_minimal() +
  labs(
    x = "Resíduo",
    y = "Frequência",
    fill = "Classe de Incidência"
  )
```

## **Cruzamento entre variáveis**

```{r}
survey |> count (year)
```

```{r}
#Frequência de ocorrência por ano

table (survey$year, survey$species)
```

```{r}
curve <- read_excel("dados.xlsx","curve")

curve2 <- curve |> 
  group_by(Irrigation, day) |> 
  summarise(mean_severity = mean (severity),
            sd_severity = sd(severity))

curve2 |> ggplot(aes(day,mean_severity, color=Irrigation))+
  geom_point()+
  geom_line()
```

```{r}
curve2 |> ggplot(aes(day,mean_severity, color=Irrigation))+
  geom_point()+
  geom_errorbar(aes(ymin=mean_severity - sd_severity,
                    ymax = mean_severity + sd_severity),
                width = 0.1)+
  geom_line()
```

```{r}

library(epifitter)

curve3 <- curve |> 
  group_by(Irrigation, rep) |> 
  summarise(audpc = AUDPC(day, severity,
                          y_proportion = F)) |> 
  pivot_wider(1, names_from = Irrigation,
            values_from = audpc)

t.test(curve3$Drip, curve$Furrow)
```

Exemplo:

```{r}
library(gsheet)

tw <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1t5xftb0xSRPNFhM7h_MiPNtwt2UFUcm9/edit#gid=1594889893")
tw |> 
  group_by(cult,silicio,hai) |> 
  summarise (mean_lesion = mean (as.numeric(lesion_size)),
             sd_lesion = sd(lesion_size)) |> 
  ggplot(aes(hai,mean_lesion, color = silicio))+
  geom_line()+
  geom_point()+
  geom_errorbar(aes(ymin=mean_lesion - sd_lesion,
                    ymax = mean_lesion + sd_lesion),
                width = 0.1)+
  facet_wrap(~cult)+
   labs (y = "Lesion size (mm)", x = "Hours after inoculation")+
  ggthemes::theme_few()+
scale_color_manual(values = c("#1f78b4", "#6baed6", "#9ecae1", "#c6dbef"))
```

# **Análise da área abaixo da curva de progresso da doença - AUDPC**

A AUDPC (*Area Under the Disease Progress Curve*) é uma medida utilizada na fitopatologia para quantificar e comparar o progresso de doenças em plantas ao longo do tempo. É calculada a partir de observações repetidas da severidade ou tamanho das lesões ao longo do tempo. Para isso, constrói-se uma curva com o tempo no eixo x e a variável de interesse (como o tamanho da lesão) no eixo y. Em seguida, calcula-se a área sob essa curva. Valores elevados de AUDPC refletem maior intensidade ou impacto da doença, enquanto valores mais baixos indicam menor progressão ou severidade.

```{r}
library(agricolae)
library(dplyr)

tw2 <- tw |>
  group_by(exp,cult,silicio,rep) |> 
  summarise(audpc=audpc(lesion_size, hai)) |> 
  filter (audpc > 0)

#Visualização com ggplot2
#Aplicando a AUDPC e visualizando em boxplot

tw2 |> 
  ggplot(aes(cult,audpc, color = silicio))+
  geom_boxplot()+
  facet_wrap(~ exp)
```

## **Teste ANOVA**

Os resultados da análise de variância podem ajudar a identificar quais variáveis e interações têm efeito significativo na variável resposta audpc.

```{r}
aov1 <- aov(sqrt(audpc) ~exp*cult*silicio, data = tw2)
summary(aov1)
```

```{r}
library(performance)
check_normality(aov1)
```

```{r}
check_heteroscedasticity(aov1)
```

```{r}
library(emmeans)
m1 <- emmeans (aov1, ~cult | silicio, type = "response")
```

### Exemplo

```{r}
# Tabela de frequência
tab <- table(survey$residue, survey$species)

# Teste qui-quadrado
chisq.test(tab)

# Visualização
library(ggplot2)
survey |> 
  count(residue, species) |> 
  ggplot(aes(residue, n, fill = species)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c("#2171b5", "#6baed6", "#9ecae1", "#c6dbef")) +
  labs(x = "Resíduo", y = "Frequência", fill = "Espécie") +
  theme_minimal()
```

# **Teste de Tukey e Scott Knott (Pacote `ExpDes.pt`)**

**Pacote “ExpDes.pt”**\
O pacote `ExpDes.pt` é voltado para a análise de delineamentos experimentais, incluindo DIC, DBC e DQL. Ele permite realizar análises de variância e comparações de médias em diferentes tipos de experimentos, como:

-   Esquemas fatoriais duplos e triplos (em DIC e DBC);

-   Parcelas subdivididas (em DIC e DBC);

-   Fatoriais com tratamento adicional (duplo ou triplo, em DIC e DBC).

Oferece ferramentas para:

-   Comparação de múltiplas médias (em tratamentos qualitativos);

-   Ajuste de modelos de regressão até o terceiro grau (para tratamentos quantitativos);

-   Análise de resíduos para verificar pressupostos do modelo.

```{r}

library(tidyverse)
library(readxl)
library(ExpDes.pt)
```

## **Teste de Tukey com pacote `ExpDes.pt` (Experimento em DIC)**

### Instalar e carregar o pacote

```{r}
# Carregue o pacote
library(ExpDes.pt)
```

### **Criar os dados de exemplo**

Vamos supor que avaliamos a produtividade de 4 cultivares de milho, com 4 repetições cada:

```{r}
# Fator: tratamentos (cultivares)
trat <- c(rep("A", 4), rep("B", 4), rep("C", 4), rep("D", 4))

# Resposta: produtividade em kg/ha
resp <- c(5000, 5200, 5100, 4950,
          5300, 5400, 5350, 5250,
          4800, 4700, 4900, 4750,
          5100, 5000, 4950, 5050)
```

### Análise de variância com Tukey (DIC)

`dic()`: realiza a análise para Delineamento Inteiramente Casualizado.

`trat`: vetor com os tratamentos (fator qualitativo).

`resp`: vetor com a variável resposta (produtividade).

`quali = TRUE`: indica que os tratamentos são qualitativos.

`mcomp = "tukey"`: escolhe o teste de comparação de médias de Tukey.

`sigT = 0.05`: nível de significância (5%).

```{r}
dic(trat, resp, quali = TRUE, mcomp = "tukey", sigT = 0.05)
```

## **Teste de Tukey com pacote `ExpDes.pt` (dados transformados em raiz - sqrt)**

```{r}
insects <- InsectSprays

insects$count2 <- sqrt(insects$count)

dic(insects$spray,
    insects$count2,
    mcomp = "tukey")
```

## **Teste de Scott Knott - pacote `ExpDes.pt`**

O método de Scott-Knott é uma técnica eficiente para comparar tratamentos em experimentos, especialmente quando o objetivo é agrupar médias em conjuntos homogêneos. Esse método busca minimizar a variabilidade dentro dos grupos e, ao mesmo tempo, maximizar a diferença entre eles, evitando sobreposição. Para isso, as médias dos tratamentos são ordenadas, permitindo sua classificação. Em seguida, são avaliadas todas as possíveis divisões (partições) com o propósito de identificar a melhor separação entre os grupos.

### **Experimento em DIC**

```{r}
#Agrupamento pelo teste de Scott Knott: O teste agrupa médias e serve para 1 fator apenas.

dic(insects$spray,
    insects$count2,
    mcomp = "sk")
```

### **Experimento em DBC**

#### Criar dados de exemplo

Vamos supor que testamos 5 cultivares de feijão, com 4 blocos (repetições):

```{r}
# Tratamentos (cultivares)
trat <- c(rep("A",4), rep("B",4), rep("C",4), rep("D",4), rep("E",4))

# Blocos (repetições)
bloco <- rep(1:4, 5)

# Produtividade em kg/ha (variável resposta)
resp <- c(1800, 1850, 1750, 1820,  # A
          2100, 2150, 2080, 2120,  # B
          1700, 1680, 1720, 1690,  # C
          1950, 1980, 1930, 1970,  # D
          2200, 2250, 2220, 2180)  # E
```

#### **Análise de variância + Scott-Knott (DBC)**

`dbc()`: função para analisar um experimento em Delineamento em Blocos Casualizados.

`trat`: vetor com os tratamentos (cultivares).

`bloco`: vetor com os blocos (repetições).

`resp`: vetor com a variável resposta (ex: produtividade).

`quali = TRUE`: indica que os tratamentos são qualitativos.

`mcomp = "sk"`: aplica o **teste de Scott-Knott** para comparação de médias.

`sigT = 0.05`: nível de significância de 5%.

```{r}
dbc(trat, bloco, resp, quali = TRUE, mcomp = "sk", sigT = 0.05)
```
